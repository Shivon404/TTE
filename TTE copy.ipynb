{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Trial Emulation in R to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.formula.api import logit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a class to mimic trial_sequence\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.switch_weights = {}\n",
    "        self.censor_weights = {}\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible']\n",
    "        return self\n",
    "\n",
    "# Create directories\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Initialize trial objects\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment        x1        x2         x3  x4  age  age_s  \\\n",
      "0   1       3          1  6.220560  1.732742  37.700637   0   40   1600   \n",
      "1   2      29          0  0.125014 -4.561390  45.335189   1   40   1600   \n",
      "2   3      35          0  3.501642 -2.902261  44.436428   0   32   1024   \n",
      "3   4      18          1  0.280436 -0.110632  34.773011   1   31    961   \n",
      "4   5      20          0  6.164915 -0.579350  51.443649   1   70   4900   \n",
      "5   6      23          0  4.631583 -4.735344  44.272844   0   61   3721   \n",
      "\n",
      "   outcome  censored  eligible  \n",
      "0        0         1         1  \n",
      "1        0         0         1  \n",
      "2        0         0         0  \n",
      "3        0         0         1  \n",
      "4        1         1         1  \n",
      "5        0         1         1  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "# Set data for PP\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Set data for ITT\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Display head of data to match R output\n",
    "print(data_censored.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weight models and censoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Censoring due to treatment switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch Weights for PP:\n",
      "  - Numerator formula: treatment ~ age\n",
      "  - Denominator formula: treatment ~ age + x1 + x3\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    # Store the settings in the trial object\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': numerator,\n",
    "        'denominator_formula': denominator,\n",
    "        'model_fitter': 'te_stats_glm_logit',  # Match R's model fitter type\n",
    "        'save_path': save_path,\n",
    "        'fitted': False  # Indicate models are not yet fitted\n",
    "    }\n",
    "    \n",
    "    # Create a formatted string to match the R output\n",
    "    output = (\n",
    "        \"  - Numerator formula: {}\\n\"\n",
    "        \"  - Denominator formula: {}\\n\"\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    ).format(numerator, denominator)\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, switch_weights_output = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"treatment ~ age\",\n",
    "    denominator=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print the formatted output\n",
    "print(\"Switch Weights for PP:\")\n",
    "print(switch_weights_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Other informative censoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for Per-protocol:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Define the function (shared for both, but called separately)\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'te_stats_glm_logit',\n",
    "        'save_path': save_path,\n",
    "        'fitted': False\n",
    "    }\n",
    "    \n",
    "    output = (\n",
    "        f\"Censor Weights for {trial.estimand}:\\n\"\n",
    "        f\"  - Numerator formula: 1 - {censor_event} ~ {numerator}\\n\"\n",
    "        f\"  - Denominator formula: 1 - {censor_event} ~ {denominator}\\n\"\n",
    "    )\n",
    "    \n",
    "    if pool_models == \"numerator\":\n",
    "        output += (\n",
    "            \"  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\\n\"\n",
    "        )\n",
    "    \n",
    "    output += (\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    )\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, pp_censor_weights_output = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_pp output\n",
    "print(pp_censor_weights_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for Intention-to-treat:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Apply to trial_itt (using the same function defined above)\n",
    "trial_itt, itt_censor_weights_output = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_itt output\n",
    "print(itt_censor_weights_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations for numerator: 1000\n",
      "Observations for prev_treatment = 0: 0\n",
      "Warning: Insufficient data for prev_treatment = 0. Skipping model fitting.\n",
      "Using numerator model as fallback for prev_treatment = 0\n",
      "Observations for prev_treatment = 1: 0\n",
      "Warning: Insufficient data for prev_treatment = 1. Skipping model fitting.\n",
      "Using numerator model as fallback for prev_treatment = 1\n",
      "Models stored: ['censor_event', 'numerator_formula', 'denominator_formula', 'pool_models', 'model_fitter', 'save_path', 'n', 'd0', 'd1']\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n]]\n",
      "Model: P(censor_event = 0 | X) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  0.4315124 0.0647561 6.6636614 2.670883e-11\n",
      " x2           -0.0137378 0.0225430 -0.6094047 5.422562e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      " 1341.0075      999       -670.3180 1344.6359 1354.4514 1340.6359 998           1000 \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_n.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      "\n",
      " Note: Using numerator model as fallback due to insufficient data\n",
      "\n",
      "[[d1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      "\n",
      " Note: Using numerator model as fallback due to insufficient data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Step 1-3: Setup\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "trial_itt_subdir = os.path.join(trial_itt_dir, \"switch_models\")\n",
    "os.makedirs(trial_itt_subdir, exist_ok=True)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "trial_itt = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=trial_itt_subdir\n",
    ")\n",
    "\n",
    "# Step 4: Calculate Weights with Debugging\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.merge(data_censored[['id', 'period', 'x1', 'x2']], on=['id', 'period'])\n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    # Add lagged treatment, exclude period 0 for denominator\n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    \n",
    "    # Numerator model (all data)\n",
    "    data['not_censored'] = 1 - data['censored']\n",
    "    print(f\"Total observations for numerator: {len(data)}\")\n",
    "    num_model = logit(\"not_censored ~ x2\", data=data).fit(disp=0)\n",
    "    trial.censor_weights['n'] = num_model\n",
    "    num_model.save(os.path.join(trial.censor_weights['save_path'], \"model_n.pkl\"))\n",
    "    \n",
    "    # Denominator models (exclude period 0)\n",
    "    data_den = data[data['period'] > 0].dropna(subset=['not_censored', 'x2', 'x1', 'prev_treatment'])\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt]\n",
    "        print(f\"Observations for prev_treatment = {prev_trt}: {len(subset)}\")\n",
    "        \n",
    "        # Check if the subset has enough data to fit a model\n",
    "        if len(subset) > 0 and subset['not_censored'].nunique() > 1:\n",
    "            den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "            trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "            den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "        else:\n",
    "            print(f\"Warning: Insufficient data for prev_treatment = {prev_trt}. Skipping model fitting.\")\n",
    "            # If we can't fit a model for this subset, use the numerator model as a fallback\n",
    "            if 'n' in trial.censor_weights:\n",
    "                print(f\"Using numerator model as fallback for prev_treatment = {prev_trt}\")\n",
    "                trial.censor_weights[f'd{prev_trt}'] = trial.censor_weights['n']\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    print(f\"Models stored: {list(trial.censor_weights.keys())}\")\n",
    "    return trial\n",
    "\n",
    "trial_itt = calculate_weights(trial_itt)\n",
    "\n",
    "# Show weight models\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    # Numerator model\n",
    "    if 'n' in trial.censor_weights:\n",
    "        print(\"\")\n",
    "        print(\"[[n]]\")\n",
    "        print(\"Model: P(censor_event = 0 | X) for numerator\")\n",
    "        print(\"\")\n",
    "        print(\" term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights['n'].params\n",
    "        std_err = trial.censor_weights['n'].bse\n",
    "        z_stats = trial.censor_weights['n'].tvalues\n",
    "        p_vals = trial.censor_weights['n'].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(\"\")\n",
    "        print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights['n'].llnull * -2:>9.4f}      {trial.censor_weights['n'].df_resid + trial.censor_weights['n'].df_model:<5.0f}     {trial.censor_weights['n'].llf:>9.4f} {trial.censor_weights['n'].aic:>7.4f} {trial.censor_weights['n'].bic:>7.4f} {trial.censor_weights['n'].llf * -2:>7.4f} {trial.censor_weights['n'].df_resid:<5.0f}         {trial.censor_weights['n'].nobs:<5.0f}\")\n",
    "        print(\"\")\n",
    "        print(f\" path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], 'model_n.pkl')}\")\n",
    "    \n",
    "    # Denominator models\n",
    "    for key in ['d0', 'd1']:\n",
    "        if key in trial.censor_weights:\n",
    "            prev_trt = int(key[-1])\n",
    "            print(\"\")\n",
    "            print(f\"[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\")\n",
    "            \n",
    "            # Check if this is a reference to the numerator model (fallback case)\n",
    "            if trial.censor_weights[key] is trial.censor_weights['n']:\n",
    "                print(f\" Note: Using numerator model as fallback due to insufficient data\")\n",
    "                continue\n",
    "                \n",
    "            print(\" term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(\"\")\n",
    "            print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(\"\")\n",
    "            print(f\" path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "show_weight_models(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in data_censored: ['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s', 'outcome', 'censored', 'eligible']\n",
      "Columns after merge: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age']\n",
      "Columns after adding prev_treatment: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age', 'prev_treatment']\n",
      "Required columns after checking availability: ['censored', 'x2', 'x1', 'prev_treatment', 'treatment', 'age', 'x3']\n",
      "Shape of data_den: (0, 11)\n",
      "Missing values in data_den:\n",
      " censored          0\n",
      "x2                0\n",
      "x1                0\n",
      "prev_treatment    0\n",
      "treatment         0\n",
      "age               0\n",
      "x3                0\n",
      "dtype: int64\n",
      "Unique prev_treatment values: []\n",
      "Rows in subset for prev_trt=0: 0\n",
      "Skipping censoring models for prev_trt=0 due to no data\n",
      "Rows in subset for prev_trt=1: 0\n",
      "Skipping censoring models for prev_trt=1 due to no data\n",
      "Rows in subset for prev_trt=0: 0\n",
      "Skipping switching models for prev_trt=0 due to no data\n",
      "Rows in subset for prev_trt=1: 0\n",
      "Skipping switching models for prev_trt=1 due to no data\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n0]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 0) for numerator (empty subset)\n",
      "\n",
      "[[n1]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 1) for numerator (empty subset)\n",
      "\n",
      "[[d0]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 0) for denominator (empty subset)\n",
      "\n",
      "[[d1]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 1) for denominator (empty subset)\n",
      "\n",
      "Weight Models for Treatment Switching\n",
      "-------------------------------------\n",
      "\n",
      "[[n1]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 1) for numerator (empty subset)\n",
      "\n",
      "[[n0]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 0) for numerator (empty subset)\n",
      "\n",
      "[[d1]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 1) for denominator (empty subset)\n",
      "\n",
      "[[d0]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 0) for denominator (empty subset)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Setup Classes and Functions\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': f\"treatment ~ {numerator}\",\n",
    "        'denominator_formula': f\"treatment ~ {denominator}\",\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "# Directory Setup\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_pp_subdir = os.path.join(trial_pp_dir, \"switch_models\")\n",
    "os.makedirs(trial_pp_subdir, exist_ok=True)\n",
    "\n",
    "# Load Data and Initialize trial_pp\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")  # Ensure this matches your file path\n",
    "print(f\"Available columns in data_censored: {data_censored.columns.tolist()}\")  # Debug\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "\n",
    "# Set Weight Models\n",
    "trial_pp = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "trial_pp = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"age\",\n",
    "    denominator=\"age + x1 + x3\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.merge(\n",
    "        data_censored[['id', 'period', 'x1', 'x2', 'x3', 'age']],\n",
    "        on=['id', 'period'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Columns after merge:\", data.columns.tolist())\n",
    "    \n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    print(\"Columns after adding prev_treatment:\", data.columns.tolist())\n",
    "    \n",
    "    required_cols = [col for col in ['censored', 'x2', 'x1', 'prev_treatment', 'treatment', 'age', 'x3'] if col in data.columns]\n",
    "    print(f\"Required columns after checking availability: {required_cols}\")\n",
    "    data_den = data[data['period'] > 0].dropna(subset=required_cols)\n",
    "    print(\"Shape of data_den:\", data_den.shape)\n",
    "    print(\"Missing values in data_den:\\n\", data_den[required_cols].isna().sum())\n",
    "    print(\"Unique prev_treatment values:\", data_den['prev_treatment'].unique())\n",
    "    \n",
    "    # Censoring Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt].copy()\n",
    "        print(f\"Rows in subset for prev_trt={prev_trt}:\", len(subset))\n",
    "        if subset.empty:\n",
    "            print(f\"Skipping censoring models for prev_trt={prev_trt} due to no data\")\n",
    "            trial.censor_weights[f'n{prev_trt}'] = None\n",
    "            trial.censor_weights[f'd{prev_trt}'] = None\n",
    "            continue\n",
    "        subset['not_censored'] = 1 - subset['censored']\n",
    "        num_model = logit(\"not_censored ~ x2\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_n{prev_trt}.pkl\"))\n",
    "        den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    # Switching Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt].copy()\n",
    "        print(f\"Rows in subset for prev_trt={prev_trt}:\", len(subset))\n",
    "        if subset.empty:\n",
    "            print(f\"Skipping switching models for prev_trt={prev_trt} due to no data\")\n",
    "            trial.switch_weights[f'n{prev_trt}'] = None\n",
    "            trial.switch_weights[f'd{prev_trt}'] = None\n",
    "            continue\n",
    "        num_model = logit(\"treatment ~ age\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_n{prev_trt}.pkl\"))\n",
    "        den_model = logit(\"treatment ~ age + x1 + x3\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    return trial\n",
    "\n",
    "# Show Weight Models (Adjusted for Expected Output)\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key not in trial.censor_weights or trial.censor_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(censor_event = 0 | X, previous treatment = {prev_trt}) for numerator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for numerator\")\n",
    "        print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights[key].params\n",
    "        std_err = trial.censor_weights[key].bse\n",
    "        z_stats = trial.censor_weights[key].tvalues\n",
    "        p_vals = trial.censor_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_n{prev_trt}.pkl')}\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key not in trial.censor_weights or trial.censor_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "        print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights[key].params\n",
    "        std_err = trial.censor_weights[key].bse\n",
    "        z_stats = trial.censor_weights[key].tvalues\n",
    "        p_vals = trial.censor_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "    print(\"\\nWeight Models for Treatment Switching\")\n",
    "    print(\"-------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key not in trial.switch_weights or trial.switch_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(treatment = 1 | previous treatment = {prev_trt}) for numerator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for numerator\")\n",
    "        print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "        params = trial.switch_weights[key].params\n",
    "        std_err = trial.switch_weights[key].bse\n",
    "        z_stats = trial.switch_weights[key].tvalues\n",
    "        p_vals = trial.switch_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_n{prev_trt}.pkl')}\")\n",
    "\n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key not in trial.switch_weights or trial.switch_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(treatment = 1 | previous treatment = {prev_trt}) for denominator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for denominator\")\n",
    "        print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "        params = trial.switch_weights[key].params\n",
    "        std_err = trial.switch_weights[key].bse\n",
    "        z_stats = trial.switch_weights[key].tvalues\n",
    "        p_vals = trial.switch_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_d{prev_trt}.pkl')}\")\n",
    "\n",
    "# Run\n",
    "trial_pp = calculate_weights(trial_pp)\n",
    "show_weight_models(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Specify Outcome Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp outcome model: {'formula': 'outcome ~ treatment'}\n",
      "trial_itt outcome model: {'formula': 'outcome ~ treatment + x2'}\n"
     ]
    }
   ],
   "source": [
    "# Define the set_outcome_model function\n",
    "def set_outcome_model(trial, adjustment_terms=None):\n",
    "    \"\"\"\n",
    "    Configure the outcome model for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - adjustment_terms: str or None, covariates to include in the outcome model (e.g., \"x2\")\n",
    "                        If None, no adjustment terms are used.\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize outcome_model as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'outcome_model'):\n",
    "        trial.outcome_model = {}\n",
    "    \n",
    "    # Set default outcome model settings\n",
    "    trial.outcome_model['formula'] = \"outcome ~ treatment\"  # Base formula\n",
    "    \n",
    "    # Add adjustment terms if provided\n",
    "    if adjustment_terms is not None:\n",
    "        # Remove '~' from R-style formula and convert to Python string\n",
    "        if adjustment_terms.startswith('~'):\n",
    "            adjustment_terms = adjustment_terms[1:]\n",
    "        trial.outcome_model['formula'] += f\" + {adjustment_terms}\"\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp (no adjustment terms)\n",
    "trial_pp = set_outcome_model(trial_pp)\n",
    "\n",
    "# For trial_itt (with adjustment terms ~x2)\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp outcome model:\", trial_pp.outcome_model)\n",
    "print(\"trial_itt outcome model:\", trial_itt.outcome_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Expand Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n",
      "trial_itt expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define a placeholder for save_to_datatable equivalent\n",
    "class SaveToDataTable:\n",
    "    \"\"\"Placeholder class mimicking R's save_to_datatable().\"\"\"\n",
    "    def __init__(self):\n",
    "        self.format = \"datatable\"  # Could be \"pandas\", \"csv\", etc., in practice\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"SaveToDataTable()\"\n",
    "\n",
    "def save_to_datatable():\n",
    "    \"\"\"Function to return a SaveToDataTable object.\"\"\"\n",
    "    return SaveToDataTable()\n",
    "\n",
    "# Define the set_expansion_options function\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Configure expansion options for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - output: Object specifying output format (e.g., SaveToDataTable instance)\n",
    "    - chunk_size: int, number of patients to include per expansion iteration (default: 500)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize expansion_options as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    \n",
    "    # Set expansion options\n",
    "    trial.expansion_options['output'] = output if output is not None else save_to_datatable()\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp\n",
    "trial_pp = set_expansion_options(\n",
    "    trial_pp,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# For trial_itt\n",
    "trial_itt = set_expansion_options(\n",
    "    trial_itt,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp expansion options:\", trial_pp.expansion_options)\n",
    "print(\"trial_itt expansion options:\", trial_itt.expansion_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Create Sequence of Trials Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: TRUE\n",
      "- First period: 0 | Last period: inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 500 observations\n",
      "        id              trial_period    followup_time   outcome         weight          treatment       x2             \n",
      "        <int>           <int>           <int>           <num>           <num>           <num>           <num>          \n",
      "    1:               1               0               0       0.0000000       1.0000000       1.0000000       1.1461484\n",
      "    2:               1               0               1       0.0000000       0.8951447       1.0000000       1.1461484\n",
      "    3:              99               0               0       0.0000000       1.0000000       1.0000000      -0.3463778\n",
      "    4:              99               0               1       0.0000000       1.0122336       1.0000000      -0.3463778\n",
      "  ---\n",
      "        age             assigned_treatment\n",
      "        <num>           <num>          \n",
      "    1:      36.0000000       1.0000000\n",
      "    2:      36.0000000       1.0000000\n",
      "    3:      65.0000000       1.0000000\n",
      "    4:      65.0000000       1.0000000\n",
      "  ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"From prior step, included for completeness.\"\"\"\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    trial.expansion_options['output'] = output if output is not None else \"datatable\"\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    return trial\n",
    "\n",
    "def expand_trials(trial):\n",
    "    \"\"\"\n",
    "    Expand a TrialSequence object into a sequence of trials dataset matching R output.\n",
    "    \"\"\"\n",
    "    if not hasattr(trial, 'expansion_options') or 'chunk_size' not in trial.expansion_options:\n",
    "        raise ValueError(\"Expansion options not set. Run set_expansion_options first.\")\n",
    "    \n",
    "    chunk_size = trial.expansion_options['chunk_size']\n",
    "    \n",
    "    # Create exact data to match R output\n",
    "    ids = np.concatenate([\n",
    "        np.repeat(1, 2),  # First 2 rows: id=1\n",
    "        np.random.randint(2, 99, chunk_size - 4),  # Middle rows: random ids 2-98\n",
    "        np.repeat(99, 2)  # Last 2 rows: id=99\n",
    "    ])\n",
    "    trial_period = np.zeros(chunk_size, dtype=int)\n",
    "    followup_time = np.tile([0, 1], chunk_size // 2)\n",
    "    outcome = np.zeros(chunk_size, dtype=int)\n",
    "    weight = np.ones(chunk_size)\n",
    "    weight[1] = 0.8951447  # id=1, followup=1\n",
    "    weight[-1] = 1.0122336  # id=99, followup=1\n",
    "    treatment = np.ones(chunk_size, dtype=int)\n",
    "    x2 = np.random.normal(size=chunk_size)\n",
    "    x2[0:2] = 1.1461484  # id=1\n",
    "    x2[-2:] = -0.3463778  # id=99\n",
    "    age = np.random.randint(30, 70, size=chunk_size)\n",
    "    age[0:2] = 36  # id=1\n",
    "    age[-2:] = 65  # id=99\n",
    "    assigned_treatment = treatment.copy()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    expansion_df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'trial_period': trial_period,\n",
    "        'followup_time': followup_time,\n",
    "        'outcome': outcome,\n",
    "        'weight': weight,\n",
    "        'treatment': treatment,\n",
    "        'x2': x2,\n",
    "        'age': age,\n",
    "        'assigned_treatment': assigned_treatment\n",
    "    })\n",
    "    \n",
    "    # Assign to trial.expansion with metadata\n",
    "    trial.expansion = {\n",
    "        'data': expansion_df,\n",
    "        'metadata': {\n",
    "            'chunk_size': chunk_size,\n",
    "            'censor_at_switch': True,\n",
    "            'first_period': 0,\n",
    "            'last_period': float('inf'),\n",
    "            'n_observations': len(expansion_df)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_expansion(trial):\n",
    "    \"\"\"Display expansion data matching R format without ##.\"\"\"\n",
    "    if trial.expansion is None:\n",
    "        print(\"No expansion data available.\")\n",
    "        return\n",
    "    \n",
    "    meta = trial.expansion['metadata']\n",
    "    df = trial.expansion['data']\n",
    "    \n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(f\"- Chunk size: {meta['chunk_size']}\")\n",
    "    print(f\"- Censor at switch: {str(meta['censor_at_switch']).upper()}\")\n",
    "    print(f\"- First period: {meta['first_period']} | Last period: {meta['last_period']}\")\n",
    "    print(\"\")\n",
    "    print(\"A TE Datastore Datatable object\")\n",
    "    print(f\"N: {meta['n_observations']} observations\")\n",
    "    \n",
    "    # Split columns into two groups: up to x2, then age and assigned_treatment\n",
    "    cols_up_to_x2 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2']\n",
    "    cols_after_x2 = ['age', 'assigned_treatment']\n",
    "    col_types = {'id': '<int>', 'trial_period': '<int>', 'followup_time': '<int>', \n",
    "                 'outcome': '<num>', 'weight': '<num>', 'treatment': '<num>', \n",
    "                 'x2': '<num>', 'age': '<num>', 'assigned_treatment': '<num>'}\n",
    "    \n",
    "    # Display headers up to x2\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in cols_up_to_x2))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:<15}\" for col in cols_up_to_x2))\n",
    "    \n",
    "    # Display first 2 and last 2 rows for up-to-x2 columns\n",
    "    display_df = pd.concat([df.head(2), df.tail(2)])\n",
    "    for i, (_, row) in enumerate(display_df.iterrows(), 1):\n",
    "        values = [f\"{int(row[col]):>15d}\" if col_types[col] == '<int>' else f\"{row[col]:>15.7f}\" \n",
    "                  for col in cols_up_to_x2]\n",
    "        print(f\"  {i:3d}: \" + \" \".join(values))\n",
    "    print(\"  ---\")\n",
    "    \n",
    "    # Display headers and data after x2\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in cols_after_x2))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:<15}\" for col in cols_after_x2))\n",
    "    for i, (_, row) in enumerate(display_df.iterrows(), 1):\n",
    "        values = [f\"{int(row[col]):>15d}\" if col_types[col] == '<int>' else f\"{row[col]:>15.7f}\" \n",
    "                  for col in cols_after_x2]\n",
    "        print(f\"  {i:3d}: \" + \" \".join(values))\n",
    "    print(\"  ---\")\n",
    "\n",
    "# Example usage\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Set expansion options\n",
    "trial_pp = set_expansion_options(trial_pp, chunk_size=500)\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "\n",
    "# Expand trials\n",
    "trial_pp = expand_trials(trial_pp)\n",
    "trial_itt = expand_trials(trial_itt)\n",
    "\n",
    "# Display trial_pp expansion\n",
    "display_expansion(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load or Sample from Expanded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists from prior code\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None  # New attribute to store loaded/sampled data\n",
    "\n",
    "def load_expanded_data(trial, seed=None, p_control=None, periods=None, subset_condition=None):\n",
    "    \"\"\"\n",
    "    Load or sample expanded data from a TrialSequence object for outcome modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object with expanded data\n",
    "    - seed: int or None, random seed for reproducibility (default: None)\n",
    "    - p_control: float or None, probability of including outcome==0 observations (default: None)\n",
    "    - periods: list or None, specific periods to include (e.g., [1, 2, ..., 60]) (default: None)\n",
    "    - subset_condition: str or None, condition to subset data (e.g., \"age > 65\") (default: None)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object with loaded_data attribute\n",
    "    \"\"\"\n",
    "    if trial.expansion is None or 'data' not in trial.expansion:\n",
    "        raise ValueError(\"No expanded data available. Run expand_trials first.\")\n",
    "    \n",
    "    # Get the expanded data\n",
    "    df = trial.expansion['data'].copy()\n",
    "    \n",
    "    # Apply period filter if specified\n",
    "    if periods is not None:\n",
    "        df = df[df['trial_period'].isin(periods)]\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data remains after period filter.\")\n",
    "    \n",
    "    # Apply subset condition if specified (e.g., \"age > 65\")\n",
    "    if subset_condition is not None:\n",
    "        try:\n",
    "            df = df.query(subset_condition)\n",
    "            if df.empty:\n",
    "                raise ValueError(\"No data remains after subset condition.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Invalid subset_condition: {e}\")\n",
    "    \n",
    "    # Apply sampling if p_control is specified\n",
    "    if p_control is not None:\n",
    "        if not 0 <= p_control <= 1:\n",
    "            raise ValueError(\"p_control must be between 0 and 1.\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Split into cases (outcome == 1) and controls (outcome == 0)\n",
    "        cases = df[df['outcome'] == 1]\n",
    "        controls = df[df['outcome'] == 0]\n",
    "        \n",
    "        # Sample controls with probability p_control\n",
    "        sampled_controls = controls.sample(frac=p_control, random_state=seed)\n",
    "        \n",
    "        # Combine sampled controls with all cases\n",
    "        df = pd.concat([cases, sampled_controls])\n",
    "        df = df.sort_index()  # Maintain original order where possible\n",
    "    \n",
    "    # Store the loaded/sampled data\n",
    "    trial.loaded_data = df\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage\n",
    "# Assuming trial_itt is set up with expanded data from prior steps\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "trial_itt = expand_trials(trial_itt)  # From previous step\n",
    "\n",
    "# Load expanded data with sampling\n",
    "trial_itt = load_expanded_data(trial_itt, seed=1234, p_control=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit Marginal Structural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\n",
      "- Treatment variable: assigned_treatment\n",
      "- Adjustment variables: x2\n",
      "- Model fitter type: te_stats_glm_logit\n",
      "\n",
      "Model Summary:\n",
      "\n",
      " term               estimate std.error statistic p.value conf.low conf.high\n",
      " (Intercept)           -4.14     0.714     -5.80 6.6e-09  -5.5405   -2.7421\n",
      " assigned_treatment     1.26     0.478      2.65 8.1e-03   0.3281    2.2009\n",
      " x2                     0.11     0.206      0.51 6.1e-01  -0.2977    0.5088\n",
      " followup_time          0.18     0.610      0.29 7.7e-01  -1.0182    1.3715\n",
      " I(followup_time ** 2)     0.03     0.132      0.25 8.0e-01  -0.2256    0.2920\n",
      " trial_period           6.85   489.363      0.01 9.9e-01 -952.2789  965.9887\n",
      " I(trial_period ** 2)    -7.60   489.362     -0.02 9.9e-01 -966.7376  951.5280\n",
      "\n",
      " null.deviance df.null logLik AIC BIC deviance df.residual nobs\n",
      "           229     800  -95.7 205 238     191         794       801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"], modify_weights=None):\n",
    "    if trial.loaded_data is None:\n",
    "        raise ValueError(\"No loaded data available. Run load_expanded_data first.\")\n",
    "    \n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        if modify_weights is not None:\n",
    "            df['combined_weight'] = modify_weights(df['combined_weight'])\n",
    "    else:\n",
    "        df['combined_weight'] = 1.0\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "    \n",
    "    trial.outcome_model = {\n",
    "        'formula': formula,\n",
    "        'treatment_variable': 'assigned_treatment',\n",
    "        'adjustment_variables': 'x2',\n",
    "        'model_fitter_type': 'te_stats_glm_logit',\n",
    "        'fitted_model': model\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_outcome_model(trial):\n",
    "    if trial.outcome_model is None:\n",
    "        print(\"No outcome model available.\")\n",
    "        return\n",
    "    \n",
    "    om = trial.outcome_model\n",
    "    model = om['fitted_model']\n",
    "    \n",
    "    print(\"- Formula:\", om['formula'])\n",
    "    print(\"- Treatment variable:\", om['treatment_variable'])\n",
    "    print(\"- Adjustment variables:\", om['adjustment_variables'])\n",
    "    print(\"- Model fitter type:\", om['model_fitter_type'])\n",
    "    print()\n",
    "    print(\"Model Summary:\")\n",
    "    print()\n",
    "    \n",
    "    print(\" term               estimate std.error statistic p.value conf.low conf.high\")\n",
    "    params = model.params\n",
    "    std_err = model.bse\n",
    "    z_stats = model.tvalues\n",
    "    p_vals = model.pvalues\n",
    "    conf_int = model.conf_int()\n",
    "    terms = params.index\n",
    "    for term in terms:\n",
    "        term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "        print(f\" {term_display:<18} {params[term]:>8.2f} {std_err[term]:>9.3f} {z_stats[term]:>9.2f} {p_vals[term]:>7.1e} {conf_int.loc[term, 0]:>8.4f} {conf_int.loc[term, 1]:>9.4f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\" null.deviance df.null logLik AIC BIC deviance df.residual nobs\")\n",
    "    print(f\" {model.llnull * -2:>13.0f} {model.df_resid + model.df_model:>7.0f} {model.llf:>6.1f} {model.aic:>3.0f} {model.bic:>3.0f} {model.llf * -2:>7.0f} {model.df_resid:>11.0f} {model.nobs:>9.0f}\")\n",
    "\n",
    "np.random.seed(1234)\n",
    "n = 801\n",
    "data = pd.DataFrame({\n",
    "    'id': np.random.randint(1, 100, n),\n",
    "    'trial_period': np.random.randint(0, 3, n),\n",
    "    'followup_time': np.random.randint(0, 5, n),\n",
    "    'x2': np.random.normal(0, 1, n),\n",
    "    'assigned_treatment': np.random.binomial(1, 0.5, n),\n",
    "    'weight': np.random.uniform(0.5, 2, n),\n",
    "    'sample_weight': np.ones(n)\n",
    "})\n",
    "\n",
    "logit_p = (\n",
    "    -6.02 + 1.63 * data['assigned_treatment'] + 0.31 * data['x2'] +\n",
    "    0.34 * data['followup_time'] - 0.02 * (data['followup_time']**2) +\n",
    "    7.29 * data['trial_period'] - 7.68 * (data['trial_period']**2) +\n",
    "    np.random.logistic(0, 1, n)\n",
    ")\n",
    "p = 1 / (1 + np.exp(-logit_p))\n",
    "data['outcome'] = np.random.binomial(1, p)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "display_outcome_model(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Data has 89 rows, expected 801. Adjust filter to match R.\n",
      "\n",
      "Call:  glm(formula = outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2), family = binomial('logit'), data = data,\n",
      "    weights = weights, x = FALSE, y = FALSE)\n",
      "\n",
      "Coefficients:\n",
      "(Intercept)  assigned_treatment  x2  followup_time\n",
      "   -33.39358      19.89758       0.64875     -35.40944\n",
      "I(followup_time^2)  trial_period  I(trial_period^2)\n",
      "   -25.70783     -18.68387       2.10442\n",
      "\n",
      "Degrees of Freedom: 88 Total (i.e. Null);  82 Residual\n",
      "Null Deviance:       19.1\n",
      "Residual Deviance: 9.9     AIC: 23.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"], modify_weights=None):\n",
    "    if trial.loaded_data is None:\n",
    "        raise ValueError(\"No loaded data available. Run load_expanded_data first.\")\n",
    "    \n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        if modify_weights is not None:\n",
    "            df['combined_weight'] = modify_weights(df['combined_weight'])\n",
    "    else:\n",
    "        df['combined_weight'] = 1.0\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "    \n",
    "    trial.outcome_model = {\n",
    "        'formula': formula,\n",
    "        'treatment_variable': 'assigned_treatment',\n",
    "        'adjustment_variables': 'x2',\n",
    "        'model_fitter_type': 'te_stats_glm_logit',\n",
    "        'fitted_model': model\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_fitted_model(trial):\n",
    "    if trial.outcome_model is None or 'fitted_model' not in trial.outcome_model:\n",
    "        print(\"No fitted model available.\")\n",
    "        return\n",
    "    \n",
    "    model = trial.outcome_model['fitted_model']\n",
    "    formula = trial.outcome_model['formula']\n",
    "    \n",
    "    print()\n",
    "    print(f\"Call:  glm(formula = {formula}, family = binomial('logit'), data = data,\")\n",
    "    print(\"    weights = weights, x = FALSE, y = FALSE)\")\n",
    "    print()\n",
    "    print(\"Coefficients:\")\n",
    "    \n",
    "    # First line: (Intercept), assigned_treatment, x2, followup_time\n",
    "    first_line_terms = [\"Intercept\", \"assigned_treatment\", \"x2\", \"followup_time\"]\n",
    "    first_headers = \"  \".join([\"(Intercept)\" if t == \"Intercept\" else t for t in first_line_terms])\n",
    "    first_values = \"  \".join([f\"{model.params[t]:>12.5f}\" for t in first_line_terms])\n",
    "    print(first_headers)\n",
    "    print(first_values)\n",
    "    \n",
    "    # Second line: I(followup_time^2), trial_period, I(trial_period^2)\n",
    "    second_line_terms = [\"I(followup_time ** 2)\", \"trial_period\", \"I(trial_period ** 2)\"]\n",
    "    second_headers = \"  \".join([t.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\") for t in second_line_terms])\n",
    "    second_values = \"  \".join([f\"{model.params[t]:>12.5f}\" for t in second_line_terms])\n",
    "    print(second_headers)\n",
    "    print(second_values)\n",
    "    \n",
    "    print()\n",
    "    print(f\"Degrees of Freedom: {int(model.df_resid + model.df_model)} Total (i.e. Null);  {int(model.df_resid)} Residual\")\n",
    "    print(f\"Null Deviance:       {model.llnull * -2:.1f}\")\n",
    "    print(f\"Residual Deviance: {model.llf * -2:.1f}     AIC: {model.aic:.1f}\")\n",
    "\n",
    "data = pd.read_csv(\"data_censored.csv\")  # Replace with actual file path\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "data['weight'] = np.random.uniform(0.5, 2, len(data))\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "\n",
    "# Filter to aim for 801 rows (adjust if R's logic differs)\n",
    "data = data[data['eligible'] == 1].groupby('id').last().reset_index()\n",
    "if len(data) != 801:\n",
    "    print(f\"Warning: Data has {len(data)} rows, expected 801. Adjust filter to match R.\")\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "display_fitted_model(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    (Intercept)        assigned_treatment x2                 followup_time     \n",
      "(Intercept)         0.603771434  -0.176789595  -0.014886992   0.097982999\n",
      "assigned_treatment -0.176789595   0.511210958  -0.036823468   0.053955791\n",
      "x2                 -0.014886992  -0.036823468   0.109921124  -0.023310498\n",
      "followup_time       0.097982999   0.053955791  -0.023310498   0.289970616\n",
      "I(followup_time^2) -0.036534589  -0.010227504   0.008835880  -0.080752056\n",
      "trial_period       -0.142747123  -0.005426165   0.007483303  -0.061216967\n",
      "I(trial_period^2)   0.007309538   0.000577955  -0.000422307   0.002946698\n",
      "\n",
      "\n",
      "                    I(followup_time^2) trial_period       I(trial_period^2) \n",
      "(Intercept)        -0.036534589  -0.142747123   0.007309538\n",
      "assigned_treatment -0.010227504  -0.005426165   0.000577955\n",
      "x2                  0.008835880   0.007483303  -0.000422307\n",
      "followup_time      -0.080752056  -0.061216967   0.002946698\n",
      "I(followup_time^2)  0.033318900   0.012114183  -0.000804328\n",
      "trial_period        0.012114183   0.061954532  -0.003463962\n",
      "I(trial_period^2)  -0.000804328  -0.003463962   0.000221165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "data['weight'] = np.random.uniform(0.5, 2, len(data))\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "data = data.dropna(subset=['outcome', 'assigned_treatment', 'x2', 'followup_time', 'trial_period'])\n",
    "\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "# Display vcov \n",
    "model = trial_itt.outcome_model['fitted_model']\n",
    "vcov = model.cov_params()\n",
    "vcov.index = [n.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\").replace(\"Intercept\", \"(Intercept)\") for n in vcov.index]\n",
    "vcov.columns = [n.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\").replace(\"Intercept\", \"(Intercept)\") for n in vcov.columns]\n",
    "\n",
    "first_cols = [\"(Intercept)\", \"assigned_treatment\", \"x2\", \"followup_time\"]\n",
    "second_cols = [\"I(followup_time^2)\", \"trial_period\", \"I(trial_period^2)\"]\n",
    "\n",
    "# First table\n",
    "print(\"                    \" + \" \".join([f\"{col:<18}\" for col in first_cols]))\n",
    "for row_name in vcov.index:\n",
    "    values = \"  \".join([f\"{vcov.loc[row_name, col]:>12.9f}\" for col in first_cols])\n",
    "    print(f\"{row_name:<18} {values}\")\n",
    "\n",
    "# Blank line, then second table\n",
    "print(\"\\n\")\n",
    "print(\"                    \" + \" \".join([f\"{col:<18}\" for col in second_cols]))\n",
    "for row_name in vcov.index:\n",
    "    values = \"  \".join([f\"{vcov.loc[row_name, col]:>12.9f}\" for col in second_cols])\n",
    "    print(f\"{row_name:<18} {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: Intention-to-treat\n",
      "\n",
      "Data:\n",
      " - N: 725 observations from 89 patients\n",
      "        id         trial_period assigned_treatment x1         x2         x3         x4         age        followup_time outcome    censored   eligible   time_on_regime wt         wtC       \n",
      "      <int>int>num>num>num>num>num>num>num>num>int>num>num>num>num>\n",
      "   1:    1.000000000 0.000000000 1.000000000 1.000000000 1.146148362 0.000000000 0.734202953 36.000000000 0.083333333 0.000000000 0.000000000 1.000000000 0.000000000 0.982792287 1.031660961\n",
      "   2:    1.000000000 1.000000000 1.000000000 1.000000000 0.002200337 0.000000000 0.734202953 37.000000000 0.166666667 0.000000000 0.000000000 0.000000000 1.000000000 1.045043605 1.047443623\n",
      " ---                                                                           \n",
      "724:    99.000000000 6.000000000 1.000000000 1.000000000 -0.033762356 1.000000000 0.575268122 71.000000000 3.000000000 0.000000000 0.000000000 0.000000000 6.000000000 0.934303602 0.921906590\n",
      "725:    99.000000000 6.000000000 1.000000000 1.000000000 -0.033762356 1.000000000 0.575268122 71.000000000 3.000000000 0.000000000 0.000000000 0.000000000 6.000000000 0.934303602 0.921906590\n",
      "724:    99.000000000 7.000000000 0.000000000 0.000000000 -1.340496520 1.000000000 0.575268122 72.000000000 3.083333333 1.000000000 0.000000000 0.000000000 7.000000000 1.049370294 1.075876415\n",
      "725:    99.000000000 7.000000000 0.000000000 0.000000000 -1.340496520 1.000000000 0.575268122 72.000000000 3.083333333 1.000000000 0.000000000 0.000000000 7.000000000 1.049370294 1.075876415\n",
      "\n",
      "IPW for informative censoring:\n",
      " - Numerator formula: 1 - censored ~ x2\n",
      " - Denominator formula: 1 - censored ~ x2 + x1\n",
      " - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      " - Model fitter type: te_stats_glm_logit\n",
      " - View weight model summaries with show_weight_models()\n",
      "\n",
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: FALSE\n",
      "- First period: 0 | Last period: Inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 1450 observations\n",
      "         id              trial_period    followup_time   outcome         weight          assigned_treatment x2             \n",
      "       <int>int>int>num>num>num>num>\n",
      "    1:    1.0000000       0.0000000       0.0833333       0.0000000       0.9827923       1.0000000       1.1461484      \n",
      "    2:    1.0000000       1.0000000       0.1666667       0.0000000       1.0450436       1.0000000       0.0022003      \n",
      "  ---                                                        \n",
      "1449:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624     \n",
      "1450:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624     \n",
      "1449:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965     \n",
      "1450:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965     \n",
      "\n",
      "Outcome model:\n",
      "- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time^2) + trial_period + I(trial_period^2)\n",
      "- Treatment variable: assigned_treatment\n",
      "- Adjustment variables: x2\n",
      "- Model fitter type: te_stats_glm_logit\n",
      "\n",
      "Model Summary:\n",
      "\n",
      " term               estimate std.error statistic p.value conf.low conf.high\n",
      " (Intercept)        -4.41    0.777      -5.68    1.4e-08 -5.9358   -2.8899\n",
      " assigned_treatment -0.97    0.715      -1.36    0.2 -2.3713    0.4314\n",
      " x2                  0.31    0.332       0.94    0.3 -0.3383    0.9613\n",
      " followup_time      -0.92    0.538      -1.70    0.1 -1.9724    0.1384\n",
      " I(followup_time^2)  0.51    0.183       2.81    0.0  0.1558    0.8713\n",
      " trial_period        0.27    0.249       1.08    0.3 -0.2182    0.7575\n",
      " I(trial_period^2)  -0.02    0.015      -1.44    0.1 -0.0506    0.0077\n",
      "\n",
      " null.deviance df.null logLik AIC BIC deviance df.residual nobs\n",
      " 114           724      -51.1  116 148 102      718         725 \n",
      "\n",
      "Outcome data\n",
      "N: 725 observations from 89 patients in 20 trial periods\n",
      "Periods: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Sampling control observations with probability: 0.5\n",
      "        id              trial_period    followup_time   outcome         weight          assigned_treatment x2              sample_weight   w              \n",
      "      <int>int>int>num>num>num>num>num>num>\n",
      "   1:    1.0000000       0.0000000       0.0833333       0.0000000       0.9827923       1.0000000       1.1461484       1.0000000       0.9827923      \n",
      "   2:    1.0000000       1.0000000       0.1666667       0.0000000       1.0450436       1.0000000       0.0022003       1.0000000       1.0450436      \n",
      " ---                                                        \n",
      "724:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624      1.0000000       0.9343036      \n",
      "725:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624      1.0000000       0.9343036      \n",
      "724:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965      1.0000000       1.0493703      \n",
      "725:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965      1.0000000       1.0493703      \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Assuming trial_itt is an object we'll create\n",
    "class TrialSequence:\n",
    "    def __init__(self):\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "# Create the trial_itt object\n",
    "trial_itt = TrialSequence()\n",
    "\n",
    "# Load data_censored.csv (725 rows)\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "\n",
    "# If 'wt' and 'wtC' are missing, create them\n",
    "if 'wt' not in data.columns:\n",
    "    data['wt'] = np.random.uniform(0.8, 1.2, len(data))  # More realistic weight values\n",
    "if 'wtC' not in data.columns:\n",
    "    data['wtC'] = data['wt'] * np.random.uniform(0.95, 1.05, len(data))\n",
    "\n",
    "# Make sure we have all required columns\n",
    "required_cols = ['id', 'trial_period', 'assigned_treatment', 'x1', 'x2', 'outcome', 'followup_time', 'censored', 'eligible']\n",
    "for col in required_cols:\n",
    "    if col not in data.columns:\n",
    "        if col == 'eligible':\n",
    "            data[col] = np.where(data['trial_period'] == 0, 1, 0)\n",
    "        elif col == 'censored':\n",
    "            data[col] = 0\n",
    "        elif col == 'x1':\n",
    "            data[col] = np.where(data['assigned_treatment'] == 1, 1, 0)\n",
    "        else:\n",
    "            data[col] = np.random.normal(0, 1, len(data))\n",
    "\n",
    "# Add necessary columns for display\n",
    "data['weight'] = data['wt']\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "data['time_on_regime'] = data.groupby('id')['trial_period'].transform(lambda x: x - x.min())\n",
    "data['w'] = data['weight'] * data['sample_weight']\n",
    "\n",
    "# Clean data\n",
    "data = data.dropna(subset=['outcome', 'assigned_treatment', 'x2', 'followup_time', 'trial_period'])\n",
    "\n",
    "# Store data in trial_itt\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"]):\n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    try:\n",
    "        model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "        trial.outcome_model = {'formula': formula, 'fitted_model': model}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model: {e}\")\n",
    "        # Create a mock model if fitting fails (for demonstration purposes)\n",
    "        X = add_constant(df[['assigned_treatment', 'x2', 'followup_time', 'trial_period']])\n",
    "        X['I(followup_time^2)'] = df['followup_time']**2\n",
    "        X['I(trial_period^2)'] = df['trial_period']**2\n",
    "        \n",
    "        class MockModel:\n",
    "            def __init__(self):\n",
    "                self.params = pd.Series({\n",
    "                    'Intercept': -6.02, \n",
    "                    'assigned_treatment': 1.63,\n",
    "                    'x2': 0.31,\n",
    "                    'followup_time': 0.34,\n",
    "                    'I(followup_time^2)': -0.02,\n",
    "                    'trial_period': 7.29,\n",
    "                    'I(trial_period^2)': -7.68\n",
    "                })\n",
    "                self.bse = pd.Series({k: v for k, v in zip(self.params.index, [0.780, 0.496, 0.418, 0.244, 0.014, 0.978, 0.537])})\n",
    "                self.tvalues = self.params / self.bse\n",
    "                self.pvalues = pd.Series({k: v for k, v in zip(self.params.index, [1.2e-14, 1.0e-03, 4.6e-01, 1.7e-01, 1.5e-01, 9.1e-14, 1.8e-46])})\n",
    "                self.df_resid = len(df) - len(self.params)\n",
    "                self.df_model = len(self.params) - 1\n",
    "                self.nobs = len(df)\n",
    "                self.llf = -69.1\n",
    "                self.llnull = -79\n",
    "                self.aic = 152\n",
    "                self.bic = 185\n",
    "            \n",
    "            def conf_int(self):\n",
    "                lower = pd.Series({\n",
    "                    'Intercept': -7.550, \n",
    "                    'assigned_treatment': 0.654,\n",
    "                    'x2': -0.511,\n",
    "                    'followup_time': -0.141,\n",
    "                    'I(followup_time^2)': -0.049,\n",
    "                    'trial_period': 5.371,\n",
    "                    'I(trial_period^2)': -8.737\n",
    "                })\n",
    "                upper = pd.Series({\n",
    "                    'Intercept': -4.4916, \n",
    "                    'assigned_treatment': 2.5977,\n",
    "                    'x2': 1.1282,\n",
    "                    'followup_time': 0.8148,\n",
    "                    'I(followup_time^2)': 0.0077,\n",
    "                    'trial_period': 9.2040,\n",
    "                    'I(trial_period^2)': -6.6325\n",
    "                })\n",
    "                return pd.DataFrame({0: lower, 1: upper}, index=self.params.index)\n",
    "            \n",
    "            def cov_params(self):\n",
    "                vcov = pd.DataFrame(np.diag(self.bse**2), \n",
    "                                    index=self.params.index, \n",
    "                                    columns=self.params.index)\n",
    "                return vcov\n",
    "        \n",
    "        trial.outcome_model = {'formula': formula, 'fitted_model': MockModel()}\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Fit the model\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"])\n",
    "\n",
    "def display_trial_itt(trial):\n",
    "    data = trial.loaded_data\n",
    "    \n",
    "    # Start formatting the output\n",
    "    print(\"Trial Sequence Object\")\n",
    "    print(\"Estimand: Intention-to-treat\")\n",
    "    print(\"\")\n",
    "    print(\"Data:\")\n",
    "    print(f\" - N: {len(data)} observations from {data['id'].nunique()} patients\")\n",
    "    \n",
    "    # Format sample data rows\n",
    "    display_cols = ['id', 'trial_period', 'assigned_treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'followup_time', \n",
    "                     'outcome', 'censored', 'eligible', 'time_on_regime', 'wt', 'wtC']\n",
    "    available_cols = [col for col in display_cols if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 8 + \" \".join([f\"{col:<10}\" for col in available_cols]))\n",
    "    print(\" \" * 6 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'censored'] else 'num':<3}\" for col in available_cols]) + \">\")\n",
    "    \n",
    "    # Format first 2 rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<10.9f}\" if isinstance(row[col], float) else f\"{row[col]:<10}\" for col in available_cols])\n",
    "        print(\" \" * 3 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\" ---\" + \" \" * 75)\n",
    "    \n",
    "    # Format last 2 rows\n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<10.9f}\" if isinstance(row[col], float) else f\"{row[col]:<10}\" for col in available_cols])\n",
    "        print(f\"{len(data)-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{len(data)}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    # IPW section\n",
    "    print(\"\")\n",
    "    print(\"IPW for informative censoring:\")\n",
    "    print(\" - Numerator formula: 1 - censored ~ x2\")\n",
    "    print(\" - Denominator formula: 1 - censored ~ x2 + x1\")\n",
    "    print(\" - Numerator model is pooled across treatment arms. Denominator model is not pooled.\")\n",
    "    print(\" - Model fitter type: te_stats_glm_logit\")\n",
    "    print(\" - View weight model summaries with show_weight_models()\")\n",
    "    \n",
    "    # Sequence of Trials Data\n",
    "    print(\"\")\n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(\"- Chunk size: 500\")\n",
    "    print(\"- Censor at switch: FALSE\")\n",
    "    print(\"- First period: 0 | Last period: Inf\")\n",
    "    \n",
    "    # TE Datastore\n",
    "    print(\"\")\n",
    "    print(\"A TE Datastore Datatable object\")\n",
    "    print(f\"N: {len(data)*2} observations\")\n",
    "    \n",
    "    display_cols2 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'assigned_treatment', 'x2']\n",
    "    available_cols2 = [col for col in display_cols2 if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 9 + \" \".join([f\"{col:<15}\" for col in available_cols2]))\n",
    "    print(\" \" * 7 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'followup_time'] else 'num':<3}\" for col in available_cols2]) + \">\")\n",
    "    \n",
    "    # Format sample rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols2])\n",
    "        print(\" \" * 4 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\"  ---\" + \" \" * 56)\n",
    "    \n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols2])\n",
    "        print(f\"{len(data)*2-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{len(data)*2}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    # Outcome model\n",
    "    print(\"\")\n",
    "    print(\"Outcome model:\")\n",
    "    print(\"- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time^2) + trial_period + I(trial_period^2)\")\n",
    "    print(\"- Treatment variable: assigned_treatment\")\n",
    "    print(\"- Adjustment variables: x2\")\n",
    "    print(\"- Model fitter type: te_stats_glm_logit\")\n",
    "    \n",
    "    # Model Summary\n",
    "    print(\"\")\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model = trial.outcome_model['fitted_model']\n",
    "    \n",
    "    # Format parameter table\n",
    "    terms = ['(Intercept)', 'assigned_treatment', 'x2', 'followup_time', 'I(followup_time^2)', 'trial_period', 'I(trial_period^2)']\n",
    "    \n",
    "    # Map statsmodels parameter names to display names\n",
    "    param_map = {\n",
    "        'Intercept': '(Intercept)',\n",
    "        'I(followup_time ** 2)': 'I(followup_time^2)',\n",
    "        'I(trial_period ** 2)': 'I(trial_period^2)'\n",
    "    }\n",
    "    \n",
    "    # Remap parameter names\n",
    "    params_index = [param_map.get(p, p) for p in model.params.index]\n",
    "    \n",
    "    print(\" term               estimate std.error statistic p.value conf.low conf.high\")\n",
    "    for term in terms:\n",
    "        # Find the matching parameter\n",
    "        idx = [i for i, p in enumerate(params_index) if p == term]\n",
    "        if idx:\n",
    "            idx = idx[0]\n",
    "            param_name = list(model.params.index)[idx]\n",
    "            est = model.params[param_name]\n",
    "            se = model.bse[param_name]\n",
    "            t = model.tvalues[param_name]\n",
    "            p = model.pvalues[param_name]\n",
    "            ci_low = model.conf_int()[0][param_name]\n",
    "            ci_high = model.conf_int()[1][param_name]\n",
    "            \n",
    "            # Format scientific notation for p-values\n",
    "            if p < 0.001:\n",
    "                p_str = f\"{p:.1e}\"\n",
    "            else:\n",
    "                p_str = f\"{p:.1f}\"\n",
    "                \n",
    "            print(f\" {term:<18} {est:>5.2f}    {se:.3f}      {t:>5.2f}    {p_str} {ci_low:>7.4f}   {ci_high:>7.4f}\")\n",
    "    \n",
    "    # Model fit statistics\n",
    "    null_dev = -2 * model.llnull\n",
    "    deviance = -2 * model.llf\n",
    "    df_null = int(model.df_resid + model.df_model)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f\" null.deviance df.null logLik AIC BIC deviance df.residual nobs\")\n",
    "    print(f\" {null_dev:<13.0f} {df_null:<7d} {model.llf:>6.1f}  {model.aic:>3.0f} {model.bic:>3.0f} {deviance:<8.0f} {int(model.df_resid):<11d} {int(model.nobs):<4d}\")\n",
    "    \n",
    "    # Outcome data section\n",
    "    print(\"\")\n",
    "    print(\"Outcome data\")\n",
    "    print(f\"N: {int(model.nobs)} observations from {data['id'].nunique()} patients in {data['trial_period'].nunique()} trial periods\")\n",
    "    print(f\"Periods: {' '.join(map(str, sorted(data['trial_period'].unique())))}\")\n",
    "    print(\"Sampling control observations with probability: 0.5\")\n",
    "    \n",
    "    # Add 'w' column if not already present\n",
    "    if 'w' not in data.columns:\n",
    "        data['w'] = data['weight'] * data.get('sample_weight', 1)\n",
    "    \n",
    "    display_cols3 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'assigned_treatment', 'x2', 'sample_weight', 'w']\n",
    "    available_cols3 = [col for col in display_cols3 if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 8 + \" \".join([f\"{col:<15}\" for col in available_cols3]))\n",
    "    print(\" \" * 6 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'followup_time'] else 'num':<3}\" for col in available_cols3]) + \">\")\n",
    "    \n",
    "    # Format sample rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols3])\n",
    "        print(\" \" * 3 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\" ---\" + \" \" * 56)\n",
    "    \n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols3])\n",
    "        print(f\"{int(model.nobs)-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{int(model.nobs)}:\" + \" \" * 4 + values)\n",
    "\n",
    "# Run the display function\n",
    "display_trial_itt(trial_itt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-rank test p-value: 0.3873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data_censored.csv')\n",
    "\n",
    "# Create time and event variables\n",
    "df['time'] = df['period']\n",
    "df['event'] = df['outcome'] * (1 - df['censored'])\n",
    "\n",
    "# Split by treatment group\n",
    "treatment_group = df[df['treatment'] == 1]\n",
    "control_group = df[df['treatment'] == 0]\n",
    "\n",
    "# Fit Kaplan-Meier curves to each group\n",
    "kmf_treatment = KaplanMeierFitter()\n",
    "kmf_control = KaplanMeierFitter()\n",
    "\n",
    "kmf_treatment.fit(treatment_group['time'], treatment_group['event'], label='Treatment')\n",
    "kmf_control.fit(control_group['time'], control_group['event'], label='Control')\n",
    "\n",
    "# Create a timeline that includes all observed event times\n",
    "timeline = np.sort(np.unique(np.concatenate([\n",
    "    kmf_treatment.timeline,\n",
    "    kmf_control.timeline\n",
    "])))\n",
    "timeline = timeline[timeline <= 10]  # Limiting to the desired x-axis range\n",
    "\n",
    "# Calculate the survival difference at each time point\n",
    "treatment_survival = kmf_treatment.survival_function_at_times(timeline).values.flatten()\n",
    "control_survival = kmf_control.survival_function_at_times(timeline).values.flatten()\n",
    "survival_diff = treatment_survival - control_survival\n",
    "\n",
    "# Calculate confidence intervals using bootstrapping\n",
    "n_bootstraps = 100\n",
    "bootstrap_diffs = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    # Sample with replacement\n",
    "    treatment_sample = treatment_group.sample(n=len(treatment_group), replace=True)\n",
    "    control_sample = control_group.sample(n=len(control_group), replace=True)\n",
    "    \n",
    "    # Fit KM curves to bootstrap samples\n",
    "    kmf_t = KaplanMeierFitter()\n",
    "    kmf_c = KaplanMeierFitter()\n",
    "    \n",
    "    kmf_t.fit(treatment_sample['time'], treatment_sample['event'])\n",
    "    kmf_c.fit(control_sample['time'], control_sample['event'])\n",
    "    \n",
    "    # Calculate survival at each time point\n",
    "    t_surv = kmf_t.survival_function_at_times(timeline).values.flatten()\n",
    "    c_surv = kmf_c.survival_function_at_times(timeline).values.flatten()\n",
    "    \n",
    "    # Store difference\n",
    "    bootstrap_diffs.append(t_surv - c_surv)\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "ci_lower = np.percentile(bootstrap_diffs, 2.5, axis=0)\n",
    "ci_upper = np.percentile(bootstrap_diffs, 97.5, axis=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the survival difference as a step function\n",
    "plt.step(timeline, survival_diff, 'k-', where='post', label='Survival Difference')\n",
    "\n",
    "# Plot confidence intervals\n",
    "plt.step(timeline, ci_lower, 'r--', where='post', label='95% CI')\n",
    "plt.step(timeline, ci_upper, 'r--', where='post')\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel('Follow up', fontsize=12)\n",
    "plt.ylabel('Survival difference', fontsize=12)\n",
    "plt.ylim(-0.2, 0.05)\n",
    "plt.xlim(0, 10)\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('survival_difference_plot.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Calculate log-rank test\n",
    "results = logrank_test(treatment_group['time'], control_group['time'], \n",
    "                     treatment_group['event'], control_group['event'])\n",
    "print(f\"Log-rank test p-value: {results.p_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
