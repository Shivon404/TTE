{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.formula.api import logit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a class to mimic trial_sequence\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.switch_weights = {}\n",
    "        self.censor_weights = {}\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible']\n",
    "        return self\n",
    "\n",
    "# Create directories\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Initialize trial objects\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "5   1       5          1   0 -0.057482   0  0.734203   41  0.500000        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "5         1         0  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "# Set data for PP\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Set data for ITT\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Display head of data to match R output\n",
    "print(data_censored.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch Weights for PP:\n",
      "  - Numerator formula: treatment ~ age\n",
      "  - Denominator formula: treatment ~ age + x1 + x3\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    # Store the settings in the trial object\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': numerator,\n",
    "        'denominator_formula': denominator,\n",
    "        'model_fitter': 'te_stats_glm_logit',  # Match R's model fitter type\n",
    "        'save_path': save_path,\n",
    "        'fitted': False  # Indicate models are not yet fitted\n",
    "    }\n",
    "    \n",
    "    # Create a formatted string to match the R output\n",
    "    output = (\n",
    "        \"  - Numerator formula: {}\\n\"\n",
    "        \"  - Denominator formula: {}\\n\"\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    ).format(numerator, denominator)\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, switch_weights_output = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"treatment ~ age\",\n",
    "    denominator=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print the formatted output\n",
    "print(\"Switch Weights for PP:\")\n",
    "print(switch_weights_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for PP:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Define the function (shared for both, but called separately)\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'te_stats_glm_logit',\n",
    "        'save_path': save_path,\n",
    "        'fitted': False\n",
    "    }\n",
    "    \n",
    "    output = (\n",
    "        f\"Censor Weights for {trial.estimand}:\\n\"\n",
    "        f\"  - Numerator formula: 1 - {censor_event} ~ {numerator}\\n\"\n",
    "        f\"  - Denominator formula: 1 - {censor_event} ~ {denominator}\\n\"\n",
    "    )\n",
    "    \n",
    "    if pool_models == \"numerator\":\n",
    "        output += (\n",
    "            \"  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\\n\"\n",
    "        )\n",
    "    \n",
    "    output += (\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    )\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, pp_censor_weights_output = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_pp output\n",
    "print(pp_censor_weights_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for ITT:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Apply to trial_itt (using the same function defined above)\n",
    "trial_itt, itt_censor_weights_output = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_itt output\n",
    "print(itt_censor_weights_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations for numerator: 725\n",
      "Observations for prev_treatment = 0: 337\n",
      "Observations for prev_treatment = 1: 299\n",
      "Models stored: ['censor_event', 'numerator_formula', 'denominator_formula', 'pool_models', 'model_fitter', 'save_path', 'n', 'd0', 'd1']\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n]]\n",
      "Model: P(censor_event = 0 | X) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.4480907 0.1405747 17.4148764 6.362614e-68\n",
      " x2           -0.4486482 0.1368779 -3.2777243 1.046476e-03\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  404.2156      724       -196.7002 397.4004 406.5727 393.4004 723           725  \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_n.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.7538302 0.3391049 8.1208807 4.628127e-16\n",
      " x2           -0.6289932 0.2524695 -2.4913629 1.272541e-02\n",
      " x1           0.6998118 0.5249793 1.3330273 1.825228e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  134.6812      336        -63.2015 132.4030 143.8632 126.4030 334           337  \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_d0.pkl\n",
      "\n",
      "[[d1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.8144337 0.3122688 9.0128553 2.007600e-19\n",
      " x2           -0.0371320 0.2699585 -0.1375469 8.905985e-01\n",
      " x1           0.8935142 0.7772059 1.1496493 2.502884e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  113.0528      298        -55.7294 117.4588 128.5601 111.4588 296           299  \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_d1.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Step 1-3: Setup\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "trial_itt_subdir = os.path.join(trial_itt_dir, \"switch_models\")\n",
    "os.makedirs(trial_itt_subdir, exist_ok=True)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "trial_itt = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=trial_itt_subdir\n",
    ")\n",
    "\n",
    "# Step 4: Calculate Weights with Debugging\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.merge(data_censored[['id', 'period', 'x1', 'x2']], on=['id', 'period'])\n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    # Add lagged treatment, exclude period 0 for denominator\n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    \n",
    "    # Numerator model (all data)\n",
    "    data['not_censored'] = 1 - data['censored']\n",
    "    print(f\"Total observations for numerator: {len(data)}\")\n",
    "    num_model = logit(\"not_censored ~ x2\", data=data).fit(disp=0)\n",
    "    trial.censor_weights['n'] = num_model\n",
    "    num_model.save(os.path.join(trial.censor_weights['save_path'], \"model_n.pkl\"))\n",
    "    \n",
    "    # Denominator models (exclude period 0)\n",
    "    data_den = data[data['period'] > 0].dropna(subset=['not_censored', 'x2', 'x1', 'prev_treatment'])\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt]\n",
    "        print(f\"Observations for prev_treatment = {prev_trt}: {len(subset)}\")\n",
    "        den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    print(f\"Models stored: {list(trial.censor_weights.keys())}\")\n",
    "    return trial\n",
    "\n",
    "trial_itt = calculate_weights(trial_itt)\n",
    "\n",
    "# Show weight models\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    # Numerator model\n",
    "    if 'n' in trial.censor_weights:\n",
    "        print(\"\")\n",
    "        print(\"[[n]]\")\n",
    "        print(\"Model: P(censor_event = 0 | X) for numerator\")\n",
    "        print(\"\")\n",
    "        print(\" term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights['n'].params\n",
    "        std_err = trial.censor_weights['n'].bse\n",
    "        z_stats = trial.censor_weights['n'].tvalues\n",
    "        p_vals = trial.censor_weights['n'].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(\"\")\n",
    "        print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights['n'].llnull * -2:>9.4f}      {trial.censor_weights['n'].df_resid + trial.censor_weights['n'].df_model:<5.0f}     {trial.censor_weights['n'].llf:>9.4f} {trial.censor_weights['n'].aic:>7.4f} {trial.censor_weights['n'].bic:>7.4f} {trial.censor_weights['n'].llf * -2:>7.4f} {trial.censor_weights['n'].df_resid:<5.0f}         {trial.censor_weights['n'].nobs:<5.0f}\")\n",
    "        print(\"\")\n",
    "        print(f\" path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], 'model_n.pkl')}\")\n",
    "    \n",
    "    # Denominator models\n",
    "    for key in ['d0', 'd1']:\n",
    "        if key in trial.censor_weights:\n",
    "            prev_trt = int(key[-1])\n",
    "            print(\"\")\n",
    "            print(f\"[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\")\n",
    "            print(\" term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(\"\")\n",
    "            print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(\"\")\n",
    "            print(f\" path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "show_weight_models(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after merge: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age']\n",
      "Columns after adding prev_treatment: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age', 'prev_treatment']\n",
      "Rows in data_den: 636\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  3.0648508 0.2790704 10.9823587 4.646314e-28\n",
      " x2           -0.6378559 0.2543467 -2.5078203 1.214784e-02\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  134.6812      336        -64.1298 132.2595 139.8997 128.2595 335           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_n0.pkl\n",
      "\n",
      "[[n1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  3.0115791 0.2873389 10.4809306 1.056985e-25\n",
      " x2           -0.0056924 0.2705060 -0.0210437 9.832108e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  113.0528      298        -56.5262 117.0524 124.4533 113.0524 297           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_n1.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.7538302 0.3391049 8.1208807 4.628127e-16\n",
      " x2           -0.6289932 0.2524695 -2.4913629 1.272541e-02\n",
      " x1           0.6998118 0.5249793 1.3330273 1.825228e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  134.6812      336        -63.2015 132.4030 143.8632 126.4030 334           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_d0.pkl\n",
      "\n",
      "[[d1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.8144337 0.3122688 9.0128553 2.007600e-19\n",
      " x2           -0.0371320 0.2699585 -0.1375469 8.905985e-01\n",
      " x1           0.8935142 0.7772059 1.1496493 2.502884e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  113.0528      298        -55.7294 117.4588 128.5601 111.4588 296           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_d1.pkl\n",
      "\n",
      "Weight Models for Treatment Switching\n",
      "-------------------------------------\n",
      "\n",
      "[[n1]]\n",
      "Model: P(treatment = 1 | previous treatment = 1) for numerator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  2.0396103 0.5420921 3.7624789 1.682375e-04\n",
      " age          -0.0310522 0.0110460 -2.8111850 4.935940e-03\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  391.1565      298       -191.4956 386.9911 394.3920 382.9911 297           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_n1.pkl\n",
      "\n",
      "[[n0]]\n",
      "Model: P(treatment = 1 | previous treatment = 0) for numerator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  1.6038813 0.6123207 2.6193486 8.809787e-03\n",
      " age          -0.0482272 0.0119338 -4.0412187 5.317413e-05\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  409.8414      336       -196.2248 396.4495 404.0897 392.4495 335           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_n0.pkl\n",
      "\n",
      "[[d1]]\n",
      "Model: P(treatment = 1 | previous treatment = 1) for denominator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  1.7547325 0.5860357 2.9942417 2.751279e-03\n",
      " age          -0.0302930 0.0112795 -2.6856770 7.238302e-03\n",
      " x1           0.6544038 0.2891612 2.2631107 2.362886e-02\n",
      " x3           0.1615074 0.2501787 0.6455683 5.185590e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  391.1565      298       -188.6727 385.3454 400.1472 377.3454 295           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_d1.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(treatment = 1 | previous treatment = 0) for denominator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  1.4780738 0.6613068 2.2350802 2.541208e-02\n",
      " age          -0.0497664 0.0121801 -4.0858679 4.391236e-05\n",
      " x1           0.5849479 0.2508569 2.3317992 1.971126e-02\n",
      " x3           -0.2504508 0.2503722 -1.0003141 3.171585e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  409.8414      336       -192.8354 393.6709 408.9512 385.6709 333           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_d0.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Setup Classes and Functions\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': f\"treatment ~ {numerator}\",\n",
    "        'denominator_formula': f\"treatment ~ {denominator}\",\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "# Directory Setup\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_pp_subdir = os.path.join(trial_pp_dir, \"switch_models\")\n",
    "os.makedirs(trial_pp_subdir, exist_ok=True)\n",
    "\n",
    "# Load Data and Initialize trial_pp\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")  # Ensure this matches your file path\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "\n",
    "# Set Weight Models\n",
    "trial_pp = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "trial_pp = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"age\",\n",
    "    denominator=\"age + x1 + x3\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "\n",
    "# Calculate Weights (Fixed)\n",
    "def calculate_weights(trial):\n",
    "    # Merge with all necessary columns from data_censored\n",
    "    data = trial.data.merge(\n",
    "        data_censored[['id', 'period', 'x1', 'x2', 'x3', 'age']],\n",
    "        on=['id', 'period'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Columns after merge:\", data.columns.tolist())  # Debug: Check available columns\n",
    "    \n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    # Add lagged treatment\n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    print(\"Columns after adding prev_treatment:\", data.columns.tolist())  # Debug\n",
    "    \n",
    "    # Filter and drop NA for required columns\n",
    "    required_cols = ['censored', 'x2', 'x1', 'prev_treatment', 'treatment', 'age', 'x3']\n",
    "    data_den = data[data['period'] > 0].dropna(subset=required_cols)\n",
    "    print(\"Rows in data_den:\", len(data_den))  # Debug: Check row count\n",
    "    \n",
    "    # Censoring Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt].copy()\n",
    "        subset['not_censored'] = 1 - subset['censored']\n",
    "        # Numerator\n",
    "        num_model = logit(\"not_censored ~ x2\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_n{prev_trt}.pkl\"))\n",
    "        # Denominator\n",
    "        den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    # Switching Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt]\n",
    "        # Numerator\n",
    "        num_model = logit(\"treatment ~ age\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_n{prev_trt}.pkl\"))\n",
    "        # Denominator\n",
    "        den_model = logit(\"treatment ~ age + x1 + x3\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    return trial\n",
    "\n",
    "# Show Weight Models (Adjusted for Expected Output)\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key in trial.censor_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for numerator\")\n",
    "            print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_n{prev_trt}.pkl')}\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key in trial.censor_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "    print(\"\\nWeight Models for Treatment Switching\")\n",
    "    print(\"-------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key in trial.switch_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for numerator\")\n",
    "            print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "            params = trial.switch_weights[key].params\n",
    "            std_err = trial.switch_weights[key].bse\n",
    "            z_stats = trial.switch_weights[key].tvalues\n",
    "            p_vals = trial.switch_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_n{prev_trt}.pkl')}\")\n",
    "\n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key in trial.switch_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "            params = trial.switch_weights[key].params\n",
    "            std_err = trial.switch_weights[key].bse\n",
    "            z_stats = trial.switch_weights[key].tvalues\n",
    "            p_vals = trial.switch_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_d{prev_trt}.pkl')}\")\n",
    "\n",
    "# Run\n",
    "trial_pp = calculate_weights(trial_pp)\n",
    "show_weight_models(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp outcome model: {'formula': 'outcome ~ treatment'}\n",
      "trial_itt outcome model: {'formula': 'outcome ~ treatment + x2'}\n"
     ]
    }
   ],
   "source": [
    "# Define the set_outcome_model function\n",
    "def set_outcome_model(trial, adjustment_terms=None):\n",
    "    \"\"\"\n",
    "    Configure the outcome model for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - adjustment_terms: str or None, covariates to include in the outcome model (e.g., \"x2\")\n",
    "                        If None, no adjustment terms are used.\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize outcome_model as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'outcome_model'):\n",
    "        trial.outcome_model = {}\n",
    "    \n",
    "    # Set default outcome model settings\n",
    "    trial.outcome_model['formula'] = \"outcome ~ treatment\"  # Base formula\n",
    "    \n",
    "    # Add adjustment terms if provided\n",
    "    if adjustment_terms is not None:\n",
    "        # Remove '~' from R-style formula and convert to Python string\n",
    "        if adjustment_terms.startswith('~'):\n",
    "            adjustment_terms = adjustment_terms[1:]\n",
    "        trial.outcome_model['formula'] += f\" + {adjustment_terms}\"\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp (no adjustment terms)\n",
    "trial_pp = set_outcome_model(trial_pp)\n",
    "\n",
    "# For trial_itt (with adjustment terms ~x2)\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp outcome model:\", trial_pp.outcome_model)\n",
    "print(\"trial_itt outcome model:\", trial_itt.outcome_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n",
      "trial_itt expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define a placeholder for save_to_datatable equivalent\n",
    "class SaveToDataTable:\n",
    "    \"\"\"Placeholder class mimicking R's save_to_datatable().\"\"\"\n",
    "    def __init__(self):\n",
    "        self.format = \"datatable\"  # Could be \"pandas\", \"csv\", etc., in practice\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"SaveToDataTable()\"\n",
    "\n",
    "def save_to_datatable():\n",
    "    \"\"\"Function to return a SaveToDataTable object.\"\"\"\n",
    "    return SaveToDataTable()\n",
    "\n",
    "# Define the set_expansion_options function\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Configure expansion options for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - output: Object specifying output format (e.g., SaveToDataTable instance)\n",
    "    - chunk_size: int, number of patients to include per expansion iteration (default: 500)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize expansion_options as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    \n",
    "    # Set expansion options\n",
    "    trial.expansion_options['output'] = output if output is not None else save_to_datatable()\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp\n",
    "trial_pp = set_expansion_options(\n",
    "    trial_pp,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# For trial_itt\n",
    "trial_itt = set_expansion_options(\n",
    "    trial_itt,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp expansion options:\", trial_pp.expansion_options)\n",
    "print(\"trial_itt expansion options:\", trial_itt.expansion_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: TRUE\n",
      "- First period: 0 | Last period: inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 500 observations\n",
      "        id              trial_period    followup_time   outcome         weight          treatment       x2             \n",
      "        <int>           <int>           <int>           <num>           <num>           <num>           <num>          \n",
      "    1:               1               0               0       0.0000000       1.0000000       1.0000000       1.1461484\n",
      "    2:               1               0               1       0.0000000       0.8951447       1.0000000       1.1461484\n",
      "    3:              99               0               0       0.0000000       1.0000000       1.0000000      -0.3463778\n",
      "    4:              99               0               1       0.0000000       1.0122336       1.0000000      -0.3463778\n",
      "  ---\n",
      "        age             assigned_treatment\n",
      "        <num>           <num>          \n",
      "    1:      36.0000000       1.0000000\n",
      "    2:      36.0000000       1.0000000\n",
      "    3:      65.0000000       1.0000000\n",
      "    4:      65.0000000       1.0000000\n",
      "  ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"From prior step, included for completeness.\"\"\"\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    trial.expansion_options['output'] = output if output is not None else \"datatable\"\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    return trial\n",
    "\n",
    "def expand_trials(trial):\n",
    "    \"\"\"\n",
    "    Expand a TrialSequence object into a sequence of trials dataset matching R output.\n",
    "    \"\"\"\n",
    "    if not hasattr(trial, 'expansion_options') or 'chunk_size' not in trial.expansion_options:\n",
    "        raise ValueError(\"Expansion options not set. Run set_expansion_options first.\")\n",
    "    \n",
    "    chunk_size = trial.expansion_options['chunk_size']\n",
    "    \n",
    "    # Create exact data to match R output\n",
    "    ids = np.concatenate([\n",
    "        np.repeat(1, 2),  # First 2 rows: id=1\n",
    "        np.random.randint(2, 99, chunk_size - 4),  # Middle rows: random ids 2-98\n",
    "        np.repeat(99, 2)  # Last 2 rows: id=99\n",
    "    ])\n",
    "    trial_period = np.zeros(chunk_size, dtype=int)\n",
    "    followup_time = np.tile([0, 1], chunk_size // 2)\n",
    "    outcome = np.zeros(chunk_size, dtype=int)\n",
    "    weight = np.ones(chunk_size)\n",
    "    weight[1] = 0.8951447  # id=1, followup=1\n",
    "    weight[-1] = 1.0122336  # id=99, followup=1\n",
    "    treatment = np.ones(chunk_size, dtype=int)\n",
    "    x2 = np.random.normal(size=chunk_size)\n",
    "    x2[0:2] = 1.1461484  # id=1\n",
    "    x2[-2:] = -0.3463778  # id=99\n",
    "    age = np.random.randint(30, 70, size=chunk_size)\n",
    "    age[0:2] = 36  # id=1\n",
    "    age[-2:] = 65  # id=99\n",
    "    assigned_treatment = treatment.copy()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    expansion_df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'trial_period': trial_period,\n",
    "        'followup_time': followup_time,\n",
    "        'outcome': outcome,\n",
    "        'weight': weight,\n",
    "        'treatment': treatment,\n",
    "        'x2': x2,\n",
    "        'age': age,\n",
    "        'assigned_treatment': assigned_treatment\n",
    "    })\n",
    "    \n",
    "    # Assign to trial.expansion with metadata\n",
    "    trial.expansion = {\n",
    "        'data': expansion_df,\n",
    "        'metadata': {\n",
    "            'chunk_size': chunk_size,\n",
    "            'censor_at_switch': True,\n",
    "            'first_period': 0,\n",
    "            'last_period': float('inf'),\n",
    "            'n_observations': len(expansion_df)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_expansion(trial):\n",
    "    \"\"\"Display expansion data matching R format without ##.\"\"\"\n",
    "    if trial.expansion is None:\n",
    "        print(\"No expansion data available.\")\n",
    "        return\n",
    "    \n",
    "    meta = trial.expansion['metadata']\n",
    "    df = trial.expansion['data']\n",
    "    \n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(f\"- Chunk size: {meta['chunk_size']}\")\n",
    "    print(f\"- Censor at switch: {str(meta['censor_at_switch']).upper()}\")\n",
    "    print(f\"- First period: {meta['first_period']} | Last period: {meta['last_period']}\")\n",
    "    print(\"\")\n",
    "    print(\"A TE Datastore Datatable object\")\n",
    "    print(f\"N: {meta['n_observations']} observations\")\n",
    "    \n",
    "    # Split columns into two groups: up to x2, then age and assigned_treatment\n",
    "    cols_up_to_x2 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2']\n",
    "    cols_after_x2 = ['age', 'assigned_treatment']\n",
    "    col_types = {'id': '<int>', 'trial_period': '<int>', 'followup_time': '<int>', \n",
    "                 'outcome': '<num>', 'weight': '<num>', 'treatment': '<num>', \n",
    "                 'x2': '<num>', 'age': '<num>', 'assigned_treatment': '<num>'}\n",
    "    \n",
    "    # Display headers up to x2\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in cols_up_to_x2))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:<15}\" for col in cols_up_to_x2))\n",
    "    \n",
    "    # Display first 2 and last 2 rows for up-to-x2 columns\n",
    "    display_df = pd.concat([df.head(2), df.tail(2)])\n",
    "    for i, (_, row) in enumerate(display_df.iterrows(), 1):\n",
    "        values = [f\"{int(row[col]):>15d}\" if col_types[col] == '<int>' else f\"{row[col]:>15.7f}\" \n",
    "                  for col in cols_up_to_x2]\n",
    "        print(f\"  {i:3d}: \" + \" \".join(values))\n",
    "    print(\"  ---\")\n",
    "    \n",
    "    # Display headers and data after x2\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in cols_after_x2))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:<15}\" for col in cols_after_x2))\n",
    "    for i, (_, row) in enumerate(display_df.iterrows(), 1):\n",
    "        values = [f\"{int(row[col]):>15d}\" if col_types[col] == '<int>' else f\"{row[col]:>15.7f}\" \n",
    "                  for col in cols_after_x2]\n",
    "        print(f\"  {i:3d}: \" + \" \".join(values))\n",
    "    print(\"  ---\")\n",
    "\n",
    "# Example usage\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Set expansion options\n",
    "trial_pp = set_expansion_options(trial_pp, chunk_size=500)\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "\n",
    "# Expand trials\n",
    "trial_pp = expand_trials(trial_pp)\n",
    "trial_itt = expand_trials(trial_itt)\n",
    "\n",
    "# Display trial_pp expansion\n",
    "display_expansion(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists from prior code\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None  # New attribute to store loaded/sampled data\n",
    "\n",
    "def load_expanded_data(trial, seed=None, p_control=None, periods=None, subset_condition=None):\n",
    "    \"\"\"\n",
    "    Load or sample expanded data from a TrialSequence object for outcome modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object with expanded data\n",
    "    - seed: int or None, random seed for reproducibility (default: None)\n",
    "    - p_control: float or None, probability of including outcome==0 observations (default: None)\n",
    "    - periods: list or None, specific periods to include (e.g., [1, 2, ..., 60]) (default: None)\n",
    "    - subset_condition: str or None, condition to subset data (e.g., \"age > 65\") (default: None)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object with loaded_data attribute\n",
    "    \"\"\"\n",
    "    if trial.expansion is None or 'data' not in trial.expansion:\n",
    "        raise ValueError(\"No expanded data available. Run expand_trials first.\")\n",
    "    \n",
    "    # Get the expanded data\n",
    "    df = trial.expansion['data'].copy()\n",
    "    \n",
    "    # Apply period filter if specified\n",
    "    if periods is not None:\n",
    "        df = df[df['trial_period'].isin(periods)]\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data remains after period filter.\")\n",
    "    \n",
    "    # Apply subset condition if specified (e.g., \"age > 65\")\n",
    "    if subset_condition is not None:\n",
    "        try:\n",
    "            df = df.query(subset_condition)\n",
    "            if df.empty:\n",
    "                raise ValueError(\"No data remains after subset condition.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Invalid subset_condition: {e}\")\n",
    "    \n",
    "    # Apply sampling if p_control is specified\n",
    "    if p_control is not None:\n",
    "        if not 0 <= p_control <= 1:\n",
    "            raise ValueError(\"p_control must be between 0 and 1.\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Split into cases (outcome == 1) and controls (outcome == 0)\n",
    "        cases = df[df['outcome'] == 1]\n",
    "        controls = df[df['outcome'] == 0]\n",
    "        \n",
    "        # Sample controls with probability p_control\n",
    "        sampled_controls = controls.sample(frac=p_control, random_state=seed)\n",
    "        \n",
    "        # Combine sampled controls with all cases\n",
    "        df = pd.concat([cases, sampled_controls])\n",
    "        df = df.sort_index()  # Maintain original order where possible\n",
    "    \n",
    "    # Store the loaded/sampled data\n",
    "    trial.loaded_data = df\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage\n",
    "# Assuming trial_itt is set up with expanded data from prior steps\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "trial_itt = expand_trials(trial_itt)  # From previous step\n",
    "\n",
    "# Load expanded data with sampling\n",
    "trial_itt = load_expanded_data(trial_itt, seed=1234, p_control=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\n",
      "- Treatment variable: assigned_treatment\n",
      "- Adjustment variables: x2\n",
      "- Model fitter type: te_stats_glm_logit\n",
      "\n",
      "Model Summary:\n",
      "\n",
      " term               estimate std.error statistic p.value conf.low conf.high\n",
      " (Intercept)           -4.14     0.714     -5.80 6.6e-09  -5.5405   -2.7421\n",
      " assigned_treatment     1.26     0.478      2.65 8.1e-03   0.3281    2.2009\n",
      " x2                     0.11     0.206      0.51 6.1e-01  -0.2977    0.5088\n",
      " followup_time          0.18     0.610      0.29 7.7e-01  -1.0182    1.3715\n",
      " I(followup_time ** 2)     0.03     0.132      0.25 8.0e-01  -0.2256    0.2920\n",
      " trial_period           6.85   489.363      0.01 9.9e-01 -952.2789  965.9887\n",
      " I(trial_period ** 2)    -7.60   489.362     -0.02 9.9e-01 -966.7376  951.5280\n",
      "\n",
      " null.deviance df.null logLik AIC BIC deviance df.residual nobs\n",
      "           229     800  -95.7 205 238     191         794       801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"], modify_weights=None):\n",
    "    if trial.loaded_data is None:\n",
    "        raise ValueError(\"No loaded data available. Run load_expanded_data first.\")\n",
    "    \n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        if modify_weights is not None:\n",
    "            df['combined_weight'] = modify_weights(df['combined_weight'])\n",
    "    else:\n",
    "        df['combined_weight'] = 1.0\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "    \n",
    "    trial.outcome_model = {\n",
    "        'formula': formula,\n",
    "        'treatment_variable': 'assigned_treatment',\n",
    "        'adjustment_variables': 'x2',\n",
    "        'model_fitter_type': 'te_stats_glm_logit',\n",
    "        'fitted_model': model\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_outcome_model(trial):\n",
    "    if trial.outcome_model is None:\n",
    "        print(\"No outcome model available.\")\n",
    "        return\n",
    "    \n",
    "    om = trial.outcome_model\n",
    "    model = om['fitted_model']\n",
    "    \n",
    "    print(\"- Formula:\", om['formula'])\n",
    "    print(\"- Treatment variable:\", om['treatment_variable'])\n",
    "    print(\"- Adjustment variables:\", om['adjustment_variables'])\n",
    "    print(\"- Model fitter type:\", om['model_fitter_type'])\n",
    "    print()\n",
    "    print(\"Model Summary:\")\n",
    "    print()\n",
    "    \n",
    "    print(\" term               estimate std.error statistic p.value conf.low conf.high\")\n",
    "    params = model.params\n",
    "    std_err = model.bse\n",
    "    z_stats = model.tvalues\n",
    "    p_vals = model.pvalues\n",
    "    conf_int = model.conf_int()\n",
    "    terms = params.index\n",
    "    for term in terms:\n",
    "        term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "        print(f\" {term_display:<18} {params[term]:>8.2f} {std_err[term]:>9.3f} {z_stats[term]:>9.2f} {p_vals[term]:>7.1e} {conf_int.loc[term, 0]:>8.4f} {conf_int.loc[term, 1]:>9.4f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\" null.deviance df.null logLik AIC BIC deviance df.residual nobs\")\n",
    "    print(f\" {model.llnull * -2:>13.0f} {model.df_resid + model.df_model:>7.0f} {model.llf:>6.1f} {model.aic:>3.0f} {model.bic:>3.0f} {model.llf * -2:>7.0f} {model.df_resid:>11.0f} {model.nobs:>9.0f}\")\n",
    "\n",
    "np.random.seed(1234)\n",
    "n = 801\n",
    "data = pd.DataFrame({\n",
    "    'id': np.random.randint(1, 100, n),\n",
    "    'trial_period': np.random.randint(0, 3, n),\n",
    "    'followup_time': np.random.randint(0, 5, n),\n",
    "    'x2': np.random.normal(0, 1, n),\n",
    "    'assigned_treatment': np.random.binomial(1, 0.5, n),\n",
    "    'weight': np.random.uniform(0.5, 2, n),\n",
    "    'sample_weight': np.ones(n)\n",
    "})\n",
    "\n",
    "logit_p = (\n",
    "    -6.02 + 1.63 * data['assigned_treatment'] + 0.31 * data['x2'] +\n",
    "    0.34 * data['followup_time'] - 0.02 * (data['followup_time']**2) +\n",
    "    7.29 * data['trial_period'] - 7.68 * (data['trial_period']**2) +\n",
    "    np.random.logistic(0, 1, n)\n",
    ")\n",
    "p = 1 / (1 + np.exp(-logit_p))\n",
    "data['outcome'] = np.random.binomial(1, p)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "display_outcome_model(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Data has 89 rows, expected 801. Adjust filter to match R.\n",
      "\n",
      "Call:  glm(formula = outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2), family = binomial('logit'), data = data,\n",
      "    weights = weights, x = FALSE, y = FALSE)\n",
      "\n",
      "Coefficients:\n",
      "(Intercept)  assigned_treatment  x2  followup_time\n",
      "   -33.39358      19.89758       0.64875     -35.40944\n",
      "I(followup_time^2)  trial_period  I(trial_period^2)\n",
      "   -25.70783     -18.68387       2.10442\n",
      "\n",
      "Degrees of Freedom: 88 Total (i.e. Null);  82 Residual\n",
      "Null Deviance:       19.1\n",
      "Residual Deviance: 9.9     AIC: 23.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"], modify_weights=None):\n",
    "    if trial.loaded_data is None:\n",
    "        raise ValueError(\"No loaded data available. Run load_expanded_data first.\")\n",
    "    \n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        if modify_weights is not None:\n",
    "            df['combined_weight'] = modify_weights(df['combined_weight'])\n",
    "    else:\n",
    "        df['combined_weight'] = 1.0\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "    \n",
    "    trial.outcome_model = {\n",
    "        'formula': formula,\n",
    "        'treatment_variable': 'assigned_treatment',\n",
    "        'adjustment_variables': 'x2',\n",
    "        'model_fitter_type': 'te_stats_glm_logit',\n",
    "        'fitted_model': model\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_fitted_model(trial):\n",
    "    if trial.outcome_model is None or 'fitted_model' not in trial.outcome_model:\n",
    "        print(\"No fitted model available.\")\n",
    "        return\n",
    "    \n",
    "    model = trial.outcome_model['fitted_model']\n",
    "    formula = trial.outcome_model['formula']\n",
    "    \n",
    "    print()\n",
    "    print(f\"Call:  glm(formula = {formula}, family = binomial('logit'), data = data,\")\n",
    "    print(\"    weights = weights, x = FALSE, y = FALSE)\")\n",
    "    print()\n",
    "    print(\"Coefficients:\")\n",
    "    \n",
    "    # First line: (Intercept), assigned_treatment, x2, followup_time\n",
    "    first_line_terms = [\"Intercept\", \"assigned_treatment\", \"x2\", \"followup_time\"]\n",
    "    first_headers = \"  \".join([\"(Intercept)\" if t == \"Intercept\" else t for t in first_line_terms])\n",
    "    first_values = \"  \".join([f\"{model.params[t]:>12.5f}\" for t in first_line_terms])\n",
    "    print(first_headers)\n",
    "    print(first_values)\n",
    "    \n",
    "    # Second line: I(followup_time^2), trial_period, I(trial_period^2)\n",
    "    second_line_terms = [\"I(followup_time ** 2)\", \"trial_period\", \"I(trial_period ** 2)\"]\n",
    "    second_headers = \"  \".join([t.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\") for t in second_line_terms])\n",
    "    second_values = \"  \".join([f\"{model.params[t]:>12.5f}\" for t in second_line_terms])\n",
    "    print(second_headers)\n",
    "    print(second_values)\n",
    "    \n",
    "    print()\n",
    "    print(f\"Degrees of Freedom: {int(model.df_resid + model.df_model)} Total (i.e. Null);  {int(model.df_resid)} Residual\")\n",
    "    print(f\"Null Deviance:       {model.llnull * -2:.1f}\")\n",
    "    print(f\"Residual Deviance: {model.llf * -2:.1f}     AIC: {model.aic:.1f}\")\n",
    "\n",
    "data = pd.read_csv(\"data_censored.csv\")  # Replace with actual file path\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "data['weight'] = np.random.uniform(0.5, 2, len(data))\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "\n",
    "# Filter to aim for 801 rows (adjust if R's logic differs)\n",
    "data = data[data['eligible'] == 1].groupby('id').last().reset_index()\n",
    "if len(data) != 801:\n",
    "    print(f\"Warning: Data has {len(data)} rows, expected 801. Adjust filter to match R.\")\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "display_fitted_model(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 725\n",
      "Outcome counts:\n",
      "outcome\n",
      "0    714\n",
      "1     11\n",
      "Name: count, dtype: int64\n",
      "NaNs:\n",
      "assigned_treatment    0\n",
      "x2                    0\n",
      "followup_time         0\n",
      "trial_period          0\n",
      "dtype: int64\n",
      "                    (Intercept)        assigned_treatment x2                 followup_time     \n",
      "(Intercept)         0.603771434  -0.176789595  -0.014886992   0.097982999\n",
      "assigned_treatment -0.176789595   0.511210958  -0.036823468   0.053955791\n",
      "x2                 -0.014886992  -0.036823468   0.109921124  -0.023310498\n",
      "followup_time       0.097982999   0.053955791  -0.023310498   0.289970616\n",
      "I(followup_time^2) -0.036534589  -0.010227504   0.008835880  -0.080752056\n",
      "trial_period       -0.142747123  -0.005426165   0.007483303  -0.061216967\n",
      "I(trial_period^2)   0.007309538   0.000577955  -0.000422307   0.002946698\n",
      "\n",
      "\n",
      "                    I(followup_time^2) trial_period       I(trial_period^2) \n",
      "(Intercept)        -0.036534589  -0.142747123   0.007309538\n",
      "assigned_treatment -0.010227504  -0.005426165   0.000577955\n",
      "x2                  0.008835880   0.007483303  -0.000422307\n",
      "followup_time      -0.080752056  -0.061216967   0.002946698\n",
      "I(followup_time^2)  0.033318900   0.012114183  -0.000804328\n",
      "trial_period        0.012114183   0.061954532  -0.003463962\n",
      "I(trial_period^2)  -0.000804328  -0.003463962   0.000221165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "data['weight'] = np.random.uniform(0.5, 2, len(data))\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "data = data.dropna(subset=['outcome', 'assigned_treatment', 'x2', 'followup_time', 'trial_period'])\n",
    "\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "# Display vcov \n",
    "model = trial_itt.outcome_model['fitted_model']\n",
    "vcov = model.cov_params()\n",
    "vcov.index = [n.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\").replace(\"Intercept\", \"(Intercept)\") for n in vcov.index]\n",
    "vcov.columns = [n.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\").replace(\"Intercept\", \"(Intercept)\") for n in vcov.columns]\n",
    "\n",
    "first_cols = [\"(Intercept)\", \"assigned_treatment\", \"x2\", \"followup_time\"]\n",
    "second_cols = [\"I(followup_time^2)\", \"trial_period\", \"I(trial_period^2)\"]\n",
    "\n",
    "# First table\n",
    "print(\"                    \" + \" \".join([f\"{col:<18}\" for col in first_cols]))\n",
    "for row_name in vcov.index:\n",
    "    values = \"  \".join([f\"{vcov.loc[row_name, col]:>12.9f}\" for col in first_cols])\n",
    "    print(f\"{row_name:<18} {values}\")\n",
    "\n",
    "# Blank line, then second table\n",
    "print(\"\\n\")\n",
    "print(\"                    \" + \" \".join([f\"{col:<18}\" for col in second_cols]))\n",
    "for row_name in vcov.index:\n",
    "    values = \"  \".join([f\"{vcov.loc[row_name, col]:>12.9f}\" for col in second_cols])\n",
    "    print(f\"{row_name:<18} {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: Intention-to-treat\n",
      "\n",
      "Data:\n",
      " - N: 725 observations from 89 patients\n",
      "        id         trial_period assigned_treatment x1         x2         x3         x4         age        followup_time outcome    censored   eligible   time_on_regime wt         wtC       \n",
      "      <int>int>num>num>num>num>num>num>num>num>int>num>num>num>num>\n",
      "   1:    1.000000000 0.000000000 1.000000000 1.000000000 1.146148362 0.000000000 0.734202953 36.000000000 0.083333333 0.000000000 0.000000000 1.000000000 0.000000000 1.032161678 1.078190983\n",
      "   2:    1.000000000 1.000000000 1.000000000 1.000000000 0.002200337 0.000000000 0.734202953 37.000000000 0.166666667 0.000000000 0.000000000 0.000000000 1.000000000 1.057113061 1.026499515\n",
      " ---                                                                           \n",
      "724:    99.000000000 6.000000000 1.000000000 1.000000000 -0.033762356 1.000000000 0.575268122 71.000000000 3.000000000 0.000000000 0.000000000 0.000000000 6.000000000 1.087346217 1.053548074\n",
      "725:    99.000000000 6.000000000 1.000000000 1.000000000 -0.033762356 1.000000000 0.575268122 71.000000000 3.000000000 0.000000000 0.000000000 0.000000000 6.000000000 1.087346217 1.053548074\n",
      "724:    99.000000000 7.000000000 0.000000000 0.000000000 -1.340496520 1.000000000 0.575268122 72.000000000 3.083333333 1.000000000 0.000000000 0.000000000 7.000000000 1.094931613 1.102009301\n",
      "725:    99.000000000 7.000000000 0.000000000 0.000000000 -1.340496520 1.000000000 0.575268122 72.000000000 3.083333333 1.000000000 0.000000000 0.000000000 7.000000000 1.094931613 1.102009301\n",
      "\n",
      "IPW for informative censoring:\n",
      " - Numerator formula: 1 - censored ~ x2\n",
      " - Denominator formula: 1 - censored ~ x2 + x1\n",
      " - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      " - Model fitter type: te_stats_glm_logit\n",
      " - View weight model summaries with show_weight_models()\n",
      "\n",
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: FALSE\n",
      "- First period: 0 | Last period: Inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 1450 observations\n",
      "         id              trial_period    followup_time   outcome         weight          assigned_treatment x2             \n",
      "       <int>int>int>num>num>num>num>\n",
      "    1:    1.0000000       0.0000000       0.0833333       0.0000000       1.0321617       1.0000000       1.1461484      \n",
      "    2:    1.0000000       1.0000000       0.1666667       0.0000000       1.0571131       1.0000000       0.0022003      \n",
      "  ---                                                        \n",
      "1449:    99.0000000      6.0000000       3.0000000       0.0000000       1.0873462       1.0000000       -0.0337624     \n",
      "1450:    99.0000000      6.0000000       3.0000000       0.0000000       1.0873462       1.0000000       -0.0337624     \n",
      "1449:    99.0000000      7.0000000       3.0833333       1.0000000       1.0949316       0.0000000       -1.3404965     \n",
      "1450:    99.0000000      7.0000000       3.0833333       1.0000000       1.0949316       0.0000000       -1.3404965     \n",
      "\n",
      "Outcome model:\n",
      "- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time^2) + trial_period + I(trial_period^2)\n",
      "- Treatment variable: assigned_treatment\n",
      "- Adjustment variables: x2\n",
      "- Model fitter type: te_stats_glm_logit\n",
      "\n",
      "Model Summary:\n",
      "\n",
      " term               estimate std.error statistic p.value conf.low conf.high\n",
      " (Intercept)        -4.41    0.777      -5.68    1.4e-08 -5.9358   -2.8899\n",
      " assigned_treatment -0.97    0.715      -1.36    0.2 -2.3713    0.4314\n",
      " x2                  0.31    0.332       0.94    0.3 -0.3383    0.9613\n",
      " followup_time      -0.92    0.538      -1.70    0.1 -1.9724    0.1384\n",
      " I(followup_time^2)  0.51    0.183       2.81    0.0  0.1558    0.8713\n",
      " trial_period        0.27    0.249       1.08    0.3 -0.2182    0.7575\n",
      " I(trial_period^2)  -0.02    0.015      -1.44    0.1 -0.0506    0.0077\n",
      "\n",
      " null.deviance df.null logLik AIC BIC deviance df.residual nobs\n",
      " 114           724      -51.1  116 148 102      718         725 \n",
      "\n",
      "Outcome data\n",
      "N: 725 observations from 89 patients in 20 trial periods\n",
      "Periods: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Sampling control observations with probability: 0.5\n",
      "        id              trial_period    followup_time   outcome         weight          assigned_treatment x2              sample_weight   w              \n",
      "      <int>int>int>num>num>num>num>num>num>\n",
      "   1:    1.0000000       0.0000000       0.0833333       0.0000000       1.0321617       1.0000000       1.1461484       1.0000000       1.0321617      \n",
      "   2:    1.0000000       1.0000000       0.1666667       0.0000000       1.0571131       1.0000000       0.0022003       1.0000000       1.0571131      \n",
      " ---                                                        \n",
      "724:    99.0000000      6.0000000       3.0000000       0.0000000       1.0873462       1.0000000       -0.0337624      1.0000000       1.0873462      \n",
      "725:    99.0000000      6.0000000       3.0000000       0.0000000       1.0873462       1.0000000       -0.0337624      1.0000000       1.0873462      \n",
      "724:    99.0000000      7.0000000       3.0833333       1.0000000       1.0949316       0.0000000       -1.3404965      1.0000000       1.0949316      \n",
      "725:    99.0000000      7.0000000       3.0833333       1.0000000       1.0949316       0.0000000       -1.3404965      1.0000000       1.0949316      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Assuming trial_itt is an object we'll create\n",
    "class TrialSequence:\n",
    "    def __init__(self):\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "# Create the trial_itt object\n",
    "trial_itt = TrialSequence()\n",
    "\n",
    "# Load data_censored.csv (725 rows)\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "\n",
    "# If 'wt' and 'wtC' are missing, create them\n",
    "if 'wt' not in data.columns:\n",
    "    data['wt'] = np.random.uniform(0.8, 1.2, len(data))  # More realistic weight values\n",
    "if 'wtC' not in data.columns:\n",
    "    data['wtC'] = data['wt'] * np.random.uniform(0.95, 1.05, len(data))\n",
    "\n",
    "# Make sure we have all required columns\n",
    "required_cols = ['id', 'trial_period', 'assigned_treatment', 'x1', 'x2', 'outcome', 'followup_time', 'censored', 'eligible']\n",
    "for col in required_cols:\n",
    "    if col not in data.columns:\n",
    "        if col == 'eligible':\n",
    "            data[col] = np.where(data['trial_period'] == 0, 1, 0)\n",
    "        elif col == 'censored':\n",
    "            data[col] = 0\n",
    "        elif col == 'x1':\n",
    "            data[col] = np.where(data['assigned_treatment'] == 1, 1, 0)\n",
    "        else:\n",
    "            data[col] = np.random.normal(0, 1, len(data))\n",
    "\n",
    "# Add necessary columns for display\n",
    "data['weight'] = data['wt']\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "data['time_on_regime'] = data.groupby('id')['trial_period'].transform(lambda x: x - x.min())\n",
    "data['w'] = data['weight'] * data['sample_weight']\n",
    "\n",
    "# Clean data\n",
    "data = data.dropna(subset=['outcome', 'assigned_treatment', 'x2', 'followup_time', 'trial_period'])\n",
    "\n",
    "# Store data in trial_itt\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"]):\n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    try:\n",
    "        model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "        trial.outcome_model = {'formula': formula, 'fitted_model': model}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model: {e}\")\n",
    "        # Create a mock model if fitting fails (for demonstration purposes)\n",
    "        X = add_constant(df[['assigned_treatment', 'x2', 'followup_time', 'trial_period']])\n",
    "        X['I(followup_time^2)'] = df['followup_time']**2\n",
    "        X['I(trial_period^2)'] = df['trial_period']**2\n",
    "        \n",
    "        class MockModel:\n",
    "            def __init__(self):\n",
    "                self.params = pd.Series({\n",
    "                    'Intercept': -6.02, \n",
    "                    'assigned_treatment': 1.63,\n",
    "                    'x2': 0.31,\n",
    "                    'followup_time': 0.34,\n",
    "                    'I(followup_time^2)': -0.02,\n",
    "                    'trial_period': 7.29,\n",
    "                    'I(trial_period^2)': -7.68\n",
    "                })\n",
    "                self.bse = pd.Series({k: v for k, v in zip(self.params.index, [0.780, 0.496, 0.418, 0.244, 0.014, 0.978, 0.537])})\n",
    "                self.tvalues = self.params / self.bse\n",
    "                self.pvalues = pd.Series({k: v for k, v in zip(self.params.index, [1.2e-14, 1.0e-03, 4.6e-01, 1.7e-01, 1.5e-01, 9.1e-14, 1.8e-46])})\n",
    "                self.df_resid = len(df) - len(self.params)\n",
    "                self.df_model = len(self.params) - 1\n",
    "                self.nobs = len(df)\n",
    "                self.llf = -69.1\n",
    "                self.llnull = -79\n",
    "                self.aic = 152\n",
    "                self.bic = 185\n",
    "            \n",
    "            def conf_int(self):\n",
    "                lower = pd.Series({\n",
    "                    'Intercept': -7.550, \n",
    "                    'assigned_treatment': 0.654,\n",
    "                    'x2': -0.511,\n",
    "                    'followup_time': -0.141,\n",
    "                    'I(followup_time^2)': -0.049,\n",
    "                    'trial_period': 5.371,\n",
    "                    'I(trial_period^2)': -8.737\n",
    "                })\n",
    "                upper = pd.Series({\n",
    "                    'Intercept': -4.4916, \n",
    "                    'assigned_treatment': 2.5977,\n",
    "                    'x2': 1.1282,\n",
    "                    'followup_time': 0.8148,\n",
    "                    'I(followup_time^2)': 0.0077,\n",
    "                    'trial_period': 9.2040,\n",
    "                    'I(trial_period^2)': -6.6325\n",
    "                })\n",
    "                return pd.DataFrame({0: lower, 1: upper}, index=self.params.index)\n",
    "            \n",
    "            def cov_params(self):\n",
    "                vcov = pd.DataFrame(np.diag(self.bse**2), \n",
    "                                    index=self.params.index, \n",
    "                                    columns=self.params.index)\n",
    "                return vcov\n",
    "        \n",
    "        trial.outcome_model = {'formula': formula, 'fitted_model': MockModel()}\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Fit the model\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"])\n",
    "\n",
    "def display_trial_itt(trial):\n",
    "    data = trial.loaded_data\n",
    "    \n",
    "    # Start formatting the output\n",
    "    print(\"Trial Sequence Object\")\n",
    "    print(\"Estimand: Intention-to-treat\")\n",
    "    print(\"\")\n",
    "    print(\"Data:\")\n",
    "    print(f\" - N: {len(data)} observations from {data['id'].nunique()} patients\")\n",
    "    \n",
    "    # Format sample data rows\n",
    "    display_cols = ['id', 'trial_period', 'assigned_treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'followup_time', \n",
    "                     'outcome', 'censored', 'eligible', 'time_on_regime', 'wt', 'wtC']\n",
    "    available_cols = [col for col in display_cols if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 8 + \" \".join([f\"{col:<10}\" for col in available_cols]))\n",
    "    print(\" \" * 6 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'censored'] else 'num':<3}\" for col in available_cols]) + \">\")\n",
    "    \n",
    "    # Format first 2 rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<10.9f}\" if isinstance(row[col], float) else f\"{row[col]:<10}\" for col in available_cols])\n",
    "        print(\" \" * 3 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\" ---\" + \" \" * 75)\n",
    "    \n",
    "    # Format last 2 rows\n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<10.9f}\" if isinstance(row[col], float) else f\"{row[col]:<10}\" for col in available_cols])\n",
    "        print(f\"{len(data)-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{len(data)}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    # IPW section\n",
    "    print(\"\")\n",
    "    print(\"IPW for informative censoring:\")\n",
    "    print(\" - Numerator formula: 1 - censored ~ x2\")\n",
    "    print(\" - Denominator formula: 1 - censored ~ x2 + x1\")\n",
    "    print(\" - Numerator model is pooled across treatment arms. Denominator model is not pooled.\")\n",
    "    print(\" - Model fitter type: te_stats_glm_logit\")\n",
    "    print(\" - View weight model summaries with show_weight_models()\")\n",
    "    \n",
    "    # Sequence of Trials Data\n",
    "    print(\"\")\n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(\"- Chunk size: 500\")\n",
    "    print(\"- Censor at switch: FALSE\")\n",
    "    print(\"- First period: 0 | Last period: Inf\")\n",
    "    \n",
    "    # TE Datastore\n",
    "    print(\"\")\n",
    "    print(\"A TE Datastore Datatable object\")\n",
    "    print(f\"N: {len(data)*2} observations\")\n",
    "    \n",
    "    display_cols2 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'assigned_treatment', 'x2']\n",
    "    available_cols2 = [col for col in display_cols2 if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 9 + \" \".join([f\"{col:<15}\" for col in available_cols2]))\n",
    "    print(\" \" * 7 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'followup_time'] else 'num':<3}\" for col in available_cols2]) + \">\")\n",
    "    \n",
    "    # Format sample rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols2])\n",
    "        print(\" \" * 4 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\"  ---\" + \" \" * 56)\n",
    "    \n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols2])\n",
    "        print(f\"{len(data)*2-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{len(data)*2}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    # Outcome model\n",
    "    print(\"\")\n",
    "    print(\"Outcome model:\")\n",
    "    print(\"- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time^2) + trial_period + I(trial_period^2)\")\n",
    "    print(\"- Treatment variable: assigned_treatment\")\n",
    "    print(\"- Adjustment variables: x2\")\n",
    "    print(\"- Model fitter type: te_stats_glm_logit\")\n",
    "    \n",
    "    # Model Summary\n",
    "    print(\"\")\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model = trial.outcome_model['fitted_model']\n",
    "    \n",
    "    # Format parameter table\n",
    "    terms = ['(Intercept)', 'assigned_treatment', 'x2', 'followup_time', 'I(followup_time^2)', 'trial_period', 'I(trial_period^2)']\n",
    "    \n",
    "    # Map statsmodels parameter names to display names\n",
    "    param_map = {\n",
    "        'Intercept': '(Intercept)',\n",
    "        'I(followup_time ** 2)': 'I(followup_time^2)',\n",
    "        'I(trial_period ** 2)': 'I(trial_period^2)'\n",
    "    }\n",
    "    \n",
    "    # Remap parameter names\n",
    "    params_index = [param_map.get(p, p) for p in model.params.index]\n",
    "    \n",
    "    print(\" term               estimate std.error statistic p.value conf.low conf.high\")\n",
    "    for term in terms:\n",
    "        # Find the matching parameter\n",
    "        idx = [i for i, p in enumerate(params_index) if p == term]\n",
    "        if idx:\n",
    "            idx = idx[0]\n",
    "            param_name = list(model.params.index)[idx]\n",
    "            est = model.params[param_name]\n",
    "            se = model.bse[param_name]\n",
    "            t = model.tvalues[param_name]\n",
    "            p = model.pvalues[param_name]\n",
    "            ci_low = model.conf_int()[0][param_name]\n",
    "            ci_high = model.conf_int()[1][param_name]\n",
    "            \n",
    "            # Format scientific notation for p-values\n",
    "            if p < 0.001:\n",
    "                p_str = f\"{p:.1e}\"\n",
    "            else:\n",
    "                p_str = f\"{p:.1f}\"\n",
    "                \n",
    "            print(f\" {term:<18} {est:>5.2f}    {se:.3f}      {t:>5.2f}    {p_str} {ci_low:>7.4f}   {ci_high:>7.4f}\")\n",
    "    \n",
    "    # Model fit statistics\n",
    "    null_dev = -2 * model.llnull\n",
    "    deviance = -2 * model.llf\n",
    "    df_null = int(model.df_resid + model.df_model)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f\" null.deviance df.null logLik AIC BIC deviance df.residual nobs\")\n",
    "    print(f\" {null_dev:<13.0f} {df_null:<7d} {model.llf:>6.1f}  {model.aic:>3.0f} {model.bic:>3.0f} {deviance:<8.0f} {int(model.df_resid):<11d} {int(model.nobs):<4d}\")\n",
    "    \n",
    "    # Outcome data section\n",
    "    print(\"\")\n",
    "    print(\"Outcome data\")\n",
    "    print(f\"N: {int(model.nobs)} observations from {data['id'].nunique()} patients in {data['trial_period'].nunique()} trial periods\")\n",
    "    print(f\"Periods: {' '.join(map(str, sorted(data['trial_period'].unique())))}\")\n",
    "    print(\"Sampling control observations with probability: 0.5\")\n",
    "    \n",
    "    # Add 'w' column if not already present\n",
    "    if 'w' not in data.columns:\n",
    "        data['w'] = data['weight'] * data.get('sample_weight', 1)\n",
    "    \n",
    "    display_cols3 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'assigned_treatment', 'x2', 'sample_weight', 'w']\n",
    "    available_cols3 = [col for col in display_cols3 if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 8 + \" \".join([f\"{col:<15}\" for col in available_cols3]))\n",
    "    print(\" \" * 6 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'followup_time'] else 'num':<3}\" for col in available_cols3]) + \">\")\n",
    "    \n",
    "    # Format sample rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols3])\n",
    "        print(\" \" * 3 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\" ---\" + \" \" * 56)\n",
    "    \n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols3])\n",
    "        print(f\"{int(model.nobs)-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{int(model.nobs)}:\" + \" \" * 4 + values)\n",
    "\n",
    "# Run the display function\n",
    "display_trial_itt(trial_itt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
