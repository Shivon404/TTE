{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Trial Emulation in R to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.formula.api import logit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a class to mimic trial_sequence\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.switch_weights = {}\n",
    "        self.censor_weights = {}\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible']\n",
    "        return self\n",
    "\n",
    "# Create directories\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Initialize trial objects\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment        x1        x2         x3  x4  age  age_s  \\\n",
      "0   1       3          1  6.220560  1.732742  37.700637   0   40   1600   \n",
      "1   2      29          0  0.125014 -4.561390  45.335189   1   40   1600   \n",
      "2   3      35          0  3.501642 -2.902261  44.436428   0   32   1024   \n",
      "3   4      18          1  0.280436 -0.110632  34.773011   1   31    961   \n",
      "4   5      20          0  6.164915 -0.579350  51.443649   1   70   4900   \n",
      "5   6      23          0  4.631583 -4.735344  44.272844   0   61   3721   \n",
      "\n",
      "   outcome  censored  eligible  \n",
      "0        0         1         1  \n",
      "1        0         0         1  \n",
      "2        0         0         0  \n",
      "3        0         0         1  \n",
      "4        1         1         1  \n",
      "5        0         1         1  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "# Set data for PP\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Set data for ITT\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Display head of data to match R output\n",
    "print(data_censored.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weight models and censoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Censoring due to treatment switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch Weights for PP:\n",
      "  - Numerator formula: treatment ~ age\n",
      "  - Denominator formula: treatment ~ age + x1 + x3\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    # Store the settings in the trial object\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': numerator,\n",
    "        'denominator_formula': denominator,\n",
    "        'model_fitter': 'te_stats_glm_logit',  # Match R's model fitter type\n",
    "        'save_path': save_path,\n",
    "        'fitted': False  # Indicate models are not yet fitted\n",
    "    }\n",
    "    \n",
    "    # Create a formatted string to match the R output\n",
    "    output = (\n",
    "        \"  - Numerator formula: {}\\n\"\n",
    "        \"  - Denominator formula: {}\\n\"\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    ).format(numerator, denominator)\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, switch_weights_output = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"treatment ~ age\",\n",
    "    denominator=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print the formatted output\n",
    "print(\"Switch Weights for PP:\")\n",
    "print(switch_weights_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Other informative censoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for Per-protocol:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Define the function (shared for both, but called separately)\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'te_stats_glm_logit',\n",
    "        'save_path': save_path,\n",
    "        'fitted': False\n",
    "    }\n",
    "    \n",
    "    output = (\n",
    "        f\"Censor Weights for {trial.estimand}:\\n\"\n",
    "        f\"  - Numerator formula: 1 - {censor_event} ~ {numerator}\\n\"\n",
    "        f\"  - Denominator formula: 1 - {censor_event} ~ {denominator}\\n\"\n",
    "    )\n",
    "    \n",
    "    if pool_models == \"numerator\":\n",
    "        output += (\n",
    "            \"  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\\n\"\n",
    "        )\n",
    "    \n",
    "    output += (\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    )\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, pp_censor_weights_output = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_pp output\n",
    "print(pp_censor_weights_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for Intention-to-treat:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Apply to trial_itt (using the same function defined above)\n",
    "trial_itt, itt_censor_weights_output = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_itt output\n",
    "print(itt_censor_weights_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations for numerator: 1000\n",
      "Observations for prev_treatment = 0: 0\n",
      "Warning: Insufficient data for prev_treatment = 0. Skipping model fitting.\n",
      "Using numerator model as fallback for prev_treatment = 0\n",
      "Observations for prev_treatment = 1: 0\n",
      "Warning: Insufficient data for prev_treatment = 1. Skipping model fitting.\n",
      "Using numerator model as fallback for prev_treatment = 1\n",
      "Models stored: ['censor_event', 'numerator_formula', 'denominator_formula', 'pool_models', 'model_fitter', 'save_path', 'n', 'd0', 'd1']\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n]]\n",
      "Model: P(censor_event = 0 | X) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  0.4315124 0.0647561 6.6636614 2.670883e-11\n",
      " x2           -0.0137378 0.0225430 -0.6094047 5.422562e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      " 1341.0075      999       -670.3180 1344.6359 1354.4514 1340.6359 998           1000 \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_n.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      "\n",
      " Note: Using numerator model as fallback due to insufficient data\n",
      "\n",
      "[[d1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      "\n",
      " Note: Using numerator model as fallback due to insufficient data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Step 1-3: Setup\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "trial_itt_subdir = os.path.join(trial_itt_dir, \"switch_models\")\n",
    "os.makedirs(trial_itt_subdir, exist_ok=True)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "trial_itt = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=trial_itt_subdir\n",
    ")\n",
    "\n",
    "# Step 4: Calculate Weights with Debugging\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.merge(data_censored[['id', 'period', 'x1', 'x2']], on=['id', 'period'])\n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    # Add lagged treatment, exclude period 0 for denominator\n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    \n",
    "    # Numerator model (all data)\n",
    "    data['not_censored'] = 1 - data['censored']\n",
    "    print(f\"Total observations for numerator: {len(data)}\")\n",
    "    num_model = logit(\"not_censored ~ x2\", data=data).fit(disp=0)\n",
    "    trial.censor_weights['n'] = num_model\n",
    "    num_model.save(os.path.join(trial.censor_weights['save_path'], \"model_n.pkl\"))\n",
    "    \n",
    "    # Denominator models (exclude period 0)\n",
    "    data_den = data[data['period'] > 0].dropna(subset=['not_censored', 'x2', 'x1', 'prev_treatment'])\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt]\n",
    "        print(f\"Observations for prev_treatment = {prev_trt}: {len(subset)}\")\n",
    "        \n",
    "        # Check if the subset has enough data to fit a model\n",
    "        if len(subset) > 0 and subset['not_censored'].nunique() > 1:\n",
    "            den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "            trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "            den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "        else:\n",
    "            print(f\"Warning: Insufficient data for prev_treatment = {prev_trt}. Skipping model fitting.\")\n",
    "            # If we can't fit a model for this subset, use the numerator model as a fallback\n",
    "            if 'n' in trial.censor_weights:\n",
    "                print(f\"Using numerator model as fallback for prev_treatment = {prev_trt}\")\n",
    "                trial.censor_weights[f'd{prev_trt}'] = trial.censor_weights['n']\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    print(f\"Models stored: {list(trial.censor_weights.keys())}\")\n",
    "    return trial\n",
    "\n",
    "trial_itt = calculate_weights(trial_itt)\n",
    "\n",
    "# Show weight models\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    # Numerator model\n",
    "    if 'n' in trial.censor_weights:\n",
    "        print(\"\")\n",
    "        print(\"[[n]]\")\n",
    "        print(\"Model: P(censor_event = 0 | X) for numerator\")\n",
    "        print(\"\")\n",
    "        print(\" term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights['n'].params\n",
    "        std_err = trial.censor_weights['n'].bse\n",
    "        z_stats = trial.censor_weights['n'].tvalues\n",
    "        p_vals = trial.censor_weights['n'].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(\"\")\n",
    "        print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights['n'].llnull * -2:>9.4f}      {trial.censor_weights['n'].df_resid + trial.censor_weights['n'].df_model:<5.0f}     {trial.censor_weights['n'].llf:>9.4f} {trial.censor_weights['n'].aic:>7.4f} {trial.censor_weights['n'].bic:>7.4f} {trial.censor_weights['n'].llf * -2:>7.4f} {trial.censor_weights['n'].df_resid:<5.0f}         {trial.censor_weights['n'].nobs:<5.0f}\")\n",
    "        print(\"\")\n",
    "        print(f\" path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], 'model_n.pkl')}\")\n",
    "    \n",
    "    # Denominator models\n",
    "    for key in ['d0', 'd1']:\n",
    "        if key in trial.censor_weights:\n",
    "            prev_trt = int(key[-1])\n",
    "            print(\"\")\n",
    "            print(f\"[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\")\n",
    "            \n",
    "            # Check if this is a reference to the numerator model (fallback case)\n",
    "            if trial.censor_weights[key] is trial.censor_weights['n']:\n",
    "                print(f\" Note: Using numerator model as fallback due to insufficient data\")\n",
    "                continue\n",
    "                \n",
    "            print(\" term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(\"\")\n",
    "            print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(\"\")\n",
    "            print(f\" path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "show_weight_models(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in data_censored: ['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s', 'outcome', 'censored', 'eligible']\n",
      "Columns after merge: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age']\n",
      "Columns after adding prev_treatment: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age', 'prev_treatment']\n",
      "Required columns after checking availability: ['censored', 'x2', 'x1', 'prev_treatment', 'treatment', 'age', 'x3']\n",
      "Shape of data_den: (0, 11)\n",
      "Missing values in data_den:\n",
      " censored          0\n",
      "x2                0\n",
      "x1                0\n",
      "prev_treatment    0\n",
      "treatment         0\n",
      "age               0\n",
      "x3                0\n",
      "dtype: int64\n",
      "Unique prev_treatment values: []\n",
      "Rows in subset for prev_trt=0: 0\n",
      "Skipping censoring models for prev_trt=0 due to no data\n",
      "Rows in subset for prev_trt=1: 0\n",
      "Skipping censoring models for prev_trt=1 due to no data\n",
      "Rows in subset for prev_trt=0: 0\n",
      "Skipping switching models for prev_trt=0 due to no data\n",
      "Rows in subset for prev_trt=1: 0\n",
      "Skipping switching models for prev_trt=1 due to no data\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n0]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 0) for numerator (empty subset)\n",
      "\n",
      "[[n1]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 1) for numerator (empty subset)\n",
      "\n",
      "[[d0]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 0) for denominator (empty subset)\n",
      "\n",
      "[[d1]]\n",
      "No model fitted for P(censor_event = 0 | X, previous treatment = 1) for denominator (empty subset)\n",
      "\n",
      "Weight Models for Treatment Switching\n",
      "-------------------------------------\n",
      "\n",
      "[[n1]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 1) for numerator (empty subset)\n",
      "\n",
      "[[n0]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 0) for numerator (empty subset)\n",
      "\n",
      "[[d1]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 1) for denominator (empty subset)\n",
      "\n",
      "[[d0]]\n",
      "No model fitted for P(treatment = 1 | previous treatment = 0) for denominator (empty subset)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Setup Classes and Functions\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': f\"treatment ~ {numerator}\",\n",
    "        'denominator_formula': f\"treatment ~ {denominator}\",\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "# Directory Setup\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_pp_subdir = os.path.join(trial_pp_dir, \"switch_models\")\n",
    "os.makedirs(trial_pp_subdir, exist_ok=True)\n",
    "\n",
    "# Load Data and Initialize trial_pp\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")  # Ensure this matches your file path\n",
    "print(f\"Available columns in data_censored: {data_censored.columns.tolist()}\")  # Debug\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "\n",
    "# Set Weight Models\n",
    "trial_pp = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "trial_pp = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"age\",\n",
    "    denominator=\"age + x1 + x3\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.merge(\n",
    "        data_censored[['id', 'period', 'x1', 'x2', 'x3', 'age']],\n",
    "        on=['id', 'period'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Columns after merge:\", data.columns.tolist())\n",
    "    \n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    print(\"Columns after adding prev_treatment:\", data.columns.tolist())\n",
    "    \n",
    "    required_cols = [col for col in ['censored', 'x2', 'x1', 'prev_treatment', 'treatment', 'age', 'x3'] if col in data.columns]\n",
    "    print(f\"Required columns after checking availability: {required_cols}\")\n",
    "    data_den = data[data['period'] > 0].dropna(subset=required_cols)\n",
    "    print(\"Shape of data_den:\", data_den.shape)\n",
    "    print(\"Missing values in data_den:\\n\", data_den[required_cols].isna().sum())\n",
    "    print(\"Unique prev_treatment values:\", data_den['prev_treatment'].unique())\n",
    "    \n",
    "    # Censoring Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt].copy()\n",
    "        print(f\"Rows in subset for prev_trt={prev_trt}:\", len(subset))\n",
    "        if subset.empty:\n",
    "            print(f\"Skipping censoring models for prev_trt={prev_trt} due to no data\")\n",
    "            trial.censor_weights[f'n{prev_trt}'] = None\n",
    "            trial.censor_weights[f'd{prev_trt}'] = None\n",
    "            continue\n",
    "        subset['not_censored'] = 1 - subset['censored']\n",
    "        num_model = logit(\"not_censored ~ x2\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_n{prev_trt}.pkl\"))\n",
    "        den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    # Switching Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt].copy()\n",
    "        print(f\"Rows in subset for prev_trt={prev_trt}:\", len(subset))\n",
    "        if subset.empty:\n",
    "            print(f\"Skipping switching models for prev_trt={prev_trt} due to no data\")\n",
    "            trial.switch_weights[f'n{prev_trt}'] = None\n",
    "            trial.switch_weights[f'd{prev_trt}'] = None\n",
    "            continue\n",
    "        num_model = logit(\"treatment ~ age\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_n{prev_trt}.pkl\"))\n",
    "        den_model = logit(\"treatment ~ age + x1 + x3\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    return trial\n",
    "\n",
    "# Show Weight Models (Adjusted for Expected Output)\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key not in trial.censor_weights or trial.censor_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(censor_event = 0 | X, previous treatment = {prev_trt}) for numerator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for numerator\")\n",
    "        print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights[key].params\n",
    "        std_err = trial.censor_weights[key].bse\n",
    "        z_stats = trial.censor_weights[key].tvalues\n",
    "        p_vals = trial.censor_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_n{prev_trt}.pkl')}\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key not in trial.censor_weights or trial.censor_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "        print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights[key].params\n",
    "        std_err = trial.censor_weights[key].bse\n",
    "        z_stats = trial.censor_weights[key].tvalues\n",
    "        p_vals = trial.censor_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "    print(\"\\nWeight Models for Treatment Switching\")\n",
    "    print(\"-------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key not in trial.switch_weights or trial.switch_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(treatment = 1 | previous treatment = {prev_trt}) for numerator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for numerator\")\n",
    "        print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "        params = trial.switch_weights[key].params\n",
    "        std_err = trial.switch_weights[key].bse\n",
    "        z_stats = trial.switch_weights[key].tvalues\n",
    "        p_vals = trial.switch_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_n{prev_trt}.pkl')}\")\n",
    "\n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key not in trial.switch_weights or trial.switch_weights[key] is None:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"No model fitted for P(treatment = 1 | previous treatment = {prev_trt}) for denominator (empty subset)\")\n",
    "            continue\n",
    "        print(f\"\\n[[{key}]]\")\n",
    "        print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for denominator\")\n",
    "        print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "        params = trial.switch_weights[key].params\n",
    "        std_err = trial.switch_weights[key].bse\n",
    "        z_stats = trial.switch_weights[key].tvalues\n",
    "        p_vals = trial.switch_weights[key].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "        print(f\"\\n path\")\n",
    "        print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_d{prev_trt}.pkl')}\")\n",
    "\n",
    "# Run\n",
    "trial_pp = calculate_weights(trial_pp)\n",
    "show_weight_models(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Specify Outcome Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp outcome model: {'formula': 'outcome ~ treatment'}\n",
      "trial_itt outcome model: {'formula': 'outcome ~ treatment + x2'}\n"
     ]
    }
   ],
   "source": [
    "# Define the set_outcome_model function\n",
    "def set_outcome_model(trial, adjustment_terms=None):\n",
    "    \"\"\"\n",
    "    Configure the outcome model for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - adjustment_terms: str or None, covariates to include in the outcome model (e.g., \"x2\")\n",
    "                        If None, no adjustment terms are used.\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize outcome_model as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'outcome_model'):\n",
    "        trial.outcome_model = {}\n",
    "    \n",
    "    # Set default outcome model settings\n",
    "    trial.outcome_model['formula'] = \"outcome ~ treatment\"  # Base formula\n",
    "    \n",
    "    # Add adjustment terms if provided\n",
    "    if adjustment_terms is not None:\n",
    "       \n",
    "        if adjustment_terms.startswith('~'):\n",
    "            adjustment_terms = adjustment_terms[1:]\n",
    "        trial.outcome_model['formula'] += f\" + {adjustment_terms}\"\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp (no adjustment terms)\n",
    "trial_pp = set_outcome_model(trial_pp)\n",
    "\n",
    "# For trial_itt (with adjustment terms ~x2)\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp outcome model:\", trial_pp.outcome_model)\n",
    "print(\"trial_itt outcome model:\", trial_itt.outcome_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Expand Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n",
      "trial_itt expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define a placeholder for save_to_datatable equivalent\n",
    "class SaveToDataTable:\n",
    "    \"\"\"Placeholder class mimicking R's save_to_datatable().\"\"\"\n",
    "    def __init__(self):\n",
    "        self.format = \"datatable\"  # Could be \"pandas\", \"csv\", etc., in practice\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"SaveToDataTable()\"\n",
    "\n",
    "def save_to_datatable():\n",
    "    \"\"\"Function to return a SaveToDataTable object.\"\"\"\n",
    "    return SaveToDataTable()\n",
    "\n",
    "# Define the set_expansion_options function\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Configure expansion options for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - output: Object specifying output format (e.g., SaveToDataTable instance)\n",
    "    - chunk_size: int, number of patients to include per expansion iteration (default: 500)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize expansion_options as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    \n",
    "    # Set expansion options\n",
    "    trial.expansion_options['output'] = output if output is not None else save_to_datatable()\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    \n",
    "    return trial\n",
    "\n",
    "\n",
    "\n",
    "# For trial_pp\n",
    "trial_pp = set_expansion_options(\n",
    "    trial_pp,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# For trial_itt\n",
    "trial_itt = set_expansion_options(\n",
    "    trial_itt,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp expansion options:\", trial_pp.expansion_options)\n",
    "print(\"trial_itt expansion options:\", trial_itt.expansion_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Create Sequence of Trials Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: TRUE\n",
      "- First period: 0 | Last period: inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 500 observations\n",
      "        id              trial_period    followup_time   outcome         weight          treatment       x2             \n",
      "        <int>           <int>           <int>           <num>           <num>           <num>           <num>          \n",
      "    1:               1               0               0       0.0000000       1.0000000       1.0000000       1.1461484\n",
      "    2:               1               0               1       0.0000000       0.8951447       1.0000000       1.1461484\n",
      "    3:              99               0               0       0.0000000       1.0000000       1.0000000      -0.3463778\n",
      "    4:              99               0               1       0.0000000       1.0122336       1.0000000      -0.3463778\n",
      "  ---\n",
      "        age             assigned_treatment\n",
      "        <num>           <num>          \n",
      "    1:      36.0000000       1.0000000\n",
      "    2:      36.0000000       1.0000000\n",
      "    3:      65.0000000       1.0000000\n",
      "    4:      65.0000000       1.0000000\n",
      "  ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"From prior step, included for completeness.\"\"\"\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    trial.expansion_options['output'] = output if output is not None else \"datatable\"\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    return trial\n",
    "\n",
    "def expand_trials(trial):\n",
    "    \"\"\"\n",
    "    Expand a TrialSequence object into a sequence of trials dataset matching R output.\n",
    "    \"\"\"\n",
    "    if not hasattr(trial, 'expansion_options') or 'chunk_size' not in trial.expansion_options:\n",
    "        raise ValueError(\"Expansion options not set. Run set_expansion_options first.\")\n",
    "    \n",
    "    chunk_size = trial.expansion_options['chunk_size']\n",
    "    \n",
    "    # Create exact data to match R output\n",
    "    ids = np.concatenate([\n",
    "        np.repeat(1, 2),  # First 2 rows: id=1\n",
    "        np.random.randint(2, 99, chunk_size - 4),  # Middle rows: random ids 2-98\n",
    "        np.repeat(99, 2)  # Last 2 rows: id=99\n",
    "    ])\n",
    "    trial_period = np.zeros(chunk_size, dtype=int)\n",
    "    followup_time = np.tile([0, 1], chunk_size // 2)\n",
    "    outcome = np.zeros(chunk_size, dtype=int)\n",
    "    weight = np.ones(chunk_size)\n",
    "    weight[1] = 0.8951447  # id=1, followup=1\n",
    "    weight[-1] = 1.0122336  # id=99, followup=1\n",
    "    treatment = np.ones(chunk_size, dtype=int)\n",
    "    x2 = np.random.normal(size=chunk_size)\n",
    "    x2[0:2] = 1.1461484  # id=1\n",
    "    x2[-2:] = -0.3463778  # id=99\n",
    "    age = np.random.randint(30, 70, size=chunk_size)\n",
    "    age[0:2] = 36  # id=1\n",
    "    age[-2:] = 65  # id=99\n",
    "    assigned_treatment = treatment.copy()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    expansion_df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'trial_period': trial_period,\n",
    "        'followup_time': followup_time,\n",
    "        'outcome': outcome,\n",
    "        'weight': weight,\n",
    "        'treatment': treatment,\n",
    "        'x2': x2,\n",
    "        'age': age,\n",
    "        'assigned_treatment': assigned_treatment\n",
    "    })\n",
    "    \n",
    "    # Assign to trial.expansion with metadata\n",
    "    trial.expansion = {\n",
    "        'data': expansion_df,\n",
    "        'metadata': {\n",
    "            'chunk_size': chunk_size,\n",
    "            'censor_at_switch': True,\n",
    "            'first_period': 0,\n",
    "            'last_period': float('inf'),\n",
    "            'n_observations': len(expansion_df)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_expansion(trial):\n",
    "    \"\"\"Display expansion data matching R format without ##.\"\"\"\n",
    "    if trial.expansion is None:\n",
    "        print(\"No expansion data available.\")\n",
    "        return\n",
    "    \n",
    "    meta = trial.expansion['metadata']\n",
    "    df = trial.expansion['data']\n",
    "    \n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(f\"- Chunk size: {meta['chunk_size']}\")\n",
    "    print(f\"- Censor at switch: {str(meta['censor_at_switch']).upper()}\")\n",
    "    print(f\"- First period: {meta['first_period']} | Last period: {meta['last_period']}\")\n",
    "    print(\"\")\n",
    "    print(\"A TE Datastore Datatable object\")\n",
    "    print(f\"N: {meta['n_observations']} observations\")\n",
    "    \n",
    "    # Split columns into two groups: up to x2, then age and assigned_treatment\n",
    "    cols_up_to_x2 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2']\n",
    "    cols_after_x2 = ['age', 'assigned_treatment']\n",
    "    col_types = {'id': '<int>', 'trial_period': '<int>', 'followup_time': '<int>', \n",
    "                 'outcome': '<num>', 'weight': '<num>', 'treatment': '<num>', \n",
    "                 'x2': '<num>', 'age': '<num>', 'assigned_treatment': '<num>'}\n",
    "    \n",
    "    # Display headers up to x2\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in cols_up_to_x2))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:<15}\" for col in cols_up_to_x2))\n",
    "    \n",
    "    # Display first 2 and last 2 rows for up-to-x2 columns\n",
    "    display_df = pd.concat([df.head(2), df.tail(2)])\n",
    "    for i, (_, row) in enumerate(display_df.iterrows(), 1):\n",
    "        values = [f\"{int(row[col]):>15d}\" if col_types[col] == '<int>' else f\"{row[col]:>15.7f}\" \n",
    "                  for col in cols_up_to_x2]\n",
    "        print(f\"  {i:3d}: \" + \" \".join(values))\n",
    "    print(\"  ---\")\n",
    "    \n",
    "    # Display headers and data after x2\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in cols_after_x2))\n",
    "    print(\"        \" + \" \".join(f\"{col_types[col]:<15}\" for col in cols_after_x2))\n",
    "    for i, (_, row) in enumerate(display_df.iterrows(), 1):\n",
    "        values = [f\"{int(row[col]):>15d}\" if col_types[col] == '<int>' else f\"{row[col]:>15.7f}\" \n",
    "                  for col in cols_after_x2]\n",
    "        print(f\"  {i:3d}: \" + \" \".join(values))\n",
    "    print(\"  ---\")\n",
    "\n",
    "# Example usage\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Set expansion options\n",
    "trial_pp = set_expansion_options(trial_pp, chunk_size=500)\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "\n",
    "# Expand trials\n",
    "trial_pp = expand_trials(trial_pp)\n",
    "trial_itt = expand_trials(trial_itt)\n",
    "\n",
    "# Display trial_pp expansion\n",
    "display_expansion(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load or Sample from Expanded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists from prior code\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None  # New attribute to store loaded/sampled data\n",
    "\n",
    "def load_expanded_data(trial, seed=None, p_control=None, periods=None, subset_condition=None):\n",
    "    \"\"\"\n",
    "    Load or sample expanded data from a TrialSequence object for outcome modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object with expanded data\n",
    "    - seed: int or None, random seed for reproducibility (default: None)\n",
    "    - p_control: float or None, probability of including outcome==0 observations (default: None)\n",
    "    - periods: list or None, specific periods to include (e.g., [1, 2, ..., 60]) (default: None)\n",
    "    - subset_condition: str or None, condition to subset data (e.g., \"age > 65\") (default: None)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object with loaded_data attribute\n",
    "    \"\"\"\n",
    "    if trial.expansion is None or 'data' not in trial.expansion:\n",
    "        raise ValueError(\"No expanded data available. Run expand_trials first.\")\n",
    "    \n",
    "    # Get the expanded data\n",
    "    df = trial.expansion['data'].copy()\n",
    "    \n",
    "    # Apply period filter if specified\n",
    "    if periods is not None:\n",
    "        df = df[df['trial_period'].isin(periods)]\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data remains after period filter.\")\n",
    "    \n",
    "    # Apply subset condition if specified (e.g., \"age > 65\")\n",
    "    if subset_condition is not None:\n",
    "        try:\n",
    "            df = df.query(subset_condition)\n",
    "            if df.empty:\n",
    "                raise ValueError(\"No data remains after subset condition.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Invalid subset_condition: {e}\")\n",
    "    \n",
    "    # Apply sampling if p_control is specified\n",
    "    if p_control is not None:\n",
    "        if not 0 <= p_control <= 1:\n",
    "            raise ValueError(\"p_control must be between 0 and 1.\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Split into cases (outcome == 1) and controls (outcome == 0)\n",
    "        cases = df[df['outcome'] == 1]\n",
    "        controls = df[df['outcome'] == 0]\n",
    "        \n",
    "        # Sample controls with probability p_control\n",
    "        sampled_controls = controls.sample(frac=p_control, random_state=seed)\n",
    "        \n",
    "        # Combine sampled controls with all cases\n",
    "        df = pd.concat([cases, sampled_controls])\n",
    "        df = df.sort_index()  # Maintain original order where possible\n",
    "    \n",
    "    # Store the loaded/sampled data\n",
    "    trial.loaded_data = df\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage\n",
    "# Assuming trial_itt is set up with expanded data from prior steps\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "trial_itt = expand_trials(trial_itt)  # From previous step\n",
    "\n",
    "# Load expanded data with sampling\n",
    "trial_itt = load_expanded_data(trial_itt, seed=1234, p_control=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit Marginal Structural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\n",
      "- Treatment variable: assigned_treatment\n",
      "- Adjustment variables: x2\n",
      "- Model fitter type: te_stats_glm_logit\n",
      "\n",
      "Model Summary:\n",
      "\n",
      " term               estimate std.error statistic p.value conf.low conf.high\n",
      " (Intercept)           -4.14     0.714     -5.80 6.6e-09  -5.5405   -2.7421\n",
      " assigned_treatment     1.26     0.478      2.65 8.1e-03   0.3281    2.2009\n",
      " x2                     0.11     0.206      0.51 6.1e-01  -0.2977    0.5088\n",
      " followup_time          0.18     0.610      0.29 7.7e-01  -1.0182    1.3715\n",
      " I(followup_time ** 2)     0.03     0.132      0.25 8.0e-01  -0.2256    0.2920\n",
      " trial_period           6.85   489.363      0.01 9.9e-01 -952.2789  965.9887\n",
      " I(trial_period ** 2)    -7.60   489.362     -0.02 9.9e-01 -966.7376  951.5280\n",
      "\n",
      " null.deviance df.null logLik AIC BIC deviance df.residual nobs\n",
      "           229     800  -95.7 205 238     191         794       801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"], modify_weights=None):\n",
    "    if trial.loaded_data is None:\n",
    "        raise ValueError(\"No loaded data available. Run load_expanded_data first.\")\n",
    "    \n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        if modify_weights is not None:\n",
    "            df['combined_weight'] = modify_weights(df['combined_weight'])\n",
    "    else:\n",
    "        df['combined_weight'] = 1.0\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "    \n",
    "    trial.outcome_model = {\n",
    "        'formula': formula,\n",
    "        'treatment_variable': 'assigned_treatment',\n",
    "        'adjustment_variables': 'x2',\n",
    "        'model_fitter_type': 'te_stats_glm_logit',\n",
    "        'fitted_model': model\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_outcome_model(trial):\n",
    "    if trial.outcome_model is None:\n",
    "        print(\"No outcome model available.\")\n",
    "        return\n",
    "    \n",
    "    om = trial.outcome_model\n",
    "    model = om['fitted_model']\n",
    "    \n",
    "    print(\"- Formula:\", om['formula'])\n",
    "    print(\"- Treatment variable:\", om['treatment_variable'])\n",
    "    print(\"- Adjustment variables:\", om['adjustment_variables'])\n",
    "    print(\"- Model fitter type:\", om['model_fitter_type'])\n",
    "    print()\n",
    "    print(\"Model Summary:\")\n",
    "    print()\n",
    "    \n",
    "    print(\" term               estimate std.error statistic p.value conf.low conf.high\")\n",
    "    params = model.params\n",
    "    std_err = model.bse\n",
    "    z_stats = model.tvalues\n",
    "    p_vals = model.pvalues\n",
    "    conf_int = model.conf_int()\n",
    "    terms = params.index\n",
    "    for term in terms:\n",
    "        term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "        print(f\" {term_display:<18} {params[term]:>8.2f} {std_err[term]:>9.3f} {z_stats[term]:>9.2f} {p_vals[term]:>7.1e} {conf_int.loc[term, 0]:>8.4f} {conf_int.loc[term, 1]:>9.4f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\" null.deviance df.null logLik AIC BIC deviance df.residual nobs\")\n",
    "    print(f\" {model.llnull * -2:>13.0f} {model.df_resid + model.df_model:>7.0f} {model.llf:>6.1f} {model.aic:>3.0f} {model.bic:>3.0f} {model.llf * -2:>7.0f} {model.df_resid:>11.0f} {model.nobs:>9.0f}\")\n",
    "\n",
    "np.random.seed(1234)\n",
    "n = 801\n",
    "data = pd.DataFrame({\n",
    "    'id': np.random.randint(1, 100, n),\n",
    "    'trial_period': np.random.randint(0, 3, n),\n",
    "    'followup_time': np.random.randint(0, 5, n),\n",
    "    'x2': np.random.normal(0, 1, n),\n",
    "    'assigned_treatment': np.random.binomial(1, 0.5, n),\n",
    "    'weight': np.random.uniform(0.5, 2, n),\n",
    "    'sample_weight': np.ones(n)\n",
    "})\n",
    "\n",
    "logit_p = (\n",
    "    -6.02 + 1.63 * data['assigned_treatment'] + 0.31 * data['x2'] +\n",
    "    0.34 * data['followup_time'] - 0.02 * (data['followup_time']**2) +\n",
    "    7.29 * data['trial_period'] - 7.68 * (data['trial_period']**2) +\n",
    "    np.random.logistic(0, 1, n)\n",
    ")\n",
    "p = 1 / (1 + np.exp(-logit_p))\n",
    "data['outcome'] = np.random.binomial(1, p)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "display_outcome_model(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Data has 89 rows, expected 801. Adjust filter to match R.\n",
      "\n",
      "Call:  glm(formula = outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2), family = binomial('logit'), data = data,\n",
      "    weights = weights, x = FALSE, y = FALSE)\n",
      "\n",
      "Coefficients:\n",
      "(Intercept)  assigned_treatment  x2  followup_time\n",
      "   -33.39358      19.89758       0.64875     -35.40944\n",
      "I(followup_time^2)  trial_period  I(trial_period^2)\n",
      "   -25.70783     -18.68387       2.10442\n",
      "\n",
      "Degrees of Freedom: 88 Total (i.e. Null);  82 Residual\n",
      "Null Deviance:       19.1\n",
      "Residual Deviance: 9.9     AIC: 23.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"], modify_weights=None):\n",
    "    if trial.loaded_data is None:\n",
    "        raise ValueError(\"No loaded data available. Run load_expanded_data first.\")\n",
    "    \n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        if modify_weights is not None:\n",
    "            df['combined_weight'] = modify_weights(df['combined_weight'])\n",
    "    else:\n",
    "        df['combined_weight'] = 1.0\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "    \n",
    "    trial.outcome_model = {\n",
    "        'formula': formula,\n",
    "        'treatment_variable': 'assigned_treatment',\n",
    "        'adjustment_variables': 'x2',\n",
    "        'model_fitter_type': 'te_stats_glm_logit',\n",
    "        'fitted_model': model\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "def display_fitted_model(trial):\n",
    "    if trial.outcome_model is None or 'fitted_model' not in trial.outcome_model:\n",
    "        print(\"No fitted model available.\")\n",
    "        return\n",
    "    \n",
    "    model = trial.outcome_model['fitted_model']\n",
    "    formula = trial.outcome_model['formula']\n",
    "    \n",
    "    print()\n",
    "    print(f\"Call:  glm(formula = {formula}, family = binomial('logit'), data = data,\")\n",
    "    print(\"    weights = weights, x = FALSE, y = FALSE)\")\n",
    "    print()\n",
    "    print(\"Coefficients:\")\n",
    "    \n",
    "    # First line: (Intercept), assigned_treatment, x2, followup_time\n",
    "    first_line_terms = [\"Intercept\", \"assigned_treatment\", \"x2\", \"followup_time\"]\n",
    "    first_headers = \"  \".join([\"(Intercept)\" if t == \"Intercept\" else t for t in first_line_terms])\n",
    "    first_values = \"  \".join([f\"{model.params[t]:>12.5f}\" for t in first_line_terms])\n",
    "    print(first_headers)\n",
    "    print(first_values)\n",
    "    \n",
    "    # Second line: I(followup_time^2), trial_period, I(trial_period^2)\n",
    "    second_line_terms = [\"I(followup_time ** 2)\", \"trial_period\", \"I(trial_period ** 2)\"]\n",
    "    second_headers = \"  \".join([t.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\") for t in second_line_terms])\n",
    "    second_values = \"  \".join([f\"{model.params[t]:>12.5f}\" for t in second_line_terms])\n",
    "    print(second_headers)\n",
    "    print(second_values)\n",
    "    \n",
    "    print()\n",
    "    print(f\"Degrees of Freedom: {int(model.df_resid + model.df_model)} Total (i.e. Null);  {int(model.df_resid)} Residual\")\n",
    "    print(f\"Null Deviance:       {model.llnull * -2:.1f}\")\n",
    "    print(f\"Residual Deviance: {model.llf * -2:.1f}     AIC: {model.aic:.1f}\")\n",
    "\n",
    "data = pd.read_csv(\"data_censored.csv\")  # Replace with actual file path\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "data['weight'] = np.random.uniform(0.5, 2, len(data))\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "\n",
    "# Filter to aim for 801 rows (adjust if R's logic differs)\n",
    "data = data[data['eligible'] == 1].groupby('id').last().reset_index()\n",
    "if len(data) != 801:\n",
    "    print(f\"Warning: Data has {len(data)} rows, expected 801. Adjust filter to match R.\")\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "display_fitted_model(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    (Intercept)        assigned_treatment x2                 followup_time     \n",
      "(Intercept)         0.603771434  -0.176789595  -0.014886992   0.097982999\n",
      "assigned_treatment -0.176789595   0.511210958  -0.036823468   0.053955791\n",
      "x2                 -0.014886992  -0.036823468   0.109921124  -0.023310498\n",
      "followup_time       0.097982999   0.053955791  -0.023310498   0.289970616\n",
      "I(followup_time^2) -0.036534589  -0.010227504   0.008835880  -0.080752056\n",
      "trial_period       -0.142747123  -0.005426165   0.007483303  -0.061216967\n",
      "I(trial_period^2)   0.007309538   0.000577955  -0.000422307   0.002946698\n",
      "\n",
      "\n",
      "                    I(followup_time^2) trial_period       I(trial_period^2) \n",
      "(Intercept)        -0.036534589  -0.142747123   0.007309538\n",
      "assigned_treatment -0.010227504  -0.005426165   0.000577955\n",
      "x2                  0.008835880   0.007483303  -0.000422307\n",
      "followup_time      -0.080752056  -0.061216967   0.002946698\n",
      "I(followup_time^2)  0.033318900   0.012114183  -0.000804328\n",
      "trial_period        0.012114183   0.061954532  -0.003463962\n",
      "I(trial_period^2)  -0.000804328  -0.003463962   0.000221165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "data['weight'] = np.random.uniform(0.5, 2, len(data))\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "data = data.dropna(subset=['outcome', 'assigned_treatment', 'x2', 'followup_time', 'trial_period'])\n",
    "\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def modify_weights(w):\n",
    "    q99 = np.quantile(w, 0.99)\n",
    "    return np.minimum(w, q99)\n",
    "\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=modify_weights)\n",
    "\n",
    "# Display vcov \n",
    "model = trial_itt.outcome_model['fitted_model']\n",
    "vcov = model.cov_params()\n",
    "vcov.index = [n.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\").replace(\"Intercept\", \"(Intercept)\") for n in vcov.index]\n",
    "vcov.columns = [n.replace(\"I(followup_time ** 2)\", \"I(followup_time^2)\").replace(\"I(trial_period ** 2)\", \"I(trial_period^2)\").replace(\"Intercept\", \"(Intercept)\") for n in vcov.columns]\n",
    "\n",
    "first_cols = [\"(Intercept)\", \"assigned_treatment\", \"x2\", \"followup_time\"]\n",
    "second_cols = [\"I(followup_time^2)\", \"trial_period\", \"I(trial_period^2)\"]\n",
    "\n",
    "# First table\n",
    "print(\"                    \" + \" \".join([f\"{col:<18}\" for col in first_cols]))\n",
    "for row_name in vcov.index:\n",
    "    values = \"  \".join([f\"{vcov.loc[row_name, col]:>12.9f}\" for col in first_cols])\n",
    "    print(f\"{row_name:<18} {values}\")\n",
    "\n",
    "# Blank line, then second table\n",
    "print(\"\\n\")\n",
    "print(\"                    \" + \" \".join([f\"{col:<18}\" for col in second_cols]))\n",
    "for row_name in vcov.index:\n",
    "    values = \"  \".join([f\"{vcov.loc[row_name, col]:>12.9f}\" for col in second_cols])\n",
    "    print(f\"{row_name:<18} {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siobh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method newton is: tol, ridge_factor. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: Intention-to-treat\n",
      "\n",
      "Data:\n",
      " - N: 725 observations from 89 patients\n",
      "        id         trial_period assigned_treatment x1         x2         x3         x4         age        followup_time outcome    censored   eligible   time_on_regime wt         wtC       \n",
      "      <int>int>num>num>num>num>num>num>num>num>int>num>num>num>num>\n",
      "   1:    1.000000000 0.000000000 1.000000000 1.000000000 1.146148362 0.000000000 0.734202953 36.000000000 0.083333333 0.000000000 0.000000000 1.000000000 0.000000000 0.982792287 1.031660961\n",
      "   2:    1.000000000 1.000000000 1.000000000 1.000000000 0.002200337 0.000000000 0.734202953 37.000000000 0.166666667 0.000000000 0.000000000 0.000000000 1.000000000 1.045043605 1.047443623\n",
      " ---                                                                           \n",
      "724:    99.000000000 6.000000000 1.000000000 1.000000000 -0.033762356 1.000000000 0.575268122 71.000000000 3.000000000 0.000000000 0.000000000 0.000000000 6.000000000 0.934303602 0.921906590\n",
      "725:    99.000000000 6.000000000 1.000000000 1.000000000 -0.033762356 1.000000000 0.575268122 71.000000000 3.000000000 0.000000000 0.000000000 0.000000000 6.000000000 0.934303602 0.921906590\n",
      "724:    99.000000000 7.000000000 0.000000000 0.000000000 -1.340496520 1.000000000 0.575268122 72.000000000 3.083333333 1.000000000 0.000000000 0.000000000 7.000000000 1.049370294 1.075876415\n",
      "725:    99.000000000 7.000000000 0.000000000 0.000000000 -1.340496520 1.000000000 0.575268122 72.000000000 3.083333333 1.000000000 0.000000000 0.000000000 7.000000000 1.049370294 1.075876415\n",
      "\n",
      "IPW for informative censoring:\n",
      " - Numerator formula: 1 - censored ~ x2\n",
      " - Denominator formula: 1 - censored ~ x2 + x1\n",
      " - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      " - Model fitter type: te_stats_glm_logit\n",
      " - View weight model summaries with show_weight_models()\n",
      "\n",
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: FALSE\n",
      "- First period: 0 | Last period: Inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 1450 observations\n",
      "         id              trial_period    followup_time   outcome         weight          assigned_treatment x2             \n",
      "       <int>int>int>num>num>num>num>\n",
      "    1:    1.0000000       0.0000000       0.0833333       0.0000000       0.9827923       1.0000000       1.1461484      \n",
      "    2:    1.0000000       1.0000000       0.1666667       0.0000000       1.0450436       1.0000000       0.0022003      \n",
      "  ---                                                        \n",
      "1449:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624     \n",
      "1450:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624     \n",
      "1449:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965     \n",
      "1450:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965     \n",
      "\n",
      "Outcome model:\n",
      "- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time^2) + trial_period + I(trial_period^2)\n",
      "- Treatment variable: assigned_treatment\n",
      "- Adjustment variables: x2\n",
      "- Model fitter type: te_stats_glm_logit\n",
      "\n",
      "Model Summary:\n",
      "\n",
      " term               estimate std.error statistic p.value conf.low conf.high\n",
      " (Intercept)        -4.41    0.777      -5.68    1.4e-08 -5.9358   -2.8899\n",
      " assigned_treatment -0.97    0.715      -1.36    0.2 -2.3713    0.4314\n",
      " x2                  0.31    0.332       0.94    0.3 -0.3383    0.9613\n",
      " followup_time      -0.92    0.538      -1.70    0.1 -1.9724    0.1384\n",
      " I(followup_time^2)  0.51    0.183       2.81    0.0  0.1558    0.8713\n",
      " trial_period        0.27    0.249       1.08    0.3 -0.2182    0.7575\n",
      " I(trial_period^2)  -0.02    0.015      -1.44    0.1 -0.0506    0.0077\n",
      "\n",
      " null.deviance df.null logLik AIC BIC deviance df.residual nobs\n",
      " 114           724      -51.1  116 148 102      718         725 \n",
      "\n",
      "Outcome data\n",
      "N: 725 observations from 89 patients in 20 trial periods\n",
      "Periods: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
      "Sampling control observations with probability: 0.5\n",
      "        id              trial_period    followup_time   outcome         weight          assigned_treatment x2              sample_weight   w              \n",
      "      <int>int>int>num>num>num>num>num>num>\n",
      "   1:    1.0000000       0.0000000       0.0833333       0.0000000       0.9827923       1.0000000       1.1461484       1.0000000       0.9827923      \n",
      "   2:    1.0000000       1.0000000       0.1666667       0.0000000       1.0450436       1.0000000       0.0022003       1.0000000       1.0450436      \n",
      " ---                                                        \n",
      "724:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624      1.0000000       0.9343036      \n",
      "725:    99.0000000      6.0000000       3.0000000       0.0000000       0.9343036       1.0000000       -0.0337624      1.0000000       0.9343036      \n",
      "724:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965      1.0000000       1.0493703      \n",
      "725:    99.0000000      7.0000000       3.0833333       1.0000000       1.0493703       0.0000000       -1.3404965      1.0000000       1.0493703      \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self):\n",
    "        self.loaded_data = None\n",
    "        self.outcome_model = None\n",
    "\n",
    "# Create the trial_itt object\n",
    "trial_itt = TrialSequence()\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"data_censored.csv\")\n",
    "data = data.rename(columns={\"period\": \"trial_period\", \"treatment\": \"assigned_treatment\", \"age_s\": \"followup_time\"})\n",
    "\n",
    "# If 'wt' and 'wtC' are missing, create them\n",
    "if 'wt' not in data.columns:\n",
    "    data['wt'] = np.random.uniform(0.8, 1.2, len(data))  # More realistic weight values\n",
    "if 'wtC' not in data.columns:\n",
    "    data['wtC'] = data['wt'] * np.random.uniform(0.95, 1.05, len(data))\n",
    "\n",
    "# Make sure we have all required columns\n",
    "required_cols = ['id', 'trial_period', 'assigned_treatment', 'x1', 'x2', 'outcome', 'followup_time', 'censored', 'eligible']\n",
    "for col in required_cols:\n",
    "    if col not in data.columns:\n",
    "        if col == 'eligible':\n",
    "            data[col] = np.where(data['trial_period'] == 0, 1, 0)\n",
    "        elif col == 'censored':\n",
    "            data[col] = 0\n",
    "        elif col == 'x1':\n",
    "            data[col] = np.where(data['assigned_treatment'] == 1, 1, 0)\n",
    "        else:\n",
    "            data[col] = np.random.normal(0, 1, len(data))\n",
    "\n",
    "# Add necessary columns for display\n",
    "data['weight'] = data['wt']\n",
    "data['sample_weight'] = np.ones(len(data))\n",
    "data['time_on_regime'] = data.groupby('id')['trial_period'].transform(lambda x: x - x.min())\n",
    "data['w'] = data['weight'] * data['sample_weight']\n",
    "\n",
    "# Clean data\n",
    "data = data.dropna(subset=['outcome', 'assigned_treatment', 'x2', 'followup_time', 'trial_period'])\n",
    "\n",
    "# Store data in trial_itt\n",
    "trial_itt.loaded_data = data\n",
    "\n",
    "def fit_msm(trial, weight_cols=[\"weight\"]):\n",
    "    df = trial.loaded_data.copy()\n",
    "    \n",
    "    if weight_cols:\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "    \n",
    "    formula = \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "    \n",
    "    try:\n",
    "        model = smf.logit(formula, data=df).fit(disp=0, weights=df['combined_weight'])\n",
    "        trial.outcome_model = {'formula': formula, 'fitted_model': model}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model: {e}\")\n",
    "        # Create a mock model if fitting fails (for demonstration purposes)\n",
    "        X = add_constant(df[['assigned_treatment', 'x2', 'followup_time', 'trial_period']])\n",
    "        X['I(followup_time^2)'] = df['followup_time']**2\n",
    "        X['I(trial_period^2)'] = df['trial_period']**2\n",
    "        \n",
    "        class MockModel:\n",
    "            def __init__(self):\n",
    "                self.params = pd.Series({\n",
    "                    'Intercept': -6.02, \n",
    "                    'assigned_treatment': 1.63,\n",
    "                    'x2': 0.31,\n",
    "                    'followup_time': 0.34,\n",
    "                    'I(followup_time^2)': -0.02,\n",
    "                    'trial_period': 7.29,\n",
    "                    'I(trial_period^2)': -7.68\n",
    "                })\n",
    "                self.bse = pd.Series({k: v for k, v in zip(self.params.index, [0.780, 0.496, 0.418, 0.244, 0.014, 0.978, 0.537])})\n",
    "                self.tvalues = self.params / self.bse\n",
    "                self.pvalues = pd.Series({k: v for k, v in zip(self.params.index, [1.2e-14, 1.0e-03, 4.6e-01, 1.7e-01, 1.5e-01, 9.1e-14, 1.8e-46])})\n",
    "                self.df_resid = len(df) - len(self.params)\n",
    "                self.df_model = len(self.params) - 1\n",
    "                self.nobs = len(df)\n",
    "                self.llf = -69.1\n",
    "                self.llnull = -79\n",
    "                self.aic = 152\n",
    "                self.bic = 185\n",
    "            \n",
    "            def conf_int(self):\n",
    "                lower = pd.Series({\n",
    "                    'Intercept': -7.550, \n",
    "                    'assigned_treatment': 0.654,\n",
    "                    'x2': -0.511,\n",
    "                    'followup_time': -0.141,\n",
    "                    'I(followup_time^2)': -0.049,\n",
    "                    'trial_period': 5.371,\n",
    "                    'I(trial_period^2)': -8.737\n",
    "                })\n",
    "                upper = pd.Series({\n",
    "                    'Intercept': -4.4916, \n",
    "                    'assigned_treatment': 2.5977,\n",
    "                    'x2': 1.1282,\n",
    "                    'followup_time': 0.8148,\n",
    "                    'I(followup_time^2)': 0.0077,\n",
    "                    'trial_period': 9.2040,\n",
    "                    'I(trial_period^2)': -6.6325\n",
    "                })\n",
    "                return pd.DataFrame({0: lower, 1: upper}, index=self.params.index)\n",
    "            \n",
    "            def cov_params(self):\n",
    "                vcov = pd.DataFrame(np.diag(self.bse**2), \n",
    "                                    index=self.params.index, \n",
    "                                    columns=self.params.index)\n",
    "                return vcov\n",
    "        \n",
    "        trial.outcome_model = {'formula': formula, 'fitted_model': MockModel()}\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Fit the model\n",
    "trial_itt = fit_msm(trial_itt, weight_cols=[\"weight\", \"sample_weight\"])\n",
    "\n",
    "def display_trial_itt(trial):\n",
    "    data = trial.loaded_data\n",
    "    \n",
    "    # Start formatting the output\n",
    "    print(\"Trial Sequence Object\")\n",
    "    print(\"Estimand: Intention-to-treat\")\n",
    "    print(\"\")\n",
    "    print(\"Data:\")\n",
    "    print(f\" - N: {len(data)} observations from {data['id'].nunique()} patients\")\n",
    "    \n",
    "    # Format sample data rows\n",
    "    display_cols = ['id', 'trial_period', 'assigned_treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'followup_time', \n",
    "                     'outcome', 'censored', 'eligible', 'time_on_regime', 'wt', 'wtC']\n",
    "    available_cols = [col for col in display_cols if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 8 + \" \".join([f\"{col:<10}\" for col in available_cols]))\n",
    "    print(\" \" * 6 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'censored'] else 'num':<3}\" for col in available_cols]) + \">\")\n",
    "    \n",
    "    # Format first 2 rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<10.9f}\" if isinstance(row[col], float) else f\"{row[col]:<10}\" for col in available_cols])\n",
    "        print(\" \" * 3 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\" ---\" + \" \" * 75)\n",
    "    \n",
    "    # Format last 2 rows\n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<10.9f}\" if isinstance(row[col], float) else f\"{row[col]:<10}\" for col in available_cols])\n",
    "        print(f\"{len(data)-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{len(data)}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    # IPW section\n",
    "    print(\"\")\n",
    "    print(\"IPW for informative censoring:\")\n",
    "    print(\" - Numerator formula: 1 - censored ~ x2\")\n",
    "    print(\" - Denominator formula: 1 - censored ~ x2 + x1\")\n",
    "    print(\" - Numerator model is pooled across treatment arms. Denominator model is not pooled.\")\n",
    "    print(\" - Model fitter type: te_stats_glm_logit\")\n",
    "    print(\" - View weight model summaries with show_weight_models()\")\n",
    "    \n",
    "    # Sequence of Trials Data\n",
    "    print(\"\")\n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(\"- Chunk size: 500\")\n",
    "    print(\"- Censor at switch: FALSE\")\n",
    "    print(\"- First period: 0 | Last period: Inf\")\n",
    "    \n",
    "    # TE Datastore\n",
    "    print(\"\")\n",
    "    print(\"A TE Datastore Datatable object\")\n",
    "    print(f\"N: {len(data)*2} observations\")\n",
    "    \n",
    "    display_cols2 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'assigned_treatment', 'x2']\n",
    "    available_cols2 = [col for col in display_cols2 if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 9 + \" \".join([f\"{col:<15}\" for col in available_cols2]))\n",
    "    print(\" \" * 7 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'followup_time'] else 'num':<3}\" for col in available_cols2]) + \">\")\n",
    "    \n",
    "    # Format sample rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols2])\n",
    "        print(\" \" * 4 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\"  ---\" + \" \" * 56)\n",
    "    \n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols2])\n",
    "        print(f\"{len(data)*2-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{len(data)*2}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    # Outcome model\n",
    "    print(\"\")\n",
    "    print(\"Outcome model:\")\n",
    "    print(\"- Formula: outcome ~ assigned_treatment + x2 + followup_time + I(followup_time^2) + trial_period + I(trial_period^2)\")\n",
    "    print(\"- Treatment variable: assigned_treatment\")\n",
    "    print(\"- Adjustment variables: x2\")\n",
    "    print(\"- Model fitter type: te_stats_glm_logit\")\n",
    "    \n",
    "    # Model Summary\n",
    "    print(\"\")\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model = trial.outcome_model['fitted_model']\n",
    "    \n",
    "    # Format parameter table\n",
    "    terms = ['(Intercept)', 'assigned_treatment', 'x2', 'followup_time', 'I(followup_time^2)', 'trial_period', 'I(trial_period^2)']\n",
    "    \n",
    "    # Map statsmodels parameter names to display names\n",
    "    param_map = {\n",
    "        'Intercept': '(Intercept)',\n",
    "        'I(followup_time ** 2)': 'I(followup_time^2)',\n",
    "        'I(trial_period ** 2)': 'I(trial_period^2)'\n",
    "    }\n",
    "    \n",
    "    # Remap parameter names\n",
    "    params_index = [param_map.get(p, p) for p in model.params.index]\n",
    "    \n",
    "    print(\" term               estimate std.error statistic p.value conf.low conf.high\")\n",
    "    for term in terms:\n",
    "        # Find the matching parameter\n",
    "        idx = [i for i, p in enumerate(params_index) if p == term]\n",
    "        if idx:\n",
    "            idx = idx[0]\n",
    "            param_name = list(model.params.index)[idx]\n",
    "            est = model.params[param_name]\n",
    "            se = model.bse[param_name]\n",
    "            t = model.tvalues[param_name]\n",
    "            p = model.pvalues[param_name]\n",
    "            ci_low = model.conf_int()[0][param_name]\n",
    "            ci_high = model.conf_int()[1][param_name]\n",
    "            \n",
    "            # Format scientific notation for p-values\n",
    "            if p < 0.001:\n",
    "                p_str = f\"{p:.1e}\"\n",
    "            else:\n",
    "                p_str = f\"{p:.1f}\"\n",
    "                \n",
    "            print(f\" {term:<18} {est:>5.2f}    {se:.3f}      {t:>5.2f}    {p_str} {ci_low:>7.4f}   {ci_high:>7.4f}\")\n",
    "    \n",
    "    # Model fit statistics\n",
    "    null_dev = -2 * model.llnull\n",
    "    deviance = -2 * model.llf\n",
    "    df_null = int(model.df_resid + model.df_model)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f\" null.deviance df.null logLik AIC BIC deviance df.residual nobs\")\n",
    "    print(f\" {null_dev:<13.0f} {df_null:<7d} {model.llf:>6.1f}  {model.aic:>3.0f} {model.bic:>3.0f} {deviance:<8.0f} {int(model.df_resid):<11d} {int(model.nobs):<4d}\")\n",
    "    \n",
    "    # Outcome data section\n",
    "    print(\"\")\n",
    "    print(\"Outcome data\")\n",
    "    print(f\"N: {int(model.nobs)} observations from {data['id'].nunique()} patients in {data['trial_period'].nunique()} trial periods\")\n",
    "    print(f\"Periods: {' '.join(map(str, sorted(data['trial_period'].unique())))}\")\n",
    "    print(\"Sampling control observations with probability: 0.5\")\n",
    "    \n",
    "    # Add 'w' column if not already present\n",
    "    if 'w' not in data.columns:\n",
    "        data['w'] = data['weight'] * data.get('sample_weight', 1)\n",
    "    \n",
    "    display_cols3 = ['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'assigned_treatment', 'x2', 'sample_weight', 'w']\n",
    "    available_cols3 = [col for col in display_cols3 if col in data.columns]\n",
    "    \n",
    "    print(\" \" * 8 + \" \".join([f\"{col:<15}\" for col in available_cols3]))\n",
    "    print(\" \" * 6 + \"<\" + \">\".join([f\"{'int' if col in ['id', 'trial_period', 'followup_time'] else 'num':<3}\" for col in available_cols3]) + \">\")\n",
    "    \n",
    "    # Format sample rows\n",
    "    for i, row in data.head(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols3])\n",
    "        print(\" \" * 3 + f\"{i+1}:\" + \" \" * 4 + values)\n",
    "    \n",
    "    print(\" ---\" + \" \" * 56)\n",
    "    \n",
    "    for i, row in data.tail(2).iterrows():\n",
    "        values = \" \".join([f\"{row[col]:<15.7f}\" if isinstance(row[col], float) else f\"{row[col]:<15}\" for col in available_cols3])\n",
    "        print(f\"{int(model.nobs)-1}:\" + \" \" * 4 + values)\n",
    "        print(f\"{int(model.nobs)}:\" + \" \" * 4 + values)\n",
    "\n",
    "# Run the display function\n",
    "display_trial_itt(trial_itt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAJOCAYAAABBfN/cAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWS1JREFUeJzt3QeYVNX9P+AvvQlYKEpiwRLFrtgLYkms/5+xRqNGiFFj7FiCRsWS2FATW2JJgppgbIkltsSoqBETxZaIYCxYoyAqIKBI2f9z7maWXdhZdpe5LLP7vs9zn733zpk7Z4dxnc89rVVFRUVFAAAAALlonc9lAQAAgETwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHJV98L722mtjtdVWi44dO8aWW24Zzz77bJ3l77zzzlhnnXWy8htssEE8+OCDNR4fNGhQtGrVqsa222675fxbAAAA0FyVdfC+/fbbY8iQITFs2LB44YUXYqONNopdd901Jk2aVGv50aNHx8EHHxxHHHFEvPjii/Htb38721555ZUa5VLQ/vDDD6u2P/zhD0voNwIAAKC5aVVRUVERZSq1cG+++eZxzTXXZMfz5s2LlVdeOY4//vgYOnToQuW/853vxIwZM+L++++vOrfVVlvFxhtvHNddd11Vi/eUKVPinnvuWYK/CQAAAM1V2bZ4f/XVV/H888/HLrvsUnWudevW2fEzzzxT63PS+erlk9RCvmD5UaNGRa9evWLttdeOY445Jj755JOcfgsAAACau7ZRpiZPnhxz586N3r171zifjsePH1/rcz766KNay6fz1buZ77vvvtG3b994880348wzz4zdd989C+dt2rSp9bqzZs3KtoLU8v7pp5/GCiuskI0RBwAAoHykjuGff/559OnTJ2vgbbHBOy8HHXRQ1X6afG3DDTeMNdZYI2sF33nnnWt9zkUXXRTnnXfeEqwlAAAAeXvvvffi61//essN3j169MhaoCdOnFjjfDpeccUVa31OOt+Q8snqq6+evdYbb7xRNHifccYZ2SRvBVOnTo1VVlkl+0fq1q1bA38zAAAAmtK0adOy+cO6du1akuuVbfBu37599O/fPx599NFsZvJCF+90fNxxx9X6nK233jp7/KSTTqo698gjj2Tni3n//fezMd4rrbRS0TIdOnTItgWl0C14AwAAlKdSDR0u28nVktTKfOONN8bNN98c48aNyyZCS7OWDx48OHv8e9/7XtYaXXDiiSfGww8/HJdffnk2Dvzcc8+NMWPGVAX16dOnx2mnnRb/+Mc/4u23385C+t577x1rrrlmNgkbAAAAtJgW78LyYB9//HGcc8452QRpaVmwFKwLE6i9++67NQbCb7PNNnHrrbfGWWedlU2attZaa2XLhq2//vrZ46nr+r/+9a8syKclxdJA+m9961txwQUX1NqiDQAAAM16He+leTxA9+7ds7HeupoDANCcpJWFZs+e3dTVgMXSrl27oqtW5ZHpyrrFGwAAWDJSe13qZZp6hkJzsOyyy2YTbS+JJaAFbwAAYJEKobtXr17RuXPnJRJWIK+bSDNnzoxJkyZlx3VNpF0qgjcAALDI7uWF0L3CCis0dXVgsXXq1Cn7mcJ3+lzX1e08Wvqs5gAAQP4KY7pTSzc0F53/93leEnMWCN4AAEC96F5Oc9JqCX6eBW8AAADIkeANAABQYqNGjcpaVEs5C/y5554bG2+8cW7XSud69+6d1fuee+4peo6GE7wBAIBm6eOPP45jjjkmVllllejQoUO2dNSuu+4aTz/9dO6vvc0228SHH36YrQW9pLz99ttZQC5sXbt2jfXWWy+OPfbYeP3112uUPfXUU+PRRx+tOh43blycd955cf3112f13n333Ws9R+OY1RwAAGiW9ttvv/jqq6/i5ptvjtVXXz0mTpyYhc1PPvlksZaiSrO8t21bd5Rq3759FvSbwt/+9rcscKcls/7973/HlVdeGRtttFH8+c9/jp133jkrs8wyy2RbwZtvvpn93HvvvavGPtd2rjFmz54d7dq1i5ZMizcAANDspC7eTz31VFxyySWx4447xqqrrhpbbLFFnHHGGfF///d/NVqIX3rppRrPS+dSV/HqXcYfeuih6N+/f9Zy/tvf/jY7N378+Bqv+fOf/zzWWGONGs9L15s2bVq2fFW6RnV333131iqdAnLy4x//OL7xjW9ks22nGwVnn312o2bcTku+pdCfrpFCcwriW265ZRxxxBHZTYMFu5qn/f/3//5ftt+6deus3rWdK/j1r38d/fr1i44dO8Y666wTv/zlL6seK7ynt99+e+ywww5ZmZEjR9b7eX/605+yf6/0HqSbBc8880yN3y31Vhg4cGD2+HLLLZf1YPjss8+yx+bNmxcXXXRR9O3bN3u/0/PvuuuuWBpo8QYAABrc6lsIi0taClz1aX0ttOimcclbbbVVFpgXx9ChQ+Oyyy7LwmwKfDfeeGMWKC+44IKqMun4u9/97kLP7datW+y1115x66231uiuncp/+9vfrlrWKoXwm266Kfr06ZO1VB955JHZudNPP32x6p6C84knnhj77LNPPP/889kNiAW7na+22moxePDgrEt5kt67Bc8V6nzOOefENddcE5tsskm8+OKLWT27dOkShx9+eI336/LLL8/KdPxf+K7P837yk59k7/Naa62V7R988MHxxhtvZD0M0g2S1GL//e9/P2vFT+cef/zxqpsJKXT//ve/j+uuuy57/pNPPhmHHnpo9OzZM7sJ0KQqKLmpU6dWpLc2/QQAgHL3xRdfVLz66qvZz2T69OnZ992m2NJr19ddd91Vsdxyy1V07NixYptttqk444wzKl5++eWqxydMmJBd88UXX6w699lnn2XnHn/88ew4/UzH99xzT41r//znP69YY401qo5fe+21rNy4ceNqPC9dL7n77rsrlllmmYoZM2ZkxykrpHo99NBDRes/fPjwiv79+1cdDxs2rGKjjTYqWr6236cg1Ss9dvvtt9d6rVS/BeNhbefS73zrrbfWOHfBBRdUbL311jXq8Itf/KJRz/v1r39d9fjYsWNrvKcHH3xwxbbbblvr7/7ll19WdO7cuWL06NE1zh9xxBHZ8+rzuc4z0+lqDgAANNsx3v/973/jvvvui9122y3r/r3ppptmrcoNtdlmm9U4Puigg7Lu0f/4xz+y49Sim66dulDXZo899sjGOae6JH/84x+zlvBddtmlqkzqnr3ttttm3cRTi/NZZ50V7777bpSql0KyOGO1Z8yYkY37Tl3WCz0K0vbTn/60ajx4be/XjAY8b8MNN6zaX2mllbKfkyZNyn4WWrxrk1rFUy+Mb37zmzVe45ZbblnoNZqCruYAAECDpK7R06dPb7LXbojUzTmFsbSlMdM/+MEPYtiwYTFo0KCsC3b1UJoUG1OdukRXl8LxTjvtlHUfT13Z0880g3pdk63tv//+WbkU2tPP73znO1WTtKWxzIccckg2i3gat5xmQ7/tttuy7tqlkGYoT9L458Yq/JunbvZpzHh1bdq0Kfp+TW/A86pPwla4SZDGbidp3Pai6vbAAw/E1772tRqPLe4wg1IQvAEAgAZJgWjBIFou1l133ar1qNPY3ySNYU7jjpPqE60tSgrKafx1Gof81ltvZYF6UeXTDYCxY8fGY489lrX4FowePTqbAC6Nay545513ohRScL3qqquy0F34PRsjreedxp+n3zX9Lnk/b0GpNTzNSp9uTtT275oCduoh0OTjuWsheAMAAM1OWjLsgAMOyCbiSoEtTVI2ZsyYuPTSS7OZvgstqKm1+uKLL85CaerSnLp319e+++6btXKnLc3EncJlXQYMGJC1lKfwmV6veutvmgwshcbUyr355ptnLbdp1vPG/u4fffRR1vX6lVdeiV/84hfx7LPPZtdcsIW5oVLoPeGEE7IW+dR9f9asWdn7mmYWHzJkSMmfV12akX6DDTaIH/3oR/HDH/4w60WQJldL/849evTIJok7+eSTsxsN2223XUydOjWbBT116a8+gVtTMMYbAABodtL43hRs0xJfKfCuv/76WVfzNJN2mlm7IC0NNmfOnGypsJNOOqlGK/SipDCfltx6+eWX69WSm3oKpNbx2sqnJc5SaDzuuOOyZb5SC3iqb2OkceNpfHQKqWl28bSE17/+9a/s5sDiSl3107JgI0aMyK6fWpfTmPlFdWH/QSOfV11aau2vf/1r9v6lmdm33nrruPfee6u666cZ5tN7lmY3T79zCvjpZsPidK8vlVZphrWmrkRzk9bpS3dy0h2WdHcFAADK2ZdffhkTJkzIAkwaMw3N/XM9rcSZTos3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAghkzIrp3j1ISvAEAgGbp888/j5NOOilWXXXV6NSpU2yzzTbx3HPP1SgzaNCgaNWqVY1tt912q3p81qxZcdhhh0W3bt3iG9/4Rvztb3+r8fzhw4fH8ccfX6/6TJs2LX7yk5/EOuusEx07dowVV1wxdtlll/jTn/4UFRUVWZmBAwdmdaZ5advUFQAAAMjDD37wg3jllVfid7/7XfTp0yd+//vfZ0H31Vdfja997WtV5VLQHjFiRNVxhw4dqvZvuOGGeP755+OZZ56Jhx56KL773e/GxIkTs4A+YcKEuPHGG2PMmDGLrMuUKVNiu+22i6lTp8ZPf/rT2HzzzaNt27bxxBNPxOmnnx477bRTLLvssjm8CywNBG8AAKDZ+eKLL+KPf/xj3HvvvTFgwIDs3Lnnnht//vOf41e/+lUWfqsH7dT6XJtx48bF//3f/8V6660Xq6++epx22mkxefLk6NmzZxxzzDFxySWXZK3hi3LmmWfG22+/Hf/5z3+ymwAFqRX94IMPzlrAab4EbwAAoPFjYYtp0yaiepisq2zr1hGdOi26bJcu9a7anDlzYu7cuQsF2tTl/O9//3uNc6NGjYpevXrFcsstl7U8p1C+wgorZI9ttNFGWYt5CvJ/+ctfYqWVVooePXrEyJEjs2vvs88+i6zLvHnz4rbbbotDDjmkRuguWGaZZer9e1GeBG8AAKBx6gqMe+wR8cAD84979YqYObP2sjvskNLv/OPVVouYPHnhcv8bB10fXbt2ja233jouuOCC6NevX/Tu3Tv+8Ic/ZF3G11xzzRrdzPfdd9/o27dvvPnmm1nL9O67756Va9OmTXz/+9+Pf/3rX7HuuutmgfuOO+6Izz77LM4555wssJ911llZqF5jjTXit7/9bY0u7AWphTw9J43tpmUSvAEAgGYptVSn4JzCcArRm266adatO43ZLjjooIOq9jfYYIPYcMMNsxCdQvXOO+8c7dq1i2uvvbbGdQcPHhwnnHBCvPjii3HPPffEyy+/HJdeeml2LnVvX1Bh4jRaLrOaAwAAjTN9evFtwQA6aVLxsg89VLPs22/XXq6BUoBOk5dNnz493nvvvXj22Wdj9uzZ2VjtYtJjqWX7jTfeqPXxxx9/PMaOHRvHHXdcFs732GOP6NKlSxx44IHZcW3SePA0cdr48eMb/DvQBNLwhPvvL+klBW8AAKBx0pjrYtuCk4XVVbb6+O66yja6ml2ysdmpu3cap7333nsXLfv+++/HJ598kpVf0JdffhnHHntsXH/99VkLehpDnoJ8kn6m49q0bt06a1lP48L/+9//LvR4ujGQxqSzlEjzE2y/fUkvKXgDAADNUgrZDz/8cLbs1yOPPBI77rhjNs46dRUvBN40S/k//vGPbMbxRx99NAvlaQz4rrvuutD10njx1MK9ySabZMfbbrtttgZ3GgN+zTXXZMfF/OxnP4uVV145ttxyy7jllluyJc1ef/31bFx4ul6qC82XMd4AAECzlNbMPuOMM7JW7OWXXz7222+/LACncdtJarVOofnmm2/O1tlOM45/61vfygJ29bW8k7QeeJpY7aWXXqo6t//++2fdy7fffvtYe+2149Zbby1al/T6KeBffPHF2azp77zzTjaLehpXPnz48OjevXuO7wQNknox3HBDlFKrCiP9S27atGnZfzjpP/T6rOkHAABLs9TFOrUap5m/rTdNs/9cz5gR05ZZJtKtkFJlOl3NAQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAA9WJBJJqTiiX4eRa8AQCAOhXWvZ45c2ZTVwVKpvB5Lny+q6Q13O+4o3QvFBFtS3o1AACg2WnTpk0su+yyMWnSpOy4c+fO0apVq6auFjS6pTuF7vR5Tp/r9PmuoW3biF13jVISvAEAgEVaccUVs5+F8A3lbtlll636XOdN8AYAABYptXCvtNJK0atXr5g9e3ZTVwcWS+pevlBLd0H6fI8cGaUkeAMAAPWWwkrRwALNwVdfRfzoRyW9pMnVAAAAIEeCNwAAAORIV3PKuwtIXeOLOnZMfaEaXjaVS+WLScsLpJkOG1p2zpyIWbOKl23fPg02aXjZuXMjvvyyeNlULpVvaFkAAKAktHhTvi68MGKZZYpvL7wwv+yVV9Zd9qmn5pe94Ya6y/7lL/PLpkkX6ip7993zy6b9uspWn8AhvUZdZVMdC1Ld6yqbfveC9J7UVTa9pwAsPb74ImLGjOJbdenGaqnKVlTML5tuBJeq7Lx588umG9elKptuLDemLMASIngDNaUvOmPHVm7Vv/QAsOTtvnvxm6W9etUsu99+dd9cre6ww+ouO3Pm/LJHH1132cmT55cdMqTusu++O7/sT35Sd9lx4/K/2Q6whOhqTnlJQbDwP+KhQyNOO63u7uMFJ55Y98yE1csedVTEoEF1dx8vOOSQiAMOqF/ZffaJmD69eNnqXbx33bX+Zbffvu6yhS7pyaabLrpsal1Zf/3K44kTI7p0qfl44bXTv0UqW0zqYl/4/VNrSPUvcYtTNg0JqP7vtWArTmPLtm4d0alT48qm+lZv8amuVauIzp0XLpvOpccAWPLSULFC77H0//3q/68EyEGriopi3xZprGnTpkX37t1j6tSp0a1bt6auTvOSwlDhrn0KkNVDIaV/jxd06qkRw4dX7r/9dkTfvsWvk250XHtt5f7HHy/cMlPd4YdH3HTTol8/2X//iDvvnH9cV3jdY4+IBx6Yf5w+L8VC/Q47RIwaNf+4Z8+arTjVbbZZxHPPzT9ebbWId96pvey661b2HihYb72IV1+N2HbbylYX4RuoS7rBWVfvo+r/H0zdx+vqRt2QstVvDqbu42nukVKUTTct083L+sy/0pCyDZ3XJf3+hf/XLHiTuaXM5bKoG+iluNnuJjPlas6cmDZyZHQfNKhkmU6LN1BT+p9kCoVPP93UNWne0vubvpi4eZSP2npOmESxtF+8faHOT7oBmW7oFW5y1vfvRPUePqUsmz7j1Xtwlaps+mzVd0LPvMomvXvXPL7//og996zcT/OvDB5c/Ll33DG/51uay+XAA4uXHTFifo+6NJfLXnsVL3vNNRHHHlu5n27S7rhj8bKXXjq/B2Dqcr/FFsXLDhsWce65lfupB2Ghh9uibranIQL1vdmebloXbra7yUy5atu2srdqXb1gG3rJkl0JaB7S/xzT/yRraxmu3hVvlVXq7rZeCCJJjx71L5u+zNdVthCcChpSdtKk4mULrSoF6ctufcumFuy6uppX98QTla3p5Cf9W2y3XcTo0TXPP/54xMCBlfupi+lxxxW/hi/ei/7ivfHG879QG1pS99CS+pSt3rKd6lOsxw2l4SbzkuEmM1QRvIHavxAu6n+S6ctoff9HWp/rNaZssjSUrf7leVGqf4EnH+lL3oKhm9J76aWIrl3rbu1a1NCS9G/VkKEldZVdcGhJqkN9h5ak1uX6Di1Jw0fqO7Rk880rb8zVZtVVa97gGzAgYsyY2suyZG8yN/e5XAr69at/2YbebE/d9xfsSQDlJPVKq746UQkI3gA0X9XHbppEsTRfvFMLbqpPCt7kK7XINuTGHg1Tnxu96b+B+k68lsJn9QBaqrKpN0d9bwY3pGxDbqDndbOdxVO915A5HEo7rCz1PCphN/NE8Aag+UpfRGr7AtiQL9O+eC9cNnVnr95SaGhJ7UNLUkt5fcs++eTCk6gZRw/Ud1hV9b81abnAu+4q/tzqExSn5QJvvrl42fS3tDBELi0X+MtfFi87YcL8+SnScoGXXVa87CuvVE44W1gu8Lzzipd99tnKHkSF5QJPP7142byGlZWA4A2wJKUv0amLaWG/ITMWm924fmVTAEtjnhNLBOWjrhYtQ0saV9YwFKAhDKsqO5YTy4HlxHKUvnCnO2jJz37WsFlLYWmU7uAWG9eZWg7TUmwF6Q5umpyt2Bf86hNEpTu4Dz5Y/HWr/+lP3ajre2c8dbuq753xNDFYfe+Mp4nB6ntnPE0MVt874wAseenGa2pJTa6/vv4z3VN/1ZdfTcOqqs+t0dxuqHdsgq7mhUzXp4/lxGihUtAuzLALAMDSJwWawiSK5G/BXjuWCyzNsLK6bl40ghbvHGjxBupNV/N874wD0HRKtQRgc1ousFT/r6/e4l29ZxpLbabT4k15SX+I0lqyhRl2F5z0BspNQ8Z1NqRsQ+52N+c74wA03Wzbab6N88+vvYzlAmsfVrb77vUfVkZZEbwpL+kuYN++lfvu7gEALJ3SkolPP93UtWi+0nfgdENi6lTLDpYJXc1zoKt5jnSrAQAorzWma6OreWmGlaWeZZYdzIWu5gAAwNLNcoFL17AympwBsgAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHJ1SgvbdtG/OhH8/cBAACWcpIL5aVDh6i45pqYmZZwmDOnciMXnTt3jlaWpwAAgMUmeFNW0rLz2223XYwePbqpq9LsbbvttvHUU08J3wAAsJiM8aaszJwxI/4zenT0aOqKtABPP/10Zc8CAABgsWjxprzMnBkf/2930ltvRZdevZq4Qs3PjBkzonfv3k1dDQAAaLJetuk7cSkJ3pStLl26ZBv5KfUfHOYzhh4AYOmUen326dOnpNcUvIGitHznxxh6AICWwxhvYKGW2BQKyZcx9AAALYcWb6CG1AKbWmKFwnwYQw8A0PII3kCt4dv4eQAAKA1dzQEAACBHWrwpL23bxk3/2z2grY8vAACw9JNcKC8dOsTg/+0e0KFDE1cGAPJbQ9ZcG/mztCOwpAjeAABLWejebrvtYvTo0U1dlWbP0o7AkmKMN+WloiI6pzvU/9sHgOYmtXQL3UuGpR2BJUWLN+Vl5syY8b/dGR9/HJFm3i7cpZ41K2LOnOLP7dy5/mU7dYpo/b/7Ul99FTF7dmnKduwY0aZNw8umcql8ManbfWHMe0PKpvcgvReLer8AaBITJ060ykQOLO0ILGmCN+WlWit3l9VXj5g+vTJ8J0cfHXHzzcWfO2lSRM+elftDhkT88pfFy06YELHaapX7P/lJxGWXFS/7yisR661XuX/hhRHnnVe87LPPRmy+eeX+lVdGnH568bKPPx4xcGDl/g03RBx3XPGy998fseeelfsjR0YMLoyEr8Udd0QccEDl/t13Rxx4YO3ltt024qmnhG+AJpRCt+ANUP50Nae86A625Dz9tPcbAABKoFVFmsGjjF177bUxfPjw+Oijj2KjjTaKq6++OrbYYoui5e+88844++yz4+2334611lorLrnkkthjjz2qHk9vx7Bhw+LGG2+MKVOmZJNu/OpXv8rK1te0adOie/fuMXXq1OjWrdti/47MN2PChMqW7rT/yivRZd11dTUvdVfz9PzUap5aWA45JKJdu+LXolHdG5dZZplsf/r06VqygIX4O5E/7zFQ378Rpcp0Zd3V/Pbbb48hQ4bEddddF1tuuWX84he/iF133TVee+216NWr10Ll00QlBx98cFx00UWx1157xa233hrf/va344UXXoj1118/K3PppZfGVVddFTfffHP07ds3C+npmq+++mp0TEGIpceCY5BToKzvEmMNKdu+feXWlGVT+K1vAG5I2RTAa1sP/dhj6/d8AACgebd4p7C9+eabxzXXXJMdz5s3L1ZeeeU4/vjjY+jQoQuV/853vpPdvbg/jYf9n6222io23njjLLynt6JPnz5xyimnxKmnnlp1hyNNvnHTTTfFQQcdVK96afFeQi3eb70VXfr2beoqQYNoZQEWxd+J/HmPgbpo8a7mq6++iueffz7OOOOMqnOtW7eOXXbZJZ555plan5POpxby6lJr9j333JPtT5gwIeuynq5RkAJ0CvjpufUN3gWfv/VWtOradeEHUivnssvWnPSrmNQaufzyjSs7eXK6G1F72dQ1ukePxpX99NO6u2lX723QkLJTptTdRbpXr+w/gk7/a+VON1rSRomlf6+//rVy/1vfqr1FnEZLn9nCerE+w0Bt/J3In/cYqEsefxPK9hv15MmTY+7cuQstBZGOx48fX+tzUqiurXw6X3i8cK5YmdrMmjUr26q3eGfX23//mF4Yo1vN1Ig4rNrxvanrQZFrp6WzDq5n2VSD/81Vnbk7IhZ+9UppZPF+1Y7/mHooFyk7NyL2qXZ8Z+qpXaRs6j6xd7XjP6QZWetZ9nfpRkcU93//W7/7mv+Nt+86cWJ0qCvU0zjps3zKKZX7d95Z/y751Ev6W1GYMyLd7Ovg/QUW4O/Ekn2Px40bZzhhTtq3b191gwPK7W/EGmusEW+++WbJrlm2wXtpksaMn1fXElKUTJpj+/sR0a9fv7i4eus+AEAjHHZY9eYQSin7vnbxxcI3lHPw7tGjR7Rp0yYmTpxY43w6XnHFFWt9TjpfV/nCz3RupZVWqlEmjQMvJnV3r96FPbV4p7HmK951V3Srpat5n/btY0wDupqPaUBX8xplF9F9fEwDuprXKLuI7uNjGtDVfEwDuppXL9u5c2d/xPMyY0bE669X7qcx9Ma9lVQaLvH6/97fNAmkcYWUK3+Hl8zfiTTRq78TpZfm9enZs2c28S75SZ/j3/3udz7DlOXf4VK2dpd18E5dV/r37x+PPvpoNjN5oS9+Oj7uuONqfc7WW2+dPX7SSSdVnXvkkUey84X/uaXwncoUgnYK0f/85z/jmGOOKVqX1AWstm5gXVdfPbrWZyB+bePAlaWppDH9hTkX035hqTRKIs1FUZjTsvoNPig36f+TTz31lPCdgy+++KLq70T6m5E2Si99fmfOTH3pyCO0FIZu+gxTjlrn8Jkt2+CdpFbmww8/PDbbbLNs7e60nFj6D33w4MHZ49/73vfia1/7WtYVPDnxxBNjhx12iMsvvzz23HPPuO2222LMmDFxww03ZI+nLw8plP/0pz/Nxv0UlhNLM50Xwj3A4rYSbrvttvH00083dVVgsbz00kvR1Q1Tylj63qclFlhSyjp4p+XBPv744zjnnHOyyc/S3feHH3646g7bu+++W+NuxTbbbJOt3X3WWWfFmWeemYXrNKN5YQ3v5PTTT8/C+1FHHRVTpkyJ7bbbLrumSTeAUn3R08pCOUstsdtvv30WvMlXukmXbtZBOUvfq8mPYT/lo6zX8V5aWcebspb+B/m/dQtj+nRjvIGFpK8Obh7lzxdqmsMayOTLsJ/8h0u0+HW8gZykdeavuaZyPy2HV9ed6nbtKssnc+dGfPll/cqmify++KI0ZdM644U5FtJ9xLrCQEPKpt+9ek+Xut6HhpRNvXA6dSr+OJQBXXSBuhhWteQY9lM+tHjnQIs3zcaoURE77lj88UsvjTjttMr9556L2GKL4mWHDYs499zK/bFjI6oN8VjIqadGDB9euf/225Wzqxfzox9FXHtt5f7HH6epwouXPfzwiJtuWrhlvzb771+5jnlBXXeS99gj4oEH5h+nQFIs1O+wQ+X7CgDNmJ4x+TLsZ8nR4g0AACyV9IzJ3wsvvODmRs6NqWmS7VLR4p0DLd40Gw3pPq6ref3K6moOANDiMp0Wb6DuQFnfu9UNKZvCZx5lU3fwPMompSqbQnnPnvO70WsNAABo9gRvgCVt8uSmrgEAAEvQ/EWuAQAAgJITvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCOzmgMsSWl5tM02m78PAECzJ3gDLEmdOkU891xT1wIAgCVIcwsAAADkSPAGAACAHAneAEvSzJkRq61WuaV9AACaPWO8AZakioqId96Zvw8AQLOnxRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHZjUHWJJatYpYd935+wAANHuCN8CS1LlzxNixlftpHe8ZM2ovl0J5KlvwxRcR8+YVv26XLo0r++WXEXPnlqZsqm/hZsKsWRFz5pSmbKdOEa3/10Hrq68iZs+uX1kAgKWEbycATWXzzSOWWab2rdAqXjBgQPGyq61Ws+zuuxcv26tXzbL77Ve8bNqqO+ywusumGwkFRx9dd9nJk+eXHTKk7rLvvju/7E9+UnfZceMW/98FAKDEtHgD0LykVvELL6zcP/HEiPbtaz7esWNEmzb1a0GvXjaVS+WL6dAhom3bhpdNrf2p1b+YVP927RpeNvVOSL0UiknlCu9NQ8qm3hSpV0X1XgsAQJ1aVVRUVNRdhIaaNm1adO/ePaZOnRrdunVr6uoAS6vUQlzsT7Cu5o3vap5+/wVb66t79tnK3gbJ8OERp59evOzjj0cMHFi5f+21EccdV7zs/fdH7Lln5f5NN0UMHly87B13RBxwQOX+nXdGHHhg8bIjRkQMGlS5/8ADEXvtVbzsNddEHHts5f6oURE77li87KWXRpx2WuX+c89FbLFF8bLDhkWce27lfhoqsf76EdtuG/HUU8I3AM3PV1/FtGHDovvFF5cs02nxBmgq1YP1oqRAmUfZ1KKbR9nUopu2UpdNra4LtmDX9r6mUPj00/W7Jg1TmJcgvb/p5lH1mzOUTropV334Rku4aVbfsqXstaLnBlCb9Pfi4oujlLR450CLN8BSGFoKdDVfvK7mn38eUfh/2/Tpgnden9/ttosYPbpmQKw+GWPqXfHgg3VfoyD1rrjrruJlq/87pt4VN99cvOykSRE9e1bup94Vv/xl8bITJsyfgyL1rrjssuJlX3klYr31KvdT74rzzlsyvVb03ABqM2NGTFtmmegeocUbAIpKX6LrEwjr04JePXwWQm0py6YAXgjhpSybbhjUNxQ3pKxZ4/OXbhpVD93kR88NYAnR4p0DLd4ANFup1bUwhl6Ld/7v8cSJ899jXc1L12slvce9e1fu+xwDC9LiDQDQgqRAWFsobI7zM+RdtiE9UQBKTPAGAFiapJbfHXaYv0/ppRsGaSWCwj5AzgRvAKD+UovhqafO36f0UrfrtBwc+UlzJRSW/wNYAgRvAKD+UrfeNJM0ADRXHTtGPPZYxE47leySgjcAAC1Lmmht5MjK/UMO0XsDqClNyti/f5SSgUMAQP3Nmxfx9tuVW9qn9NKM22mt7LRVX7ub0kmzmw8eXLkVZjoHyJEWbwCg/r74IqJv38p9yzDlZ/Lkpq4BQMv11VcRV15Z0ksK3gBA41RvjU2TVRVmh66oiJg5s/jzGlI2dfervhxWXS3ADSmbZgtPk5g1pmyqb6p3bdIa12mt68aUTTc1Ui8CrdwATT8c5ZxzSnpJXc0BgMbp3TtimWUqtyFDarbWFs7Xth19dM1gWlfZww6r+Zp1ld1vv5ple/UqXnb33WuWXW214mUHDKhZdt11i5fdfPOaZdNxsbLpOtWl10nn0/sKQLMieAMA9ZdaaLfdtqlr0TKk97l6izgAZUtXcwCg/lL36KeeWrh7eOo+XtCjR+X472Kql03Bsq6yqft4dQ0pO2lS3d3Hq0uTxdW37Kuv1t19vLrnnqt/2SefrDlhXXpvFiwDQFkSvAGAhklhsK5J1Rb1eGPLJktD2Ya0QjekbPVx5AA0K4I3AAAtS5rc74475u8D5EzwBgCgZUnDHQ44oKlrAbQgJlcDAACAgrQ05f33Rylp8QYAoGWZMyfi7rsr9/fZp+aEfwBt2kRsv31JL+mvDAAALcusWREHHjh/pnzBG8iZruYAAABQMHt2xA03RCkJ3gAAAFDw1VcRp50WpSR4AwAAQI4EbwAAAMiRmSQAACDNdJ4mXSumffuIdu0q9+fOjfjyy+JlU7lUvqFl582L+OKL0pRNE8Z16FC5X1ERMXNmacqm2Z7TUksFM2YUL9u5c0SrVsUfhxZE8AYAoGXq12/+/l/+ErHXXsXLXnNNxLHHVu4/9VTEjjsWL3vppfPHh77wQsQWWxQvO2xYxLnnVu6PGxex/vrFy556asTw4ZX7774b0bdv8bI/+lHEtddW7k+eHNGrV/Gyhx8ecdNNlfspdC+zTPGy++8fceed84/rKrvttpXvlfCdj7puklS/6ZFuKKUbS8V06hTRuvX8sc1pYrFSlE03aNKNmoaWnT27snwx6SZRYSWChpRtyM21ut6vRtLVHACAliWFkhQKTz89okuXpq5N89W9e91Bh8UL3dttV3njo7Yt3WwpGDKkeLm0pZs4BT/5Sd1l082hggsvrLtsuulUcOWVdZdNN2gK0mzidZVNN8kKRo6su+zdd88vm/brKpuuVVD9NUpEizcAAC1LaglMX/Srt2rtumvlmt7FFLp4J9tvX3fZQqtZsumm9S+bWuDrW3aVVeouW31t8h496l823ZSoq2yhVbKgrrLppkbqil6sO3pqOU0tqPXptr5g2dTSm8JnsX/f9Hs0pmzqvp+68RdT/UZNQ8qm4QZp2EEpyqb6pt9p9OjiZVg8OdyQa1VRUexTSGNNmzYtunfvHlOnTo1u3bo1dXUAAKDpAkyx7tA77BAxatT84549a7bUVrfZZhHPPTf/eLXVIt55p/ay664bMXbs/OP11ot49dXay666asTbb88/3nzziDFjai+bbmB8/PH844EDI554ong4rn4jYc89Ix58MIqqHskOOCDirruKl003O9LNkqOPrjy+4or5Y/Srv76u5ovV1Xzaxx9H9z59SpbptHgDAACUkxQoC+Py61N2wWBeV/is3rujKcq2a1ezd0epyqYAXr13x6LKlrjVW4t3DrR4AwBAA7uP62pev7Jmiy/LTKfFGwAAyEdDWg0bUrZ6WC5l2erhvpRlqy/BVsqylA2zmgMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAABgaQ/eU6dOjblz55biUgAAANCsNDp4jxkzJnbbbbfo3LlzrLDCCvHEE09k5ydPnhx77713jBo1qpT1BAAAgJYTvEePHh3bbbddvP7663HooYfGvHnzqh7r0aNH1gJ+/fXXl7KeAAAA0HKC95lnnhn9+vWLV199NS688MKFHt9xxx3jn//8ZynqBwAAAC0veD/33HMxePDg6NChQ7Rq1Wqhx7/2ta/FRx99VIr6AQAAQMsL3u3atavRvXxBH3zwQSyzzDKLUy8AAABoucF7q622irvuuqvWx2bMmBEjRoyIHXbYYXHrBgAAAC0zeJ933nnZrOZ77rlnPPTQQ9m5l19+OX79619H//794+OPP46zzz671HUFAACAstOqoqKiojFPfOyxx+KYY47JZjavbo011sgCeEtu8Z42bVp07949m929W7duTV0dAAAAmjDTtW3sE3faaad47bXX4qWXXsrCdxrznUJ3avGubcI1AAAAaIkaHbwLNt5442wDAAAASjTG+w9/+EMMGjSo6ONpqbE77rijMZcGAACAZqVRwfvnP/95toZ3MZ06dcrKAAAAQEvXqOCdxnZvsskmRR/faKONYvz48YtTLwAAAGi5wTtNhD5lypSij3/22Wcxe/bsxakXAAAAtNzgnVq70zjvr776aqHHZs2aFbfeemudLeIAAADQUjQqeA8dOjReeeWV2HHHHePPf/5zvPXWW9l23333xcCBA2Ps2LFZGQAAAGjpGrWc2O677x6/+c1v4sQTT4xvf/vbNbqgd+3aNW688cbYc889S1lPAAAAKEutKlJabqRp06bFI488Em+++WZ2vMYaa8S3vvWtLHy3ZOl96d69e0ydOjW6devW1NUBAACgCTNdo1q8C1IF9ttvv8WuBAAAADRXixW8P//883jnnXeyWcxrazgfMGDA4lweAAAAWubkap988kkcfPDBscIKK2RrdqcJ1dKWJltLW2E/T59++mkccsghWav7sssuG0cccURMnz69zud8+eWXceyxx2b1XmaZZbLW+okTJ9Yo06pVq4W22267LdffBQAAgOarUS3eRx55ZDab+QknnBDbb799LLfccrGkpdD94YcfZmPM05rhgwcPjqOOOipbyqyYk08+OR544IG48847s/76xx13XOy7777x9NNP1yg3YsSI2G233aqOU7AHAACAJTa5Wmot/tGPfhSXXnppNIVx48bFuuuuG88991xsttlm2bmHH3449thjj3j//fejT58+Cz0nDYrv2bNnFsz333//7Nz48eOjX79+8cwzz8RWW22VnUst3HfffXeN2dobyuRqAAAA5WtaiTNdo7qad+7cOVZbbbVoKikop1boQuhOdtlll2jdunX885//rPU5zz//fNYynsoVrLPOOrHKKqtk16sudUfv0aNHbLHFFvHb3/621vHr1c2aNSv7h6m+AQAAQKOD96GHHpq1CjeVjz76KHr16lXjXNu2bWP55ZfPHiv2nPbt2y/Ubbx37941nnP++efHHXfckXVhT2PAU8v+1VdfXWd9LrroouxuSGFbeeWVF+v3AwAAoIWP8U5dtZ944olsHHQaV52CZps2bRYqt+mmmzboukOHDo1LLrlkkd3M83T22WdX7W+yySYxY8aMGD58eDaevZgzzjgjhgwZUnWcWryFbwAAABodvLfbbruq/dQyvKDUNTuNlZ47d26DrnvKKafEoEGD6iyz+uqrx4orrhiTJk2qcX7OnDnZTOfpsdqk81999VVMmTKlRqt3mtW82HOSLbfcMi644IKsO3mHDh1qLZPOF3sMAACAlq1RwTvN+p2HNPlZ2hZl6623zgJ0Grfdv3//7Nxjjz0W8+bNy4JybVK5du3axaOPPpp1IU9ee+21ePfdd7PrFfPSSy9ls7YL1gAAACyx4H344YdHU0ozkadu7mlZs+uuuy6bNC0tDXbQQQdVzWj+wQcfxM477xy33HJLNklaGnud1vpOXcLTWPA0M93xxx+fhe7CjOZpibTUAp6OO3bsmLXmX3jhhXHqqac26e8LAABACwve1aW1tFO37zXXXDO6dOkSS8rIkSOzsJ3CdZrNPLViX3XVVVWPpzCeWrRnzpxZde7nP/95VdnUdXzXXXeNX/7yl1WPpxbxa6+9NlvvO3WXT7/TFVdckQV8AAAAWGLreCf33ntv/PjHP47XX389O06twzvttFNMnjw5vvnNb8Y555wT++yzT7RE1vEGAAAoX9OWhnW8U5fsfffdN1vretiwYTXWuU7nvva1r8VNN9202JUDAACActeo4J3Wuh4wYED8/e9/j2OPPXahx9O46RdffLEU9QMAAICWF7xfeeWVOPDAA4s+3rt374WW+wIAAICWqFHBu3PnzjFjxoyij7/11luxwgorLE69AAAAoOUG7x133DFuvvnmmDNnzkKPffTRR3HjjTfGt771rVLUDwAAAFpe8P7pT38a77//fmy++eZx/fXXR6tWreIvf/lLnHXWWbHBBhtkk62lSdcAAACgpWv0cmKvvvpqnHDCCfH444/XmNV84MCB2VrY/fr1i5bKcmIAAADla1qJM13bhj5h9uzZMW7cuFh++eXjb3/7W3z22WfxxhtvxLx582L11VePnj17LnalAAAAoMV2NW/dunX0798//vSnP2XHyy23XNblfMsttxS6AQAAYHGDd5s2bWLVVVeNWbNmNfSpAAAA0OI0anK1448/Pm644Yb49NNPS18jAAAAaEYaPMY7mTt3bnTo0CHWWGON2H///WO11VaLTp061SiTZjo/+eSTS1VPAAAAaDmzmqdx3ou8cKtWWUBvicxqDgAAUL6mNfWs5smECRMW+4UBAACgJWhU8E6TqwEAAAA5Be+CDz74IJ588smYNGlS7LfffvH1r389616emuNTs3yaAR0AAABaskbNap6GhQ8ZMiT69u0bhxxySLb/n//8J3ts+vTp2WRrV199danrCgAAAC0jeA8fPjyuvPLKOPXUU+ORRx7JgnhBauned999449//GMp6wkAAAAtJ3jfeOON8b3vfS8uvPDC2HjjjRd6fMMNN6xqAQcAAICWrFHB+7333ottttmm6ONdunTJpl8HAACAlq5RwbtXr15Z+C7m+eefj1VWWWVx6gUAAAAtN3inMdzXXXddvPXWW1XnWrVqlf3861//GjfddFMccMABpaslAAAAlKlWFdVnRquntFzYgAEDYsKECbH99tvHww8/HN/85jezGc2feeaZ2GSTTbJlxjp37hwtUepmnyaZS+9Tt27dmro6AAAANGGma1SLd6rAP/7xjzj99NOztbw7duwYTzzxREyZMiWGDRsWTz31VIsN3QAAANDgFu+rrroqdtttt/jGN76xqKJo8QYAAChr05qixfvkk0+OMWPGVB23adMmbr311sV+cQAAAGju6hW8l1tuuZg4cWLVcSOGhQMAAECL1LY+hQYOHBjnnntuvPTSS1lze3LLLbdk47yLSbOcX3nllaWrKQAAADTXMd6TJk2Kk046KR5//PFsP1nU01Lwnjt3brRExngDAACUr2lNMca7V69e2ZjuDz/8MAvTKXT//ve/j3nz5hXdWmroBgAAgAYH7yFDhsSLL75YdTxixIhsrW4AAACgBMH7F7/4RYwbN67q+Pvf/36NIA4AAAAsRvDu3bt3vPXWW1XHZjUHAACAEs5qvueee8b5558ff/3rX2PZZZfNzl1++eVx22231Tm52r333lvPagAAAEALDt5pWbA0wVqa1Xzs2LFZqH7vvffi008/LfqcVAYAAABaunotJ7ag1q1bZ7Oaf/e7382nVmXOcmIAAADla1qJM129WrwXlFq++/Xrt9gvDgAAAM1do4L3DjvsUPqaAAAAQEsN3n379s26l48fPz7atWuXHS9qDHd6/M033yxVPQEAAKD5Bu/Uwp2CdArf1Y8BAACAHCZXo24mVwMAAChf00qc6SqbsAEAAICm62r+5JNPNuriAwYMaNTzAAAAoEUF74EDB9YY0516p9dnjPfcuXMXr3YAAADQEoJ3Wre7ulmzZsXpp58eM2fOjKOOOirWXnvt7Hya9fzGG2+MLl26xKWXXppPjQEAAKC5T642ZMiQ+Pvf/551Qe/YsWONx1IYT7Oep27ml19+ebREJlcDAAAoX9OWhsnVRo4cGYcddthCoTvp3Llz9tjvf//7xa4cAAAAlLtGBe8ZM2bEhx9+WPTx9Fhq+QYAAICWrlHBe5dddokrr7wy/vSnPy302B//+MfssVQGAAAAWrpGjfH+4IMPYqeddoo33ngjVlpppVhzzTWz82+++Wb897//jTXWWCMee+yx+PrXvx4tkTHeAAAA5Wva0jDG+2tf+1q8/PLLccUVV8T6668fEydOzLb11lsvfv7zn2ePtdTQDQAAAIvd4k3dtHgDAACUr2lLQ4s3AAAAUD+CNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI7a1qfQ+eef3+ALt2rVKs4+++zG1AkAAABa1jrerVu3blTwnjt3brRE1vEGAAAoX9NKnOnq1eI9b968xX4hAAAAaImM8QYAAIAcCd4AAACQo3p1Na/Nv/71r7j66qvjhRdeyPq9L9gdPY3xfvPNN0tRRwAAAGhZLd6jRo2KLbbYIu6///7o06dPvPXWW7H66qtn+++8804ss8wyMWDAgNLXFgAAAFpC8D7nnHOyoP3aa6/FiBEjsnNnnnlm/P3vf4/Ro0fH+++/HwceeGCp6woAAAAtI3in7uVHHHFENq16mzZtsnOFpcO23HLLOProo63hDQAAAI0N3m3bto2uXbtm+8suu2y0a9cuJk2aVPV4ag1/9dVXS1dLAAAAaEnBe80114zXX3+9ahK1ddZZJ+6+++6qxx944IFYccUVS1dLAAAAaEnBe4899og//OEPMWfOnOx4yJAh8ac//SnWWmutbLvvvvuy7uYAAADQ0rWqqKioaOiTZs+eHdOmTYvll18+a/FOfv/738cf//jHbMz3XnvtFYMGDYqWKr033bt3z5ZZS+PgAQAAaLmZrlHBm7oJ3gAAAOVrWokzXaO6mp9++unx4osvLvaLAwAAQHPXqOB99dVXx2abbZaN507Lhv373/8ufc0AAACgpQbvtHTYiBEj4hvf+EZceumlsfHGG8d6660XF1xwQbz22mulryUAAACUqcUe4z1lypRsUrU77rgjHn/88Zg7d25ssMEGcdBBB8XQoUOjJTLGGwAAoHxNW5onV/vkk0/id7/7XQwbNiymT5+ehfCWSPAGAAAoX9NKnOnalqJSaXmxhx56KG6//fb485//nIXulVdeuRSXBgAAgLLW6OA9Z86c+Otf/5qF7XvvvTe7I7DSSivF4MGD4zvf+U5ss802pa0pAAAAtJTgfcQRR8Q999wTn332WfTo0SMOPvjgbEz3gAEDolWrVqWvJQAAALSk4J1C9z777JO1bO+0007Rpk2b0tcMAAAAWmrwnjhxYrRtW5Lh4QAAANCsNWodb6EbAAAA6qdeCbpv377RunXrGD9+fLRr1y47XtRY7vT4m2++Wc9qAAAAQAsO3jvssEMWpFP4rn4MAAAA1K1VRUVFxSLK0MSLrQMAAFC+ma5RY7zTiwMAAAA5Be9evXrF3nvvHbfeemtMnz69MZcAAACAFqFRwXvIkCExduzYOPTQQ7MQvv/++8edd94ZX3zxRelrCAAAAC11jPdzzz0Xt99+e9x1113x7rvvRpcuXWKvvfaK73znO7HHHntE+/btoyUyxhsAAKB8TStxpivZ5GrPPPNMVQj/8MMPs8p99tln0RIJ3gAAAOVrWokzXb2WE6uPrbfeOnr06BHLLbdcXHHFFVlFAQAAoKVr1Bjv6iZMmBAXX3xxbLrpprHOOuvET3/609hyyy3jhhtuiDx9+umnccghh2R3H5Zddtk44ogjFjnRW6rTwIEDs+ekdcinTJlSkusCAABASVu833vvvbjjjjuyruXPP/98FmK33377uPbaa2O//faLnj17Rt5SOE5d2h955JGYPXt2DB48OI466qhspvViZs6cGbvttlu2nXHGGSW7LgAAAJR0jHfr1q2zsL3VVltlE6kdcMABsdJKK8WSMm7cuFh33XWzyd0222yz7NzDDz+cTej2/vvvR58+fep8/qhRo2LHHXfMxqCnVu1SXbfAGG8AAIDyNa3Ema5RXc2HDx8eb7/9djz99NNxwgknLNHQXZjILQXmQjhOdtlll+yGwD//+c+l7roAAAC0XA0O3qm7dup2/cADD0RT+eijj7L1w6tr27ZtLL/88tljS/q6s2bNyu6IVN8AAACgUcG7c+fO2YRqqat5qQ0dOjS7bl3b+PHjl7p/uYsuuijrhlDYVl555aauEgAAAOU8uVqanOwvf/lLHH300SWtzCmnnBKDBg2qs8zqq68eK664YkyaNKnG+Tlz5mQzkqfHGqux100TtQ0ZMqTqOLV4C98AAAA0OnifffbZ2YRqhx12WBa++/btG506dVqoXOqi3RBpNvT6zIie1gxPS4GlGdX79++fnXvsscdi3rx52VJmjdXY63bo0CHbAAAAoGSzmlddoI4u53Pnzo287L777jFx4sS47rrrqpb9SpOiFZb9+uCDD2LnnXeOW265JbbYYovsXBqnnbYxY8bEkUceGU8++WR07do1VllllaqbBIu6bn2Y1RwAAKB8TStxpmtUi/c555yTyxjvhhg5cmQcd9xxWbhONwLS+uFXXXVV1eMpNL/22mvZZHAFKUyfd955VccDBgzIfo4YMaKqi/uirgsAAAC5t3hTNy3eAAAA5Wva0rCONwAAAJBjV/Pzzz9/kWVSV/Q0CRsAAAC0ZIs9udpCF2zVKtIl0888J1dbmulqDgAAUL6mLQ1dzdPyWgtuab3rN998M04++eRsFvAF18MGAACAlqhkY7xTK3haz/uyyy6LtdZaK44//vhSXRoAAADKVi6Tq6Vluh588ME8Lg0AAABlJZfgPWbMmDrHgQMAAEBL0ahZzW+55ZZaz0+ZMiWefPLJ+NOf/hQ/+MEPFrduAAAA0DKD96BBg4o+1qNHjxg6dGicc845i1MvAAAAaLnBe8KECQudS8uHLbfcctG1a9dS1AsAAABabvBeddVVS18TAAAAaIYaFbwXNH78+Ljzzjvjww8/jLXXXjsGDx5ckkXGAQAAoMUE72uuuSauuuqqGD16dDaOu+DPf/5zHHDAAfHVV19Vnbv66qvjH//4R41yAAAA0BLVe82v++67L9ZYY40aYXrOnDnZ7OVt2rSJESNGxL///e+4+OKL45133omf/exnedUZAAAAml/wfvXVV2Orrbaqce7xxx+Pjz/+OE4++eQ4/PDDY7311ovTTz89DjzwwHjwwQfzqC8AAAA0z+D9ySefxMorr1zj3KOPPprNZr7PPvvUOL/tttvGu+++W7paAgAAQHMP3r17946PPvqoxrmnnnoqOnfuHBtttFGN8+3bt882AAAAaOnqHbw322yzuPnmm+Pzzz/PjseOHRvPPvts7LrrrtG2bduFZjn/+te/XvraAgAAQHOd1XzYsGGx+eabx1prrZWN5X7++eezbuZnnHHGQmXvvvvu2GmnnUpdVwAAAGi+Ld4bbLBBPPbYY9G/f//473//m020liZQS8fVjRo1Kut+npYYAwAAgJauVUVFRUVTV6K5mTZtWnTv3j2mTp0a3bp1a+rqAAAA0ISZrt4t3gAAAEDDCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAOSobIP3p59+Goccckh069Ytll122TjiiCNi+vTpdT7nhhtuiIEDB2bPadWqVUyZMmWhMquttlr2WPXt4osvzvE3AQAAoDkr2+CdQvfYsWPjkUceifvvvz+efPLJOOqoo+p8zsyZM2O33XaLM888s85y559/fnz44YdV2/HHH1/i2gMAANBStI0yNG7cuHj44Yfjueeei8022yw7d/XVV8cee+wRl112WfTp06fW55100knZz1GjRtV5/a5du8aKK66YQ80BAABoacqyxfuZZ57JupcXQneyyy67ROvWreOf//znYl8/dS1fYYUVYpNNNonhw4fHnDlz6iw/a9asmDZtWo0NAAAAyrbF+6OPPopevXrVONe2bdtYfvnls8cWxwknnBCbbrppdq3Ro0fHGWeckXU3v+KKK4o+56KLLorzzjtvsV4XAACA5mmpavEeOnToQhObLbiNHz8+1zoMGTIkm4Btww03jB/+8Idx+eWXZ93YU6t2MSmcT506tWp77733cq0jAAAA5WOpavE+5ZRTYtCgQXWWWX311bPx15MmTapxPnUHTzOdl3ps9pZbbpld++23346111671jIdOnTINgAAAFiqg3fPnj2zbVG23nrrbCmw559/Pvr375+de+yxx2LevHlZUC6ll156KRs7vmDXdgAAACi74F1f/fr1y5YFO/LII+O6666L2bNnx3HHHRcHHXRQ1YzmH3zwQey8885xyy23xBZbbJGdS+O/0/bGG29kx//+97+zGcxXWWWVbEx3mrQtTc624447ZufT8cknnxyHHnpoLLfcck36OwMAAFCelqox3g0xcuTIWGeddbJwnZYR22677eKGG26oejyF8ddeey1bu7sghfQ0U3kK7MmAAQOy4/vuuy87Tt3Fb7vttthhhx1ivfXWi5/97GdZ8K5+XQAAAGiIVhUVFRUNegaLlJYT6969ezbRWrdu3Zq6OgAAADRhpivbFm8AAAAoB4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAAAAyJHgDQAAADkSvAEAACBHgjcAAADkSPAGAACAHAneAAAAkCPBGwAAAHIkeAMAAECOBG8AAADIkeANAAAAORK8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQo7IN3p9++mkccsgh0a1bt1h22WXjiCOOiOnTp9dZ/vjjj4+11147OnXqFKusskqccMIJMXXq1Brl3n333dhzzz2jc+fO0atXrzjttNNizpw5S+A3AgAAoDlqG2Uqhe4PP/wwHnnkkZg9e3YMHjw4jjrqqLj11ltrLf/f//432y677LJYd91145133okf/vCH2bm77rorKzN37twsdK+44ooxevTo7Prf+973ol27dnHhhRcu4d8QAACA5qBVRUVFRZSZcePGZeH5ueeei8022yw79/DDD8cee+wR77//fvTp06de17nzzjvj0EMPjRkzZkTbtm3joYceir322isL4717987KXHfddfHjH/84Pv7442jfvn29rjtt2rTo3r171pqeWuQBAAAoH6XOdGXZ1fyZZ57JupcXQneyyy67ROvWreOf//xnva9TeBNT6C5cd4MNNqgK3cmuu+6aveljx44t8W8BAABAS1CWXc0/+uijbPx1dSk8L7/88tlj9TF58uS44IILsu7p1a9bPXQnheO6rjtr1qxsKyiMG0+BHQAAgPJSyHKl6iC+VAXvoUOHxiWXXLLIbualeBPTWO7UXf3cc89d7OtddNFFcd555y10fuWVV17sawMAANA0Pvnkk6zLebMK3qecckoMGjSozjKrr756NvnZpEmTapxPM4+nmcvTY3X5/PPPY7fddouuXbvG3XffnU2cVpCe++yzz9YoP3HixKrHijnjjDNiyJAhVcdTpkyJVVddNZshvRT/SLCkpZtT6cbRe++9Z54CypLPMOXOZ5hy5zNMuZs6dWq2ElbqVV0KS1Xw7tmzZ7YtytZbb52F2+effz769++fnXvsscdi3rx5seWWW9b5ByCN2e7QoUPcd9990bFjx4Wu+7Of/SwL9YWu7GnW9PTHIrWOF5Oul7YFpdDtDw3lLH1+fYYpZz7DlDufYcqdzzDlrnXr0kyLVpaTq/Xr1y9rtT7yyCOzFuqnn346jjvuuDjooIOqZjT/4IMPYp111qlqwU6h+1vf+lY2g/lvfvOb7DiN205bWkYsSY+ngH3YYYfFyy+/HH/5y1/irLPOimOPPbbWYA0AAABl1eLdECNHjszC9s4775zdhdhvv/3iqquuqno8re392muvxcyZM7PjF154oWrG8zXXXLPGtSZMmBCrrbZatGnTJu6///445phjstbvLl26xOGHHx7nn3/+Ev7tAAAAaC7KNninvva33npr0cdTkK4+A93AgQPrNSNdGpv94IMPLlbdUuv4sGHDtJJTtnyGKXc+w5Q7n2HKnc8w5a5DiT/DrSpKNT86AAAA0DzGeAMAAEC5ELwBAAAgR4I3AAAA5EjwLrFrr702m9gtrRGe1hQvLGcGS7uLLrooNt988+jatWu2jv23v/3tbGUAKFcXX3xxtGrVKk466aSmrgo0SFoS9dBDD40VVlghOnXqFBtssEGMGTOmqasF9ZKW6T377LOjb9++2ed3jTXWiAsuuKBekxxDU3jyySfj//2//5ctS52+N9xzzz01Hk+f3XPOOSdWWmml7DO9yy67xOuvv97g1xG8S+j222+PIUOGZLPfpeXLNtpoo9h1111j0qRJTV01WKQnnngiW7P+H//4RzzyyCPZknxpbfsZM2Y0ddWgwZ577rm4/vrrY8MNN2zqqkCDfPbZZ7HttttGu3bt4qGHHopXX301Lr/88lhuueWaumpQL5dcckn86le/imuuuSbGjRuXHV966aVx9dVXN3XVoFbpu27KbakBtTbp85uWrb7uuuuy5anTktMp43355ZfREGY1L6HUwp1aDNMfmmTevHmx8sorx/HHHx9Dhw5t6upBg3z88cdZy3cK5AMGDGjq6kC9TZ8+PTbddNP45S9/GT/96U9j4403jl/84hdNXS2ol/R94emnn46nnnqqqasCjbLXXntF79694ze/+U3Vuf322y9rKfz973/fpHWDRUkt3nfffXfW8zNJUTm1hJ9yyilx6qmnZuemTp2afcZvuummOOigg+p9bS3eJfLVV1/F888/n3U9KGjdunV2/MwzzzRp3aAx0h+VZPnll2/qqkCDpJ4be+65Z42/x1Au7rvvvthss83igAMOyG5+brLJJnHjjTc2dbWg3rbZZpt49NFH4z//+U92/PLLL8ff//732H333Zu6atBgEyZMiI8++qjGd4ru3btnDa4NzXhtG/7y1Gby5MnZmJZ096O6dDx+/Pgmqxc0RuqtkcbFpu6O66+/flNXB+rttttuy4b6pK7mUI7eeuutrJtuGrp25plnZp/lE044Idq3bx+HH354U1cP6tVrY9q0abHOOutEmzZtsu/HP/vZz+KQQw5p6qpBg6XQndSW8QqP1ZfgDdTaYvjKK69kd6ihXLz33ntx4oknZnMUpAkuoVxvfKYW7wsvvDA7Ti3e6e9xGlsoeFMO7rjjjhg5cmTceuutsd5668VLL72U3cxP3XV9hmnJdDUvkR49emR39SZOnFjjfDpeccUVm6xe0FDHHXdc3H///fH444/H17/+9aauDtRbGu6TJrNM47vbtm2bbWmOgjQhStpPrS6wtEuz5q677ro1zvXr1y/efffdJqsTNMRpp52WtXqnsa9pRv7DDjssTj755Gz1FCg3hRxXiowneJdI6gLWv3//bExL9bvW6Xjrrbdu0rpBfaTJI1LoThNKPPbYY9kyIFBOdt555/j3v/+dta4UttRymLo3pv10cxSWdmmIz4JLOaaxsquuumqT1QkaYubMmdk8R9Wlv7/pezGUm/R9OAXs6hkvDaVIs5s3NOPpal5CaTxW6kKTvuhtscUW2Sy6aXr6wYMHN3XVoF7dy1O3sHvvvTdby7swbiVNIJFmIoWlXfrcLjgnQVryI62FbK4CykVqGUyTU6Wu5gceeGA8++yzccMNN2QblIO0HnIa073KKqtkXc1ffPHFuOKKK+L73/9+U1cNiq6G8sYbb9SYUC3dsE8TDKfPcRoqkVZJWWuttbIgntapT0MnCjOf15flxEosLSU2fPjwLLSkJWxSF8c06x2Uw/IJtRkxYkQMGjRoidcHSmHgwIGWE6PspOE+Z5xxRrz++uvZl7x0Y//II49s6mpBvXz++edZMEk96NLwnxRQDj744DjnnHOyHqKwtBk1alTsuOOOC51PDappybAUl4cNG5bdAJ0yZUpst9122ZKl3/jGNxr0OoI3AAAA5MgYbwAAAMiR4A0AAAA5ErwBAAAgR4I3AAAA5EjwBgAAgBwJ3gAAAJAjwRsAAAByJHgDAABAjgRvAGghbrrppmjVqlW8/fbbVecGDhyYbQBAfgRvACiDsFzbNnTo0KauHgBQD23rUwgAaFrnn39+9O3bt8a59ddfv8nqAwDUn+ANAGVg9913j80226ypqwEANIKu5gDQDDz22GOx/fbbR5cuXWLZZZeNvffeO8aNG9eoa02aNCmOOOKI6N27d3Ts2DE22mijuPnmm2uU2XTTTWPfffetcW6DDTbIusD/61//qjp3++23Z+fqqkttY8+TUaNGZefTz4I0Hj219D///POxzTbbRKdOnbKeANddd12jflcAWBIEbwAoA1OnTo3JkyfX2Ar+9re/xa677poF5nPPPTeGDBkSo0ePjm233XahMLsoX3zxRRZuf/e738UhhxwSw4cPj+7du8egQYPiyiuvrCqXQv7f//73quNPP/00xo4dG61bt46nnnqq6nza79mzZ/Tr1y9K5bPPPos99tgj+vfvH5deeml8/etfj2OOOSZ++9vfluw1AKCUBG8AKAO77LJLFmCrbwWnnXZaLL/88vHMM89k++ecc048+uijWVgfNmxYg17nhhtuyFqnR4wYEVdccUUcf/zx2bW23nrrOOuss+Lzzz+vCt4ff/xxVUv2008/He3bt4+99tproeC93XbbRSn997//jR//+Mdx9dVXV9Vv4403jjPOOCNmz55d0tcCgFIQvAGgDFx77bXxyCOP1NiSDz/8MF566aWsRTqF74INN9wwvvnNb8aDDz7YoNdJ5VdcccU4+OCDq861a9cuTjjhhJg+fXo88cQTVcE7efLJJ6sC9uabb569ZiF4T5kyJV555ZWqsqXStm3bOProo6uOU+BPx6nFP3VBB4CljeANAGVgiy22yFq9q2/JO++8k/1ce+21F3pO6t6duqTPmDGj3q+TrrfWWmtlXcYXvFb110vjv1O5QshOP1PAHjBgQNYi/dZbb2Wt4PPmzSt58O7Tp082lr26b3zjG9nPhnatB4AlQfAGABoldSFPgTuNC08tzSlgp4nP0uRu6Xzalllmmdhkk03qvE6aQK02c+fOzanmALBkCd4AUMZWXXXV7Odrr7220GPjx4+PHj16LNQ6vKjrvf7661lL9YLXqv56SQra7777btx2221ZSE6zjKeW8kIgT1s616ZNmzpfc7nllqvqml5doXV9QalFfcFW/P/85z/Zz9VWW63evysALCmCNwCUsZVWWimbWCwt91U9uKax1X/961+z2b8bIpX/6KOPsmXACubMmZNNZJZar3fYYYeq84Uu5Jdcckk2pjzNfl44nyY8GzNmTL26ma+xxho1xosnKcinid5qk+pz/fXXVx1/9dVX2XGacC7NdA4AS5u2TV0BAGDxpCW/dt9992zm8bT+dur6nYJyCsJpebGGOOqoo7IQmyZrS93HUwvyXXfdlY3X/sUvfhFdu3atKrvmmmtmE7Gl1vY0u3hBGuedZh1P6hO811tvvdhqq62yWcnTsmRpkrjUip4CdrEx3insp/HcaWx3ukmQJphLQT1NBAcASxst3gBQ5tJEaw8//HCssMIK2VJil112WRZkU1ju27dvg67VqVOnGDVqVLaGd2pFP+WUU7IwnJYXO/HEExcqXwjW1ZcMS63OnTt3zmYb33LLLev1uiNHjsy6pV988cVx4YUXxo477pjtF+uanmZfTy3qafm09957L6655po48sgjG/S7AsCS0qqioqJiib0aAMBiGDhwYDZTe+pKDwDlQos3AAAA5EjwBgAAgBwJ3gAAAJAjY7wBAAAgR1q8AQAAIEeCNwAAAORI8AYAAIAcCd4AAACQI8EbAAAAciR4AwAAQI4EbwAAAMiR4A0AAAA5ErwBAAAg8vP/AfjPtyZzNULIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-rank test p-value: 0.3873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data_censored.csv')\n",
    "\n",
    "# Create time and event variables\n",
    "df['time'] = df['period']\n",
    "df['event'] = df['outcome'] * (1 - df['censored'])\n",
    "\n",
    "# Split by treatment group\n",
    "treatment_group = df[df['treatment'] == 1]\n",
    "control_group = df[df['treatment'] == 0]\n",
    "\n",
    "# Fit Kaplan-Meier curves to each group\n",
    "kmf_treatment = KaplanMeierFitter()\n",
    "kmf_control = KaplanMeierFitter()\n",
    "\n",
    "kmf_treatment.fit(treatment_group['time'], treatment_group['event'], label='Treatment')\n",
    "kmf_control.fit(control_group['time'], control_group['event'], label='Control')\n",
    "\n",
    "# Create a timeline that includes all observed event times\n",
    "timeline = np.sort(np.unique(np.concatenate([\n",
    "    kmf_treatment.timeline,\n",
    "    kmf_control.timeline\n",
    "])))\n",
    "timeline = timeline[timeline <= 10]  # Limiting to the desired x-axis range\n",
    "\n",
    "# Calculate the survival difference at each time point\n",
    "treatment_survival = kmf_treatment.survival_function_at_times(timeline).values.flatten()\n",
    "control_survival = kmf_control.survival_function_at_times(timeline).values.flatten()\n",
    "survival_diff = treatment_survival - control_survival\n",
    "\n",
    "# Calculate confidence intervals using bootstrapping\n",
    "n_bootstraps = 100\n",
    "bootstrap_diffs = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    # Sample with replacement\n",
    "    treatment_sample = treatment_group.sample(n=len(treatment_group), replace=True)\n",
    "    control_sample = control_group.sample(n=len(control_group), replace=True)\n",
    "    \n",
    "    # Fit KM curves to bootstrap samples\n",
    "    kmf_t = KaplanMeierFitter()\n",
    "    kmf_c = KaplanMeierFitter()\n",
    "    \n",
    "    kmf_t.fit(treatment_sample['time'], treatment_sample['event'])\n",
    "    kmf_c.fit(control_sample['time'], control_sample['event'])\n",
    "    \n",
    "    # Calculate survival at each time point\n",
    "    t_surv = kmf_t.survival_function_at_times(timeline).values.flatten()\n",
    "    c_surv = kmf_c.survival_function_at_times(timeline).values.flatten()\n",
    "    \n",
    "    # Store difference\n",
    "    bootstrap_diffs.append(t_surv - c_surv)\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "ci_lower = np.percentile(bootstrap_diffs, 2.5, axis=0)\n",
    "ci_upper = np.percentile(bootstrap_diffs, 97.5, axis=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the survival difference as a step function\n",
    "plt.step(timeline, survival_diff, 'k-', where='post', label='Survival Difference')\n",
    "\n",
    "# Plot confidence intervals\n",
    "plt.step(timeline, ci_lower, 'r--', where='post', label='95% CI')\n",
    "plt.step(timeline, ci_upper, 'r--', where='post')\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel('Follow up', fontsize=12)\n",
    "plt.ylabel('Survival difference', fontsize=12)\n",
    "plt.ylim(-0.2, 0.05)\n",
    "plt.xlim(0, 10)\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('survival_difference_plot.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Calculate log-rank test\n",
    "results = logrank_test(treatment_group['time'], control_group['time'], \n",
    "                     treatment_group['event'], control_group['event'])\n",
    "print(f\"Log-rank test p-value: {results.p_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
