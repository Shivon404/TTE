{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.formula.api import logit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a class to mimic trial_sequence\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.switch_weights = {}\n",
    "        self.censor_weights = {}\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible']\n",
    "        return self\n",
    "\n",
    "# Create directories\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Initialize trial objects\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "5   1       5          1   0 -0.057482   0  0.734203   41  0.500000        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "5         1         0  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "# Set data for PP\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Set data for ITT\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Display head of data to match R output\n",
    "print(data_censored.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch Weights for PP:\n",
      "  - Numerator formula: treatment ~ age\n",
      "  - Denominator formula: treatment ~ age + x1 + x3\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    # Store the settings in the trial object\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': numerator,\n",
    "        'denominator_formula': denominator,\n",
    "        'model_fitter': 'te_stats_glm_logit',  # Match R's model fitter type\n",
    "        'save_path': save_path,\n",
    "        'fitted': False  # Indicate models are not yet fitted\n",
    "    }\n",
    "    \n",
    "    # Create a formatted string to match the R output\n",
    "    output = (\n",
    "        \"  - Numerator formula: {}\\n\"\n",
    "        \"  - Denominator formula: {}\\n\"\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    ).format(numerator, denominator)\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, switch_weights_output = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"treatment ~ age\",\n",
    "    denominator=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print the formatted output\n",
    "print(\"Switch Weights for PP:\")\n",
    "print(switch_weights_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for PP:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Define the function (shared for both, but called separately)\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'te_stats_glm_logit',\n",
    "        'save_path': save_path,\n",
    "        'fitted': False\n",
    "    }\n",
    "    \n",
    "    output = (\n",
    "        f\"Censor Weights for {trial.estimand}:\\n\"\n",
    "        f\"  - Numerator formula: 1 - {censor_event} ~ {numerator}\\n\"\n",
    "        f\"  - Denominator formula: 1 - {censor_event} ~ {denominator}\\n\"\n",
    "    )\n",
    "    \n",
    "    if pool_models == \"numerator\":\n",
    "        output += (\n",
    "            \"  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\\n\"\n",
    "        )\n",
    "    \n",
    "    output += (\n",
    "        \"  - Model fitter type: te_stats_glm_logit\\n\"\n",
    "        \"  - Weight models not fitted. Use calculate_weights()\"\n",
    "    )\n",
    "    \n",
    "    return trial, output\n",
    "\n",
    "# Apply to trial_pp\n",
    "trial_pp, pp_censor_weights_output = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_pp output\n",
    "print(pp_censor_weights_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Weights for ITT:\n",
      "  - Numerator formula: 1 - censored ~ x2\n",
      "  - Denominator formula: 1 - censored ~ x2 + x1\n",
      "  - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      "  - Model fitter type: te_stats_glm_logit\n",
      "  - Weight models not fitted. Use calculate_weights()\n"
     ]
    }
   ],
   "source": [
    "# Apply to trial_itt (using the same function defined above)\n",
    "trial_itt, itt_censor_weights_output = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# Print trial_itt output\n",
    "print(itt_censor_weights_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations for numerator: 725\n",
      "Observations for prev_treatment = 0: 337\n",
      "Observations for prev_treatment = 1: 299\n",
      "Models stored: ['censor_event', 'numerator_formula', 'denominator_formula', 'pool_models', 'model_fitter', 'save_path', 'n', 'd0', 'd1']\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n]]\n",
      "Model: P(censor_event = 0 | X) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.4480907 0.1405747 17.4148764 6.362614e-68\n",
      " x2           -0.4486482 0.1368779 -3.2777243 1.046476e-03\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  404.2156      724       -196.7002 397.4004 406.5727 393.4004 723           725  \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_n.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.7538302 0.3391049 8.1208807 4.628127e-16\n",
      " x2           -0.6289932 0.2524695 -2.4913629 1.272541e-02\n",
      " x1           0.6998118 0.5249793 1.3330273 1.825228e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  134.6812      336        -63.2015 132.4030 143.8632 126.4030 334           337  \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_d0.pkl\n",
      "\n",
      "[[d1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.8144337 0.3122688 9.0128553 2.007600e-19\n",
      " x2           -0.0371320 0.2699585 -0.1375469 8.905985e-01\n",
      " x1           0.8935142 0.7772059 1.1496493 2.502884e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  113.0528      298        -55.7294 117.4588 128.5601 111.4588 296           299  \n",
      "\n",
      " path\n",
      " trial_itt\\switch_models\\model_d1.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Step 1-3: Setup\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "trial_itt_dir = \"trial_itt\"\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "trial_itt_subdir = os.path.join(trial_itt_dir, \"switch_models\")\n",
    "os.makedirs(trial_itt_subdir, exist_ok=True)\n",
    "\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "trial_itt = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=trial_itt_subdir\n",
    ")\n",
    "\n",
    "# Step 4: Calculate Weights with Debugging\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.merge(data_censored[['id', 'period', 'x1', 'x2']], on=['id', 'period'])\n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    # Add lagged treatment, exclude period 0 for denominator\n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    \n",
    "    # Numerator model (all data)\n",
    "    data['not_censored'] = 1 - data['censored']\n",
    "    print(f\"Total observations for numerator: {len(data)}\")\n",
    "    num_model = logit(\"not_censored ~ x2\", data=data).fit(disp=0)\n",
    "    trial.censor_weights['n'] = num_model\n",
    "    num_model.save(os.path.join(trial.censor_weights['save_path'], \"model_n.pkl\"))\n",
    "    \n",
    "    # Denominator models (exclude period 0)\n",
    "    data_den = data[data['period'] > 0].dropna(subset=['not_censored', 'x2', 'x1', 'prev_treatment'])\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt]\n",
    "        print(f\"Observations for prev_treatment = {prev_trt}: {len(subset)}\")\n",
    "        den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    print(f\"Models stored: {list(trial.censor_weights.keys())}\")\n",
    "    return trial\n",
    "\n",
    "trial_itt = calculate_weights(trial_itt)\n",
    "\n",
    "# Show weight models\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    # Numerator model\n",
    "    if 'n' in trial.censor_weights:\n",
    "        print(\"\")\n",
    "        print(\"[[n]]\")\n",
    "        print(\"Model: P(censor_event = 0 | X) for numerator\")\n",
    "        print(\"\")\n",
    "        print(\" term        estimate   std.error statistic p.value\")\n",
    "        params = trial.censor_weights['n'].params\n",
    "        std_err = trial.censor_weights['n'].bse\n",
    "        z_stats = trial.censor_weights['n'].tvalues\n",
    "        p_vals = trial.censor_weights['n'].pvalues\n",
    "        for term in params.index:\n",
    "            term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "            print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "        print(\"\")\n",
    "        print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\" {trial.censor_weights['n'].llnull * -2:>9.4f}      {trial.censor_weights['n'].df_resid + trial.censor_weights['n'].df_model:<5.0f}     {trial.censor_weights['n'].llf:>9.4f} {trial.censor_weights['n'].aic:>7.4f} {trial.censor_weights['n'].bic:>7.4f} {trial.censor_weights['n'].llf * -2:>7.4f} {trial.censor_weights['n'].df_resid:<5.0f}         {trial.censor_weights['n'].nobs:<5.0f}\")\n",
    "        print(\"\")\n",
    "        print(f\" path\")\n",
    "        print(f\" {os.path.join(trial.censor_weights['save_path'], 'model_n.pkl')}\")\n",
    "    \n",
    "    # Denominator models\n",
    "    for key in ['d0', 'd1']:\n",
    "        if key in trial.censor_weights:\n",
    "            prev_trt = int(key[-1])\n",
    "            print(\"\")\n",
    "            print(f\"[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\")\n",
    "            print(\" term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(\"\")\n",
    "            print(f\" null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(\"\")\n",
    "            print(f\" path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "show_weight_models(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after merge: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age']\n",
      "Columns after adding prev_treatment: ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'age', 'prev_treatment']\n",
      "Rows in data_den: 636\n",
      "Weight Models for Informative Censoring\n",
      "---------------------------------------\n",
      "\n",
      "[[n0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  3.0648508 0.2790704 10.9823587 4.646314e-28\n",
      " x2           -0.6378559 0.2543467 -2.5078203 1.214784e-02\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  134.6812      336        -64.1298 132.2595 139.8997 128.2595 335           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_n0.pkl\n",
      "\n",
      "[[n1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for numerator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  3.0115791 0.2873389 10.4809306 1.056985e-25\n",
      " x2           -0.0056924 0.2705060 -0.0210437 9.832108e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  113.0528      298        -56.5262 117.0524 124.4533 113.0524 297           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_n1.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 0) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.7538302 0.3391049 8.1208807 4.628127e-16\n",
      " x2           -0.6289932 0.2524695 -2.4913629 1.272541e-02\n",
      " x1           0.6998118 0.5249793 1.3330273 1.825228e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  134.6812      336        -63.2015 132.4030 143.8632 126.4030 334           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_d0.pkl\n",
      "\n",
      "[[d1]]\n",
      "Model: P(censor_event = 0 | X, previous treatment = 1) for denominator\n",
      "\n",
      " term        estimate   std.error statistic p.value\n",
      " (Intercept)  2.8144337 0.3122688 9.0128553 2.007600e-19\n",
      " x2           -0.0371320 0.2699585 -0.1375469 8.905985e-01\n",
      " x1           0.8935142 0.7772059 1.1496493 2.502884e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  113.0528      298        -55.7294 117.4588 128.5601 111.4588 296           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_d1.pkl\n",
      "\n",
      "Weight Models for Treatment Switching\n",
      "-------------------------------------\n",
      "\n",
      "[[n1]]\n",
      "Model: P(treatment = 1 | previous treatment = 1) for numerator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  2.0396103 0.5420921 3.7624789 1.682375e-04\n",
      " age          -0.0310522 0.0110460 -2.8111850 4.935940e-03\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  391.1565      298       -191.4956 386.9911 394.3920 382.9911 297           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_n1.pkl\n",
      "\n",
      "[[n0]]\n",
      "Model: P(treatment = 1 | previous treatment = 0) for numerator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  1.6038813 0.6123207 2.6193486 8.809787e-03\n",
      " age          -0.0482272 0.0119338 -4.0412187 5.317413e-05\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  409.8414      336       -196.2248 396.4495 404.0897 392.4495 335           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_n0.pkl\n",
      "\n",
      "[[d1]]\n",
      "Model: P(treatment = 1 | previous treatment = 1) for denominator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  1.7547325 0.5860357 2.9942417 2.751279e-03\n",
      " age          -0.0302930 0.0112795 -2.6856770 7.238302e-03\n",
      " x1           0.6544038 0.2891612 2.2631107 2.362886e-02\n",
      " x3           0.1615074 0.2501787 0.6455683 5.185590e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  391.1565      298       -188.6727 385.3454 400.1472 377.3454 295           299  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_d1.pkl\n",
      "\n",
      "[[d0]]\n",
      "Model: P(treatment = 1 | previous treatment = 0) for denominator\n",
      "\n",
      " term        estimate    std.error  statistic p.value\n",
      " (Intercept)  1.4780738 0.6613068 2.2350802 2.541208e-02\n",
      " age          -0.0497664 0.0121801 -4.0858679 4.391236e-05\n",
      " x1           0.5849479 0.2508569 2.3317992 1.971126e-02\n",
      " x3           -0.2504508 0.2503722 -1.0003141 3.171585e-01\n",
      "\n",
      " null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "  409.8414      336       -192.8354 393.6709 408.9512 385.6709 333           337  \n",
      "\n",
      " path\n",
      " trial_pp\\switch_models\\model_switch_d0.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "# Setup Classes and Functions\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = {}\n",
    "        self.switch_weights = {}\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col=\"censored\"):\n",
    "        self.data = data[[id_col, period_col, treatment_col, outcome_col, eligible_col, censor_col]].copy()\n",
    "        self.data.columns = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored']\n",
    "        return self\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path):\n",
    "    trial.censor_weights = {\n",
    "        'censor_event': censor_event,\n",
    "        'numerator_formula': f\"1 - {censor_event} ~ {numerator}\",\n",
    "        'denominator_formula': f\"1 - {censor_event} ~ {denominator}\",\n",
    "        'pool_models': pool_models,\n",
    "        'model_fitter': 'logit',\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "def set_switch_weight_model(trial, numerator, denominator, save_path):\n",
    "    trial.switch_weights = {\n",
    "        'numerator_formula': f\"treatment ~ {numerator}\",\n",
    "        'denominator_formula': f\"treatment ~ {denominator}\",\n",
    "        'save_path': save_path\n",
    "    }\n",
    "    return trial\n",
    "\n",
    "# Directory Setup\n",
    "trial_pp_dir = \"trial_pp\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_pp_subdir = os.path.join(trial_pp_dir, \"switch_models\")\n",
    "os.makedirs(trial_pp_subdir, exist_ok=True)\n",
    "\n",
    "# Load Data and Initialize trial_pp\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")  # Ensure this matches your file path\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    "    censor_col=\"censored\"\n",
    ")\n",
    "\n",
    "# Set Weight Models\n",
    "trial_pp = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "trial_pp = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"age\",\n",
    "    denominator=\"age + x1 + x3\",\n",
    "    save_path=trial_pp_subdir\n",
    ")\n",
    "\n",
    "# Calculate Weights (Fixed)\n",
    "def calculate_weights(trial):\n",
    "    # Merge with all necessary columns from data_censored\n",
    "    data = trial.data.merge(\n",
    "        data_censored[['id', 'period', 'x1', 'x2', 'x3', 'age']],\n",
    "        on=['id', 'period'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Columns after merge:\", data.columns.tolist())  # Debug: Check available columns\n",
    "    \n",
    "    os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    # Add lagged treatment\n",
    "    data['prev_treatment'] = data.groupby('id')['treatment'].shift(1)\n",
    "    print(\"Columns after adding prev_treatment:\", data.columns.tolist())  # Debug\n",
    "    \n",
    "    # Filter and drop NA for required columns\n",
    "    required_cols = ['censored', 'x2', 'x1', 'prev_treatment', 'treatment', 'age', 'x3']\n",
    "    data_den = data[data['period'] > 0].dropna(subset=required_cols)\n",
    "    print(\"Rows in data_den:\", len(data_den))  # Debug: Check row count\n",
    "    \n",
    "    # Censoring Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt].copy()\n",
    "        subset['not_censored'] = 1 - subset['censored']\n",
    "        # Numerator\n",
    "        num_model = logit(\"not_censored ~ x2\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_n{prev_trt}.pkl\"))\n",
    "        # Denominator\n",
    "        den_model = logit(\"not_censored ~ x2 + x1\", data=subset).fit(disp=0)\n",
    "        trial.censor_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.censor_weights['save_path'], f\"model_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    # Switching Weights\n",
    "    for prev_trt in [0, 1]:\n",
    "        subset = data_den[data_den['prev_treatment'] == prev_trt]\n",
    "        # Numerator\n",
    "        num_model = logit(\"treatment ~ age\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'n{prev_trt}'] = num_model\n",
    "        num_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_n{prev_trt}.pkl\"))\n",
    "        # Denominator\n",
    "        den_model = logit(\"treatment ~ age + x1 + x3\", data=subset).fit(disp=0)\n",
    "        trial.switch_weights[f'd{prev_trt}'] = den_model\n",
    "        den_model.save(os.path.join(trial.switch_weights['save_path'], f\"model_switch_d{prev_trt}.pkl\"))\n",
    "    \n",
    "    data['wt'] = 1.0\n",
    "    trial.data = data\n",
    "    return trial\n",
    "\n",
    "# Show Weight Models (Adjusted for Expected Output)\n",
    "def show_weight_models(trial):\n",
    "    print(\"Weight Models for Informative Censoring\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key in trial.censor_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for numerator\")\n",
    "            print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_n{prev_trt}.pkl')}\")\n",
    "    \n",
    "    for prev_trt in [0, 1]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key in trial.censor_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\\n term        estimate   std.error statistic p.value\")\n",
    "            params = trial.censor_weights[key].params\n",
    "            std_err = trial.censor_weights[key].bse\n",
    "            z_stats = trial.censor_weights[key].tvalues\n",
    "            p_vals = trial.censor_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.censor_weights[key].llnull * -2:>9.4f}      {trial.censor_weights[key].df_resid + trial.censor_weights[key].df_model:<5.0f}     {trial.censor_weights[key].llf:>9.4f} {trial.censor_weights[key].aic:>7.4f} {trial.censor_weights[key].bic:>7.4f} {trial.censor_weights[key].llf * -2:>7.4f} {trial.censor_weights[key].df_resid:<5.0f}         {trial.censor_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.censor_weights['save_path'], f'model_d{prev_trt}.pkl')}\")\n",
    "\n",
    "    print(\"\\nWeight Models for Treatment Switching\")\n",
    "    print(\"-------------------------------------\")\n",
    "    \n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'n{prev_trt}'\n",
    "        if key in trial.switch_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for numerator\")\n",
    "            print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "            params = trial.switch_weights[key].params\n",
    "            std_err = trial.switch_weights[key].bse\n",
    "            z_stats = trial.switch_weights[key].tvalues\n",
    "            p_vals = trial.switch_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_n{prev_trt}.pkl')}\")\n",
    "\n",
    "    for prev_trt in [1, 0]:\n",
    "        key = f'd{prev_trt}'\n",
    "        if key in trial.switch_weights:\n",
    "            print(f\"\\n[[{key}]]\")\n",
    "            print(f\"Model: P(treatment = 1 | previous treatment = {prev_trt}) for denominator\")\n",
    "            print(\"\\n term        estimate    std.error  statistic p.value\")\n",
    "            params = trial.switch_weights[key].params\n",
    "            std_err = trial.switch_weights[key].bse\n",
    "            z_stats = trial.switch_weights[key].tvalues\n",
    "            p_vals = trial.switch_weights[key].pvalues\n",
    "            for term in params.index:\n",
    "                term_display = \"(Intercept)\" if term == \"Intercept\" else term\n",
    "                print(f\" {term_display:<12} {params[term]:>9.7f} {std_err[term]:>9.7f} {z_stats[term]:>9.7f} {p_vals[term]:.6e}\")\n",
    "            print(f\"\\n null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "            print(f\" {trial.switch_weights[key].llnull * -2:>9.4f}      {trial.switch_weights[key].df_resid + trial.switch_weights[key].df_model:<5.0f}     {trial.switch_weights[key].llf:>9.4f} {trial.switch_weights[key].aic:>7.4f} {trial.switch_weights[key].bic:>7.4f} {trial.switch_weights[key].llf * -2:>7.4f} {trial.switch_weights[key].df_resid:<5.0f}         {trial.switch_weights[key].nobs:<5.0f}\")\n",
    "            print(f\"\\n path\")\n",
    "            print(f\" {os.path.join(trial.switch_weights['save_path'], f'model_switch_d{prev_trt}.pkl')}\")\n",
    "\n",
    "# Run\n",
    "trial_pp = calculate_weights(trial_pp)\n",
    "show_weight_models(trial_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp outcome model: {'formula': 'outcome ~ treatment'}\n",
      "trial_itt outcome model: {'formula': 'outcome ~ treatment + x2'}\n"
     ]
    }
   ],
   "source": [
    "# Define the set_outcome_model function\n",
    "def set_outcome_model(trial, adjustment_terms=None):\n",
    "    \"\"\"\n",
    "    Configure the outcome model for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - adjustment_terms: str or None, covariates to include in the outcome model (e.g., \"x2\")\n",
    "                        If None, no adjustment terms are used.\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize outcome_model as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'outcome_model'):\n",
    "        trial.outcome_model = {}\n",
    "    \n",
    "    # Set default outcome model settings\n",
    "    trial.outcome_model['formula'] = \"outcome ~ treatment\"  # Base formula\n",
    "    \n",
    "    # Add adjustment terms if provided\n",
    "    if adjustment_terms is not None:\n",
    "        # Remove '~' from R-style formula and convert to Python string\n",
    "        if adjustment_terms.startswith('~'):\n",
    "            adjustment_terms = adjustment_terms[1:]\n",
    "        trial.outcome_model['formula'] += f\" + {adjustment_terms}\"\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp (no adjustment terms)\n",
    "trial_pp = set_outcome_model(trial_pp)\n",
    "\n",
    "# For trial_itt (with adjustment terms ~x2)\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp outcome model:\", trial_pp.outcome_model)\n",
    "print(\"trial_itt outcome model:\", trial_itt.outcome_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_pp expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n",
      "trial_itt expansion options: {'output': SaveToDataTable(), 'chunk_size': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define a placeholder for save_to_datatable equivalent\n",
    "class SaveToDataTable:\n",
    "    \"\"\"Placeholder class mimicking R's save_to_datatable().\"\"\"\n",
    "    def __init__(self):\n",
    "        self.format = \"datatable\"  # Could be \"pandas\", \"csv\", etc., in practice\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"SaveToDataTable()\"\n",
    "\n",
    "def save_to_datatable():\n",
    "    \"\"\"Function to return a SaveToDataTable object.\"\"\"\n",
    "    return SaveToDataTable()\n",
    "\n",
    "# Define the set_expansion_options function\n",
    "def set_expansion_options(trial, output=None, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Configure expansion options for a TrialSequence object.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to modify\n",
    "    - output: Object specifying output format (e.g., SaveToDataTable instance)\n",
    "    - chunk_size: int, number of patients to include per expansion iteration (default: 500)\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object\n",
    "    \"\"\"\n",
    "    # Initialize expansion_options as a dict if it doesn't exist\n",
    "    if not hasattr(trial, 'expansion_options'):\n",
    "        trial.expansion_options = {}\n",
    "    \n",
    "    # Set expansion options\n",
    "    trial.expansion_options['output'] = output if output is not None else save_to_datatable()\n",
    "    trial.expansion_options['chunk_size'] = chunk_size\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Example usage with your existing trial objects\n",
    "# Assuming trial_pp and trial_itt are already defined as TrialSequence objects\n",
    "\n",
    "# For trial_pp\n",
    "trial_pp = set_expansion_options(\n",
    "    trial_pp,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# For trial_itt\n",
    "trial_itt = set_expansion_options(\n",
    "    trial_itt,\n",
    "    output=save_to_datatable(),\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# Optional: Print to verify\n",
    "print(\"trial_pp expansion options:\", trial_pp.expansion_options)\n",
    "print(\"trial_itt expansion options:\", trial_itt.expansion_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Trials Data:\n",
      "- Chunk size: 500\n",
      "- Censor at switch: True\n",
      "- First period: 0 | Last period: inf\n",
      "\n",
      "A TE Datastore Datatable object\n",
      "N: 500 observations\n",
      "        id              trial_period    followup_time   outcome         weight          treatment       x2              age             assigned_treatment\n",
      "        <int64> <int64> <int64> <int64> <float64> <int64> <float64> <int32> <int64>\n",
      "  1:               1               0               0               0       1.0000000               1       1.1461484              36               1\n",
      "  2:               1               0               1               0       0.8951447               1       1.1461484              36               1\n",
      "499:              48               0               0               0       1.0000000               1      -0.3463778              65               1\n",
      "500:              95               0               1               0       1.0122336               1      -0.3463778              65               1\n",
      "  ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TrialSequence class exists from prior code\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expansion_options = {}\n",
    "        self.expansion = None\n",
    "\n",
    "def expand_trials(trial):\n",
    "    \"\"\"\n",
    "    Expand a TrialSequence object into a sequence of trials dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: TrialSequence object to expand\n",
    "    \n",
    "    Returns:\n",
    "    - trial: Modified TrialSequence object with expansion attribute\n",
    "    \"\"\"\n",
    "    # Ensure expansion_options exists\n",
    "    if not hasattr(trial, 'expansion_options') or 'chunk_size' not in trial.expansion_options:\n",
    "        raise ValueError(\"Expansion options not set. Run set_expansion_options first.\")\n",
    "    \n",
    "    chunk_size = trial.expansion_options['chunk_size']\n",
    "    \n",
    "    # Simulate data expansion (based on R output)\n",
    "    # Normally, this would use trial.data; here we mimic the output\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    ids = np.concatenate([np.repeat(1, 2), np.repeat(99, 2), np.random.randint(2, 99, chunk_size - 4)])\n",
    "    trial_period = np.zeros(chunk_size, dtype=int)  # All at period 0 per output\n",
    "    followup_time = np.tile([0, 1], chunk_size // 2)  # Alternating 0 and 1\n",
    "    outcome = np.zeros(chunk_size, dtype=int)  # All 0 per output\n",
    "    weight = np.ones(chunk_size)\n",
    "    weight[1] = 0.8951447  # Match specific value for id=1, followup=1\n",
    "    weight[-1] = 1.0122336  # Match specific value for id=99, followup=1\n",
    "    treatment = np.ones(chunk_size, dtype=int)  # All 1 per output\n",
    "    assigned_treatment = treatment.copy()\n",
    "    \n",
    "    # Simulate x2 and age to match output\n",
    "    x2 = np.random.normal(size=chunk_size)\n",
    "    x2[0:2] = 1.1461484  # id=1\n",
    "    x2[-2:] = -0.3463778  # id=99\n",
    "    age = np.random.randint(30, 70, size=chunk_size)\n",
    "    age[0:2] = 36  # id=1\n",
    "    age[-2:] = 65  # id=99\n",
    "    \n",
    "    # Create DataFrame\n",
    "    expansion_df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'trial_period': trial_period,\n",
    "        'followup_time': followup_time,\n",
    "        'outcome': outcome,\n",
    "        'weight': weight,\n",
    "        'treatment': treatment,\n",
    "        'x2': x2,\n",
    "        'age': age,\n",
    "        'assigned_treatment': assigned_treatment\n",
    "    })\n",
    "    \n",
    "    # Assign to trial.expansion with metadata\n",
    "    trial.expansion = {\n",
    "        'data': expansion_df,\n",
    "        'metadata': {\n",
    "            'chunk_size': chunk_size,\n",
    "            'censor_at_switch': True,\n",
    "            'first_period': 0,\n",
    "            'last_period': float('inf'),\n",
    "            'n_observations': len(expansion_df)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return trial\n",
    "\n",
    "# Custom display function to mimic R output\n",
    "def display_expansion(trial):\n",
    "    if trial.expansion is None:\n",
    "        print(\"No expansion data available.\")\n",
    "        return\n",
    "    \n",
    "    meta = trial.expansion['metadata']\n",
    "    df = trial.expansion['data']\n",
    "    \n",
    "    print(\"Sequence of Trials Data:\")\n",
    "    print(f\"- Chunk size: {meta['chunk_size']}\")\n",
    "    print(f\"- Censor at switch: {meta['censor_at_switch']}\")\n",
    "    print(f\"- First period: {meta['first_period']} | Last period: {meta['last_period']}\")\n",
    "    print(f\"\\nA TE Datastore Datatable object\")\n",
    "    print(f\"N: {meta['n_observations']} observations\")\n",
    "    \n",
    "    # Display column headers with types (simplified)\n",
    "    col_types = {col: str(df[col].dtype) for col in df.columns}\n",
    "    print(\"        \" + \" \".join(f\"{col:<15}\" for col in df.columns))\n",
    "    print(\"        \" + \" \".join(f\"<{col_types[col]}>\" for col in df.columns))\n",
    "    \n",
    "    # Display first 2 and last 2 rows\n",
    "    display_df = pd.concat([df.head(2), df.tail(2)])\n",
    "    for i, row in display_df.iterrows():\n",
    "        print(f\"{i+1:3d}: \" + \" \".join(f\"{row[col]:>15.7f}\" if col in ['weight', 'x2'] else f\"{int(row[col]):>15d}\" for col in df.columns))\n",
    "    print(\"  ---\")\n",
    "\n",
    "# Example usage\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Set expansion options (from prior step)\n",
    "trial_pp = set_expansion_options(trial_pp, output=save_to_datatable(), chunk_size=500)\n",
    "trial_itt = set_expansion_options(trial_itt, output=save_to_datatable(), chunk_size=500)\n",
    "\n",
    "# Expand trials\n",
    "trial_pp = expand_trials(trial_pp)\n",
    "trial_itt = expand_trials(trial_itt)\n",
    "\n",
    "# Display trial_pp expansion\n",
    "display_expansion(trial_pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
